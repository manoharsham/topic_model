{"id": "24488539", "url": "https://en.wikipedia.org/wiki?curid=24488539", "title": "Aviation communication", "text": "Aviation communication\n\nAviation communication refers to the conversing of two or more aircraft. Aircraft are constructed in such a way that make it very difficult to see beyond what is directly in front of them. As safety is a primary focus in aviation, communication methods such as wireless radio are an effective way for aircraft to communicate with the necessary personnel. Aviation is an international industry and as a result involves multiple languages. However, as deemed by the International Civil Aviation Organization (ICAO), English is the official language of aviation. The industry considers that some pilots may not be fluent English speakers and as a result pilots are obligated to participate in an English proficiency test.\n\nAviation communication is the means by which aircraft crews connect with other aircraft and people on the ground to relay information. Aviation communication is a crucial component pertaining to the successful functionality of aircraft movement both on the ground and in the air. Increased communication reduces the risk of an accident.\n\nDuring the early stages of aviation, it was assumed that skies were too big and empty that it was impossible that two planes would collide. However, in 1956 two planes famously crashed over the Grand Canyon, which sparked the creation of the Federal Aviation Administration (FAA). Aviation was roaring during the Jet Age and as a result, communication technologies needed to be developed. This was initially seen as a very difficult task: ground controls used visual aids to provide signals to pilots in the air. With the advent of portable radios small enough to be placed in planes, pilots were able to communicate with people on the ground. With later developments, pilots were then able to converse air-to-ground and air-to-air. Today, aviation communication relies heavily on the use of many systems. Planes are outfitted with the newest radio and GPS systems, as well as Internet and video capabilities.\n\nEnglish is the main language used by the aviation industry; the use of aviation English is regulated by the International Civil Aviation Organization (ICAO).\n\nFlight was considered a foreign concept until the Wright Brothers successfully completed the world's first human flight in 1903. The industry grew rapidly and ground crews initially relied on coloured paddles, signal flares, hand signs, and other visual aids to communicate with incoming and outgoing aircraft. Although these methods were effective for ground crews, they offered no way for pilots to communicate back. As wireless telegraphy technologies developed alongside the growth of aviation during the first decade of the twentieth century, wireless telegraph systems were used to send messages in Morse code, first from ground-to-air and later air-to-ground. With this technology, planes were able to call in accurate artillery fire and act as forward observers in warfare.\n\nIn 1911, wireless telegraphy was put into operational use in the Italo-Turkish War. In 1912, the Royal Flying Corps had begun experimenting with \"wireless telegraphy\" in aircraft. Lieutenant B.T James was a leading pioneer of wireless radio in aircraft. In the spring of 1913, James had begun to experiment with radios in a B.E.2A. James managed to successfully increase the efficiency of wireless radio before he was shot down and killed by anti-aircraft fire on July 13, 1915.\n\nNonetheless, wireless communication systems in aircraft remained experimental and would take years to successfully develop a practical prototype. The early radios were heavy in weight and were considered an unreliable piece of equipment; additionally there were still major issues with ground forces using radio because signals were easily intercepted and targeted by opposing forces. At the beginning of World War I, aircraft were not typically equipped with wireless equipment. Instead, soldiers used large panel cut outs to distinguish friendly forces. These cut outs could also be used as a directional device to help pilots navigate back to friendly and familiar airfields.\n\nIn April 1915, Captain J.M. Furnival was the first person to hear a voice from the ground from Major Prince who said, \"If you can hear me now, it will be the first time speech has ever been communicated to an aeroplane in flight.\" In June 1915, the world's first air-to-ground voice transmission took place at Brooklands, England over about 20 miles. Ground-to-air was initially by Morse code, but it is believed 2-way voice communications were available and installed by July 1915. By early 1916, the Marconi Company (England) started production of air-to-ground radio transmitters/receivers which were used in the war over France.\n\nIn 1917, AT&T invented the first American air-to-ground radio transmitter. They tested this device at Langley Field in Virginia and found it was a viable technology. In May 1917, General George Squier of the U.S. Army Signal Corps contacted AT&T to develop an air-to-ground radio with a range of 2,000 yards. By July 4 of that same year, AT&T technicians achieved two-way communication between pilots and ground personnel. This allowed ground personnel to communicate directly with pilots using their voices instead of Morse code. Though few of these devices saw service in the war, they proved this was a viable and valuable technology worthy of refinement and advancement.\n\nFollowing World War I new technology was developed to increase the range and performance of the radios being used to communicate with planes in the air. In December 1919 a year after the end of World War I, Hugh Trenchard, 1st Viscount Trenchard, a senior officer in the Royal Flying Corps (RFC) later Royal Air Force (RAF), produced a report on the permanent organisation and operations of the RAF in peacetime in which he argued that if the air force officer was not to be a chauffeur, and nothing more, then navigation, meteorology, photography and wireless were necessities.\n\nIt was not until 1930 however that airborne radios were reliable enough and had enough power to make them viable to be standard in all planes and it was this year that the International Commission for Aerial Navigation agreed that all aircraft carrying 10 or more passengers should carry wireless equipment. Prior to this, only military aircraft designated for scout missions required radios. The operating distance of radios increased much slower than the distance planes were able to travel. After an original two miles-wide range for the two-way radio systems tested by 1917 had extended to ranges of an average of 20 miles, which were to remain the practical limit throughout the following decade for medium sized aircraft. In terms of air traffic control, this resulted in a planes messages having to bounce from airfield to airfield in order to get to its intended recipient. As the speed of planes increased this resulted in a plane reaching its destination before the message that it was on its way arrived at the airfield.\n\nOn 15 November 1938, the Army Airways Communications System (AACS) was established, this system was a point-to-point communications system used by the Army Air Corps. It allowed army air fields to remain in contact with planes throughout their entire flight. It could also be used to disseminate weather reports and orders to military aircraft and act as an air traffic control for arrivals and departures at military airfields. As technology increased, systems such as the AACS expanded and spread across the globe as other militaries and civilian services developed their own system of air control.\n\nThe development of radar in the mid-1930s proved a great advance in air-to-ground communication. Radar could be used to track planes in the air and determine distance, direction, speed and even type of aircraft. This allowed for better air traffic control as well as navigation aides for pilots. Radar also proved to be a valuable tool in targeting for bombers. Radar stations on the coast of Britain could aim two radar beams from separate locations on the coast towards Germany. By aligning the two radar beams to intersect over the desired target, a town or factory for example, an aircraft could then follow one radar signal until it intersected with the other where it would then know to drop bombs.\n\nThe Royal Air Force used the R1155/T1154 receiver/transmitter combination in most of its larger aircraft, particularly the Avro Lancaster and Short Sunderland. Single seat aircraft such as the Spitfire and Hurricane were equipped mostly with the TR1143 set. Other systems employed were Eureka and the S-Phone, which enabled Special Operations Executive agents working behind enemy lines to communicate with friendly aircraft and coordinate landings and the dropping of agents and supplies.\n\nCommunication error can occur between pilots and between pilots and air traffic controllers. Communication error contains: \n- amount of information\n- unclear pronunciation\n- misunderstanding\n\nThe more information needing transfer, the more chance for error. Unclear pronunciation could happen with non-English speakers. Sometimes lack of self-confidence and motivation affects expression in communication. Misunderstanding happens with both native speakers and non-native speakers through communication, so a standard aviation language is important to improve this situation.\n\nSources of communication error come from: phonology (speech rate, stress, intonation, pauses), syntax (language word patterns, sentence structure), semantics, and pragmatics (language in context). Even though English is the international aviation language, native English speakers still play a role in misunderstanding and situational awareness. Both the ICAO and the Federal Aviation Administration use alternative phrases, which is confusing to both native and non-native English speakers.\n\nThe biggest problem regarding non-native English speakers' transmissions is speech rate. In order to understand alternative and unfamiliar accents, people's rate of comprehension and response slows down. Accents also affect transmissions because of the different pronunciations across languages. Some of the earlier miscommunication issues included the limitation of language-based warning systems in aircraft and insufficient English proficiency.\n\nAccording to US department of transportation's report, errors between pilots and controllers include:\n\n- Read-back/hear-back errors - the pilot reads back the clearance incorrectly and the controller fails to correct the error - accounted for 47% of the errors found in this analysis.\n- No pilot read-back. A lack of a pilot read-back contributed to 25% of the errors found in this analysis.\n- Hear-back Errors Type H - the controller fails to notice his or her own error in the pilot's correct read-back or fails to correct critical erroneous information in a pilot's statement of intent - accounted for 18% of the errors found in this analysis.\n\nGenerally, miscommunication is caused by mis-hearing by the pilots for 28%, pilot not responding for 20%, controller mis-hearing for 15% and 10% that controllers do not respond. Also, a professional research shows that 30% of the information will be lost during the miscommunication. Moreover, miscommunication exists in personnel with different background of linguistics is shown to be one of the major problem in miscommunication to cause aviation accidents. Avoiding or minimizing miscommunication could be achieved by standardized debriefing or an interview process, and following a checklist to supplement written data.\n\nThe International Civil Aviation Organization established English as the international aviation language in 1951 to improve consistency, accuracy, and effectiveness of pilot - air traffic control communication. It requires that all pilots on international flights and air traffic controllers serving international airports and routes must be able to communicate in English effectively, as well as in their native language. The goal was to achieve standards that would eliminate communication error, language, and comprehension difficulties, all of which have been a major cause of operational airspace incidents. Miscommunication between pilots and air traffic control is a prominent factor in fatal airplane crashes, airspace incidents, runway incursion, and mid-air collisions.\n\nAviation English is the highly specialized language and sequences used by pilots, air traffic control, and other aviation personnel and it focuses on a particular pronunciation, vocabulary, grammatical structure, and discourse styles that are used in specific aviation-related contexts. The language used by pilots and air traffic controllers during radiotelephony communication can be categorized into two types: standard phraseology, and plain language repertoire. Standard phraseology is the specialized phrasing commonly used by the aviation community to effectively communicate, and plain language is a more normal language used in everyday life.\n\nMany non-native English speaking pilots and air traffic controllers learn English during their flight training and use it in a highly practical level while safely operating an aircraft and maintaining the safety of airspace, which can be highly stressful.\n\nICAO also established the Language Proficiency Requirements to try to rectify multiple issues regarding accents, terminology, and interpretation in communication. The intention of the LPRs is to \"ensure that the language proficiency of pilots and air traffic controllers is sufficient to reduce miscommunication as much as possible and to allow pilots and controllers to recognize and solve potential miscommunication when it does occur\" and \"that all speakers have sufficient language proficiency to handle non-routine situations.\" The structure of the LPR has six levels, pronunciation, structure, vocabulary, fluency, comprehension, and interactions. The implemented universal aviation English proficiency scale ranged from Level 1 to Level 6.\n\nBeginning in March 2008, ICAO set out the requirement that all pilots flying international routes and air traffic control serving international airports and routes must be a Level 4 or above and will be continually reassessed every three years. The criteria to achieve Level 4 are as follows:\n- Pronunciation: A dialect and/or accent intelligible to aeronautical community.\n- Structure: Relevant grammatical structures and sentence patterns determined by language functions appropriate to the task.\n- Vocabulary: Vocabulary range and accuracy used sufficiently to communicate effectively.\n- Fluency: Produces stretches of language at an appropriate tempo.\n- Comprehension: Comprehension accurate in common, concrete, and work-related topics and the accent used is sufficiently intelligible for the international community.\n- Interactions: Responses are immediate, appropriate, and informative.\n\nEnglish is the aviation language used by ICAO. Usually, human factors that affect communications include two aspects: direct, meaning the error caused by the language itself, which is the problem for non English speakers, and also indirect, with the gender, age, and experience impacting the communication in aviation.\n- Accent and dialect are significant problems in aviation communication. These may cause misunderstandings and result in the wrong information being conveyed.\n- Command of speech structures like grammar and vocabulary can also cause problems.\n- During the communication through English for non-English speakers, gender and race may affect ability to communicate with the second language which is an indirect impact on communication.\n- Intonation due to signal limitations, lack of function words, standard phraseology and rapid speech rate also plague many non English speakers.\nAs a result, both pilots and ATCs need to have enough English ability to accomplish their tasks. Through education to help improve aviation English, participants need not only focus on the textbook, but need experience in an actual environment such as lab experience to help speakers to improve their English fluency and avoid misunderstanding which helps non-English speakers to communicate normally.\n\n", "related": "\n- Air navigation\n"}
{"id": "2023546", "url": "https://en.wikipedia.org/wiki?curid=2023546", "title": "Military communications", "text": "Military communications\n\nMilitary communications or military signals involve all aspects of communications, or conveyance of information, by armed forces. Military communications span from pre-history to the present. The earliest military communications were delivered by runners. Later, communications progressed to visual and audible signals, and then advanced into the electronic age. Examples from \"Jane's Military Communications\" include text, audio, facsimile, [[Military tactics|tactical ground-based communications, terrestrial microwave, [[tropospheric scatter]], naval, satellite communications systems and equipment, surveillance and signal analysis, encryption and security and direction-finding and jamming.\n\nIn past centuries communicating a message usually required someone to go to the destination, bringing the message. Thus, the term \"communication\" often implied the ability to transport people and supplies. A place under [[siege]] was one that lost communication in both senses. The association between transport and messaging declined in recent centuries.\n\nThe first military communications involved the use of runners or the sending and receiving of simple [[wikt:signal|signals]] (sometimes [[cryptography|encoded]] to be unrecognizable). The first distinctive uses of military communications were called \"signals\". Modern units specializing in these tactics are usually designated as \"[[signal corps]]\". The Roman system of military communication (\"[[cursus publicus]]\" or \"cursus vehicularis\") is an early example of this. Later, the terms \"signals\" and \"[[signaler]]\" became words referring to a highly-distinct military occupation dealing with general communications methods (similar to those in [[Civilian|civil]] use) rather than with [[weapons]].\n\nPresent-day military forces of an [[informational society]] conduct intense and complicated communicating activities on a daily basis, using modern [[telecommunications]] and [[computing]] methods. Only a small portion of these activities are directly related to combat actions.\n\nModern concepts of [[network-centric warfare]] (NCW) rely on [[Telecommunications network|network]]-oriented methods of communications and control to make existing forces more effective.\n\nDrums, horns, flags, and riders on horseback were some of the early methods the military used to send messages over distances. In the middle 20th century [[radio]] equipment came to dominate the field.\n\nMany modern pieces of military communications equipment are built to both encrypt and decode [[Transmission (telecommunications)|transmissions]] and survive rough treatment in hostile climates. They use different [[frequency|frequencies]] to send signals to other radios and to satellites.\n\nMilitary communications - or \"comms\" - are activities, equipment, techniques, and tactics used by the military in some of the most hostile areas of the earth and in challenging environments such as battlefields, on [[Radio in a box|land]], underwater and also in air. Military comms include command, control and communications and intelligence and were known as the C3I model before computers were fully integrated. The U.S. Army expanded the model to C4I when it recognized the vital role played by automated computer equipment to send and receive large, bulky amounts of data. \n\nThe advent of distinctive signals led to the formation of the signal corps, a group specialized in the tactics of military communications. The signal corps evolved into a distinctive occupation where the [[signaler]] became a highly technical job dealing with all available communications methods including civil ones. \n\nIn the modern world, most nations attempt to minimize the risk of war caused by miscommunication or inadequate communication. As a result, military communication is intense and complicated, and often motivates the development of advanced technology for remote systems such as satellites and aircraft, both manned and unmanned, as well as computers. Computers and their varied applications have revolutionized military comms. Although military communication is designed for warfare, it also supports intelligence-gathering and communication between adversaries, and thus sometimes prevents war.\n[[File:Bundesarchiv Bild 101II-MW-5675-24, Übung zum Unternehmen \"Seelöwe\".jpg|alt=Man in uniform with headphones and throat microphone|thumb|Officer using radio, 1940]]\nThere are six categories of military comms: the alert measurement systems, cryptography, military radio systems, nuclear command control, the signal corps, and network-centric warfare.\n\nThe alert measurement systems are various states of alertness or readiness for the armed forces used around the world during a state of war, act of terrorism or a military attack against a state. They are known by different acronyms, such as DEFCON, or defense readiness condition, used by the U.S. Armed Forces.\n\n[[Cryptography]] is the study of methods of converting messages to a form unreadable except to one who knows how to decrypt them. This ancient military comms art gained new importance with the rise of radio systems whose signals traveled far and were easily intercepted. Cryptographic software is also widely used in civilian commerce.\n\nIn United States military communications systems, commercial refile refers to sending a military message via a commercial [[communications network]]. \nThe [[message]] may come from a military [[telecommunications network|network]], such as a [[tape relay]] network, a point-to-point telegraph network, a [[Wireless telegraphy|radio-telegraph]] network, or the [[Defense Switched Network]].\n\nCommercial refiling of a message will usually require a reformatting of the message, particularly the heading.\n\n", "related": "\n- [[Jane's Military Communications]]\n- [[Command and control]]\n- [[Signal Corps (disambiguation)]]\n- [[Telecommunications]]\n- [[Communications protection]]\n- [[Electronic warfare]]\n- [[SIGINT|Signals intelligence (SIGINT)]]\n- [[Defence Information Infrastructure]]\n- [[Kiev Military Institute of Control and Signals]]\n- [[Bowman (communications system)|Bowman]] (British Army communications system)\n- [[Parakeet (communication system)|Parakeet]] (Australian Army communications system)\n- [[Military Wireless Museum in the Midlands]]\n- [[Telegraph troops]]\n\n- [[Military hand and arm signals]]\n- [[Morse code]]\n- [[Flag semaphore]]\n- [[Flag signals]]\n- [[Naval flag signalling]]\n- [[Signal lamp]]\n- [[Heliograph]]\n- [[Radio communications]]\n- [[Wireless telegraphy]]\n\n- Signal Corps History\n- Signal Corps Officer Candidate School History\n\n[[Category:Military communications| ]]\n[[Category:Combat support occupations]]\n[[Category:Telecommunications]]"}
{"id": "1145887", "url": "https://en.wikipedia.org/wiki?curid=1145887", "title": "Mobile telephony", "text": "Mobile telephony\n\nMobile telephony is the provision of telephone services to phones which may move around freely rather than stay fixed in one location. Telephony is supposed to specifically point to a voice-only service or connection, though sometimes the line may blur.\n\nMobile phones connect to a terrestrial cellular network of base stations (cell sites), whereas satellite phones connect to orbiting satellites. Both networks are interconnected to the public switched telephone network (PSTN) to allow any phone in the world to be dialed.\n\nIn 2010 there were estimated to be five billion mobile cellular subscriptions in the world.\n\nAccording to internal memos, American Telephone & Telegraph discussed developing a wireless phone in 1915, but were afraid that deployment of the technology could undermine its monopoly on wired service in the U.S.\n\nPublic mobile phone systems were first introduced in the years after the Second World War and made use of technology developed before and during the conflict. The first system opened in St Louis, Missouri, USA in 1946 whilst other countries followed in the succeeding decades. The UK introduced its 'System 1' manual radiotelephone service as the South Lancashire Radiophone Service in 1958. Calls were made via an operator using handsets identical to ordinary phone handsets. The phone itself was a large box located in the boot (trunk) of the vehicle containing valves and other early electronic components. Although an uprated manual service ('System 3') was extended to cover most of the UK, automation did not arrive until 1981 with 'System 4'. Although this non-cellular service, based on German B-Netz technology, was expanded rapidly throughout the UK between 1982 and 1985 and continued in operation for several years before finally closing in Scotland, it was overtaken by the introduction in January 1985 of two cellular systems - the British Telecom/Securicor 'Cellnet' service and the Racal/Millicom/Barclays 'Vodafone' (from voice + data + phone) service. These cellular systems were based on US Advanced Mobile Phone Service (AMPS) technology, the modified technology being named Total Access Communication System (TACS).\n\nIn 1947, Bell Labs was the first to propose a cellular radio telephone network. The primary innovation was the development of a network of small overlapping cell sites supported by a call switching infrastructure that tracks users as they move through a network and passes their calls from one site to another without dropping the connection. In 1956, the MTA system was launched in Sweden. The early efforts to develop mobile telephony faced two significant challenges: allowing a great number of callers to use the comparatively few available frequencies simultaneously and allowing users to seamlessly move from one area to another without having their calls dropped. Both problems were solved by Bell Labs employee Amos Joel who, in 1970 applied for a patent for a mobile communications system. However, a business consulting firm calculated the entire U.S. market for mobile telephones at 100,000 units and the entire worldwide market at no more than 200,000 units based on the ready availability of pay telephones and the high cost of constructing cell towers. As a consequence, Bell Labs concluded that the invention was \"of little or no consequence,\" leading it not to attempt to commercialize the invention. The invention earned Joel induction into the National Inventors Hall of Fame in 2008.\n\nThe development of metal-oxide-semiconductor (MOS) large-scale integration (LSI) technology, information theory and cellular networking led to the development of affordable mobile communications. The first call on a handheld mobile phone was made on April 3, 1973 by Martin Cooper, then of Motorola to his opposite number in Bell Labs who were also racing to be first. Bell Labs went on to install the first trial cellular network in Chicago in 1978. This trial system was licensed by the FCC to ATT for commercial use in 1982 and, as part of the divestiture arrangements for the breakup of ATT, the AMPS technology was distributed to local telcos. The first commercial system opened in Chicago in October 1983. A system designed by Motorola also operated in the Washington D.C./Baltimore area from summer 1982 and became a full public service later the following year. Japan's first commercial radiotelephony service was launched by NTT in 1979.\n\nThe first fully automatic first generation cellular system was the Nordic Mobile Telephone (NMT) system, simultaneously launched in 1981 in Denmark, Finland, Norway and Sweden. NMT was the first mobile phone network featuring international roaming. The Swedish electrical engineer Östen Mäkitalo started to work on this vision in 1966, and is considered as the father of the NMT system and some also consider him the father of the cellular phone.\n\nThere was a rapid growth of wireless telecommunications towards the end of the 20th century, primarily due to the introduction of digital signal processing in wireless communications, driven by the development of low-cost, very large-scale integration (VLSI) RF CMOS (radio-frequency complementary MOS) technology. The advent of cellular technology encouraged European countries to co-operate in the development of a pan-European cellular technology to rival those of the US and Japan. This resulted in the GSM system, the initials originally from the \"Groupe Spécial Mobile\" that was charged with the specification and development tasks but latterly as the 'Global System for Mobile Communications'. The GSM standard eventually spread outside Europe and is now the most widely used cellular technology in the world and the de facto standard. The industry association, the GSMA, now represents 219 countries and nearly 800 mobile network operators. There are now estimated to be over 5 billion phone subscriptions according to the \"List of countries by number of mobile phones in use\" (although some users have multiple subscriptions, or inactive subscriptions), which also makes the mobile phone the most widely spread technology and the most common electronic device in the world.\n\nThe first mobile phone to enable internet connectivity and wireless email, the Nokia Communicator, was released in 1996, creating a new category of multi-use devices called smartphones. In 1999 the first mobile internet service was launched by NTT DoCoMo in Japan under the i-Mode service. By 2007 over 798 million people around the world accessed the internet or equivalent mobile internet services such as WAP and i-Mode at least occasionally using a mobile phone rather than a personal computer.\n\nMobile phones receive and send radio signals with any number of cell site base stations fitted with microwave antennas. These sites are usually mounted on a tower, pole or building, located throughout populated areas, then connected to a cabled communication network and switching system. The phones have a low-power transceiver that transmits voice and data to the nearest cell sites, normally not more than 8 to 13 km (approximately 5 to 8 miles) away. In areas of low coverage, a cellular repeater may be used, which uses a long distance high-gain dish antenna or yagi antenna to communicate with a cell tower far outside of normal range, and a repeater to rebroadcast on a small short-range local antenna that allows any cellphone within a few meters to function properly.\n\nWhen the mobile phone or data device is turned on, it registers with the mobile telephone exchange, or switch, with its unique identifiers, and can then be alerted by the mobile switch when there is an incoming telephone call. The handset constantly listens for the strongest signal being received from the surrounding base stations, and is able to switch seamlessly between sites. As the user moves around the network, the \"handoffs\" are performed to allow the device to switch sites without interrupting the call.\n\nCell sites have relatively low-power (often only one or two watts) radio transmitters which broadcast their presence and relay communications between the mobile handsets and the switch. The switch in turn connects the call to another subscriber of the same wireless service provider or to the public telephone network, which includes the networks of other wireless carriers. Many of these sites are camouflaged to blend with existing environments, particularly in scenic areas.\n\nThe dialogue between the handset and the cell site is a stream of digital data that includes digitised audio (except for the first generation analog networks). The technology that achieves this depends on the system which the mobile phone operator has adopted. The technologies are grouped by generation. The first-generation systems started in 1979 with Japan, are all analog and include AMPS and NMT. Second-generation systems, started in 1991 in Finland, are all digital and include GSM, CDMA and TDMA.\n\nThe nature of cellular technology renders many phones vulnerable to 'cloning': anytime a cell phone moves out of coverage (for example, in a road tunnel), when the signal is re-established, the phone sends out a 're-connect' signal to the nearest cell-tower, identifying itself and signalling that it is again ready to transmit. With the proper equipment, it's possible to intercept the re-connect signal and encode the data it contains into a 'blank' phone—in all respects, the 'blank' is then an exact duplicate of the real phone and any calls made on the 'clone' will be charged to the original account. This problem was widespread with the first generation analogue technology, however the modern digital standards such as GSM greatly improve security and make cloning hard to achieve.\n\nIn an effort to limit the potential harm from having a transmitter close to the user's body, the first fixed/mobile cellular phones that had a separate transmitter, vehicle-mounted antenna, and handset (known as \"car phones\" and \"bag phones\") were limited to a maximum 3 watts Effective Radiated Power. Modern \"handheld\" cellphones which must have the transmission antenna held inches from the user's skull are limited to a maximum transmission power of 0.6 watts ERP. Regardless of the potential biological effects, the reduced transmission range of modern handheld phones limits their usefulness in rural locations as compared to car/bag phones, and handhelds require that cell towers are spaced much closer together to compensate for their lack of transmission power.\n\nAn increasing number of countries, particularly in Europe, now have more mobile phones than people. According to the figures from Eurostat, the European Union's in-house statistical office, Luxembourg had the highest mobile phone penetration rate at 158 mobile subscriptions per 100 people, closely followed by Lithuania and Italy. In Hong Kong the penetration rate reached 139.8% of the population in July 2007. Over 50 countries have mobile phone subscription penetration rates higher than that of the population and the Western European average penetration rate was 110% in 2007 (source Informa 2007). Canada currently has the lowest rates of mobile phone penetrations in the industrialised world at 58%.\n\nThere are over five hundred million active mobile phone accounts in China, as of 2007, but the total penetration rate there still stands below 50%. The total number of mobile phone subscribers in the world was estimated at 2.14 billion in 2005. The subscriber count reached 2.7 billion by end of 2006 according to Information, and 3.3 billion by November, 2007, thus reaching an equivalent of over half the planet's population. Around 80% of the world's population has access to mobile phone coverage, as of 2006. This figure is expected to increase to 90% by the year 2010.\n\nIn some developing countries with little \"landline\" telephone infrastructure, mobile phone use has quadrupled in the last decade. The rise of mobile phone technology in developing countries is often cited as an example of the leapfrog effect. Many remote regions in the third world went from having no telecommunications infrastructure to having satellite based communications systems. At present, Africa has the largest growth rate of cellular subscribers in the world, its markets expanding nearly twice as fast as Asian markets.\nThe availability of prepaid or 'pay-as-you-go' services, where the subscriber is not committed to a long term contract, has helped fuel this growth in Africa as well as in other continents.\n\nOn a numerical basis, India is the largest growth market, adding about 6 million mobile phones every month. It currently has a mobile subscriber base of 937.06 million mobile phones.\n\nSince the world is operating quickly to 3G and 4G networks, mobile traffic through video is heading high. It is expected that by end of 2018, the global traffic will reach an annual rate of 190 exabytes/year. This is the result of people shifting to smartphones.\nIt is predicted by 2018, mobile traffic will reach by 10 billion connections with 94% traffic comes from Smartphones, laptops and tablets. Also 69% of mobile traffic from Videos since we have high definition screens available in smart phones and 176.9 wearable devices to be at use. Apparently, 4G will be dominating the traffic by 51% of total mobile data by 2018.\n\nLaw enforcement have used mobile phone evidence in a number of different ways. Evidence about the physical location of an individual at a given time can be obtained by triangulating the individual's cellphone between several cellphone towers. This triangulation technique can be used to show that an individual's cellphone was at a certain location at a certain time. The concerns over terrorism and terrorist use of technology prompted an inquiry by the British House of Commons Home Affairs Select Committee into the use of evidence from mobile phone devices, prompting leading mobile telephone forensic specialists to identify forensic techniques available in this area. NIST have published guidelines and procedures for the preservation, acquisition, examination, analysis, and reporting of digital information present on mobile phones can be found under the NIST Publication SP800-101.\n\nIn the UK in 2000 it was claimed that recordings of mobile phone conversations made on the day of the Omagh bombing were crucial to the police investigation. In particular, calls made on two mobile phones which were tracked from south of the Irish border to Omagh and back on the day of the bombing, were considered of vital importance.\n\nFurther example of criminal investigations using mobile phones is the initial location and ultimate identification of the terrorists of the 2004 Madrid train bombings. In the attacks, mobile phones had been used to detonate the bombs. However, one of the bombs failed to detonate, and the SIM card in the corresponding mobile phone gave the first serious lead about the terrorists to investigators. By tracking the whereabouts of the SIM card and correlating other mobile phones that had been registered in those areas, police were able to locate the terrorists.\n\nThe Finnish government decided in 2005 that the fastest way to warn citizens of disasters was the mobile phone network. In Japan, mobile phone companies provide immediate notification of earthquakes and other natural disasters to their customers free of charge. In the event of an emergency, disaster response crews can locate trapped or injured people using the signals from their mobile phones. An interactive menu accessible through the phone's Internet browser notifies the company if the user is safe or in distress. In Finland rescue services suggest hikers carry mobile phones in case of emergency even when deep in the forests beyond cellular coverage, as the radio signal of a cellphone attempting to connect to a base station can be detected by overflying rescue aircraft with special detection gear. Also, users in the United States can sign up through their provider for free text messages when an AMBER Alert goes out for a missing person in their area.\n\nHowever, most mobile phone networks operate close to capacity during normal times, and spikes in call volumes caused by widespread emergencies often overload the system just when it is needed the most. Examples reported in the media where this has occurred include the September 11, 2001 attacks, the 2003 Northeast blackouts, the 2005 London Tube bombings, Hurricane Katrina, the 2006 Kiholo Bay earthquake, and the 2007 Minnesota bridge collapse.\n\nUnder FCC regulations, all mobile telephones must be capable of dialing emergency telephone numbers, regardless of the presence of a SIM card or the payment status of the account.\n\nSince the introduction of mobile phones, concerns (both scientific and public) have been raised about the potential health impacts from regular use. But by 2008, American mobile phones transmitted and received more text messages than phone calls. Numerous studies have reported no significant relationship between mobile phone use and health, but the effect of mobile phone usage on health continues to be an area of public concern.\n\nFor example, at the request of some of their customers, Verizon created usage controls that meter service and can switch phones off, so that children could get some sleep. There have also been attempts to limit use by persons operating moving trains or automobiles, coaches when writing to potential players on their teams, and movie theater audiences. By one measure, nearly 40% of automobile drivers aged 16 to 30 years old text while driving, and by another, 40% of teenagers said they could text blindfolded.\n\n18 studies have been conducted on the link between cell phones and brain cancer; A review of these studies found that cell phone use of 10 years or more \"give a consistent pattern of an increased risk for acoustic neuroma and glioma\". The tumors are found mostly on the side of the head that the mobile phone is in contact with. In July 2008, Dr. Ronald Herberman, director of the University of Pittsburgh Cancer Institute, warned about the radiation from mobile phones. He stated that there was no definitive proof of the link between mobile phones and brain tumors but there was enough studies that mobile phone usage should be reduced as a precaution. To reduce the amount of radiation being absorbed hands free devices can be used or texting could supplement calls. Calls could also be shortened or limit mobile phone usage in rural areas. Radiation is found to be higher in areas that are located away from mobile phone towers.\n\nAccording to Reuters, The British Association of Dermatologists is warning of a rash occurring on people's ears or cheeks caused by an allergic reaction from the nickel surface commonly found on mobile devices’ exteriors. There is also a theory it could even occur on the fingers if someone spends a lot of time text messaging on metal menu buttons. In 2008, Lionel Bercovitch of Brown University in Providence, Rhode Island, and his colleagues tested 22 popular handsets from eight different manufacturers and found nickel on 10 of the devices.\n\nBetween the 1980s and the 2000s, the mobile phone has gone from being an expensive item used by the business elite to a pervasive, personal communications tool for the general population. In most countries, mobile phones outnumber land-line phones, with fixed landlines numbering 1.3 billion but mobile subscriptions 3.3 billion at the end of 2007.\n\nIn many markets from Japan and South Korea, to Europe, to Malaysia, Singapore, Taiwan and Hong Kong, most children age 8-9 have mobile phones and the new accounts are now opened for customers aged 6 and 7. Where mostly parents tend to give hand-me-down used phones to their youngest children, in Japan already new cameraphones are on the market whose target age group is under 10 years of age, introduced by KDDI in February 2007. The USA also lags on this measure, as in the US so far, about half of all children have mobile phones. In many young adults' households it has supplanted the land-line phone. Mobile phone usage is banned in some countries, such as North Korea and restricted in some other countries such as Burma.\n\nGiven the high levels of societal mobile phone service penetration, it is a key means for people to communicate with each other. The SMS feature spawned the \"texting\" sub-culture amongst younger users. In December 1993, the first person-to-person SMS text message was transmitted in Finland. Currently, texting is the most widely used data service; 1.8 billion users generated $80 billion of revenue in 2006 (source ITU). Many phones offer Instant Messenger services for simple, easy texting. Mobile phones have Internet service (e.g. NTT DoCoMo's i-mode), offering text messaging via e-mail in Japan, South Korea, China, and India. Most mobile internet access is much different from computer access, featuring alerts, weather data, e-mail, search engines, instant messages, and game and music downloading; most mobile internet access is hurried and short.\n\nBecause mobile phones are often used publicly, social norms have been shown to play a major role in the usage of mobile phones. Furthermore, the mobile phone can be a fashion totem custom-decorated to reflect the owner's personality and may be a part of their self-identity. This aspect of the mobile telephony business is, in itself, an industry, e.g. ringtone sales amounted to $3.5 billion in 2005.\nMobile phone use on aircraft is starting to be allowed with several airlines already offering the ability to use phones during flights. Mobile phone use during flights used to be prohibited and many airlines still claim in their in-plane announcements that this prohibition is due to possible interference with aircraft radio communications. Shut-off mobile phones do not interfere with aircraft avionics. The recommendation why phones should not be used during take-off and landing, even on planes that allow calls or messaging, is so that passengers pay attention to the crew for any possible accident situations, as most aircraft accidents happen on take-off and landing.\n\nMobile phone use can be an important matter of social discourtesy: phones ringing during funerals or weddings; in toilets, cinemas and theatres. Some book shops, libraries, bathrooms, cinemas, doctors' offices and places of worship prohibit their use, so that other patrons will not be disturbed by conversations. Some facilities install signal-jamming equipment to prevent their use, although in many countries, including the US, such equipment is illegal.\n\nMany US cities with subway transit systems underground are studying or have implemented mobile phone reception in their tunnels for their riders, and trains, particularly those involving long-distance services, often offer a \"quiet carriage\" where phone use is prohibited, much like the designated non-smoking carriage of the past. Most schools in the United States and Europe and Canada have prohibited mobile phones in the classroom, or in school in an effort to limit class disruptions.\n\nA working group made up of Finnish telephone companies, public transport operators and communications authorities has launched a campaign to remind mobile phone users of courtesy, especially when using mass transit—what to talk about on the phone, and how to. In particular, the campaign wants to impact loud mobile phone usage as well as calls regarding sensitive matters.\n\nThe use of mobile phones by people who are driving has become increasingly common, for example as part of their job, as in the case of delivery drivers who are calling a client, or socially as for commuters who are chatting with a friend. While many drivers have embraced the convenience of using their cellphone while driving, some jurisdictions have made the practice against the law, such as Australia, the Canadian provinces of British Columbia, Quebec, Ontario, Nova Scotia, and Newfoundland and Labrador as well as the United Kingdom, consisting of a zero-tolerance system operated in Scotland and a warning system operated in England, Wales, and Northern Ireland. Officials from these jurisdictions argue that using a mobile phone while driving is an impediment to vehicle operation that can increase the risk of road traffic accidents.\n\nStudies have found vastly different relative risks (RR). Two separate studies using case-crossover analysis each calculated RR at 4, while an epidemiological cohort study found RR, when adjusted for crash-risk exposure, of 1.11 for men and 1.21 for women.\n\nA simulation study from the University of Utah Professor David Strayer compared drivers with a blood alcohol content of 0.08% to those conversing on a cell phone, and after controlling for driving difficulty and time on task, the study concluded that cell phone drivers exhibited greater impairment than intoxicated drivers. Meta-analysis by The Canadian Automobile Association and The University of Illinois found that response time while using both hands-free and hand-held phones was approximately 0.5 standard deviations higher than normal driving (i.e., an average driver, while talking on a cell phone, has response times of a driver in roughly the 40th percentile).\n\nDriving while using a hands-free device is not safer than driving while using a hand-held phone, as concluded by case-crossover studies. epidemiological studies, simulation studies, and meta-analysis. Even with this information, California initiated new Wireless Communications Device Law (effective January 1, 2009) makes it an infraction to write, send, or read text-based communication on an electronic wireless communications device, such as a cell phone, while driving a motor vehicle. Two additional laws dealing with the use of wireless telephones while driving went into effect July 1, 2008. The first law prohibits all drivers from using a handheld wireless telephone while operating a motor vehicle. The law allows a driver to use a wireless telephone to make emergency calls to a law enforcement agency, a medical provider, the fire department, or other emergency services agency. The base fine for the FIRST offense is $20 and $50 for subsequent convictions. With penalty assessments, the fine can be more than triple the base fine amount. videos about California cellular phone laws; with captions (California Vehicle Code [VC] §23123). Motorists 18 and over may use a “hands-free device. The second law effective July 1, 2008, prohibits drivers under the age of 18 from using a wireless telephone or hands-free device while operating a motor vehicle (VC §23124)The consistency of increased crash risk between hands-free and hand-held phone use is at odds with legislation in over 30 countries that prohibit hand-held phone use but allow hands-free. Scientific literature is mixed on the dangers of talking on a phone versus those of talking with a passenger, with the Accident Research Unit at the University of Nottingham finding that the number of utterances was usually higher for mobile calls when compared to blindfolded and non-blindfolded passengers, but the University of Illinois meta-analysis concluding that passenger conversations were just as costly to driving performance as cell phone ones.\n\nAs of 2007, several airlines are experimenting with base station and antenna systems installed on the airplane, allowing low power, short-range connection of any phones aboard to remain connected to the aircraft's base station. Thus, they would not attempt connection to the ground base stations as during take off and landing. Simultaneously, airlines may offer phone services to their travelling passengers either as full voice and data services, or initially only as SMS text messaging and similar services. The Australian airline Qantas is the first airline to run a test aeroplane in this configuration in the autumn of 2007. Emirates has announced plans to allow limited mobile phone usage on some flights. However, in the past, commercial airlines have prevented the use of cell phones and laptops, due to the assertion that the frequencies emitted from these devices may disturb the radio waves contact of the airplane.\n\nOn March 20, 2008, an Emirates flight was the first time voice calls have been allowed in-flight on commercial airline flights. The breakthrough came after the European Aviation Safety Agency (EASA) and the United Arab Emirates-based General Civil Aviation Authority (GCAA) granted full approval for the AeroMobile system to be used on Emirates. Passengers were able to make and receive voice calls as well as use text messaging. The system automatically came into operation as the Airbus A340-300 reached cruise altitude. Passengers wanting to use the service received a text message welcoming them to the AeroMobile system when they first switched their phones on. The approval by EASA has established that GSM phones are safe to use on airplanes, as the AeroMobile system does not require the modification of aircraft components deemed \"sensitive,\" nor does it require the use of modified phones.\n\nIn any case, there are inconsistencies between practices allowed by different airlines and even on the same airline in different countries. For example, Delta Air Lines may allow the use of mobile phones immediately after landing on a domestic flight within the US, whereas they may state \"not until the doors are open\" on an international flight arriving in the Netherlands. In April 2007 the US Federal Communications Commission officially prohibited passengers' use of cell phones during a flight.\n\nIn a similar vein, signs are put up in many countries, such as Canada, the UK and the U.S., at petrol stations prohibiting the use of mobile phones, due to possible safety issues. However, it is unlikely that mobile phone use can cause any problems, and in fact \"petrol station employees have themselves spread the rumour about alleged incidents.\"\n\nLike all high structures, cellular antenna masts pose a hazard to low flying aircraft. Towers over a certain height or towers that are close to airports or heliports are normally required to have warning lights. There have been reports that warning lights on cellular masts, TV-towers and other high structures can attract and confuse birds. US authorities estimate that millions of birds are killed near communication towers in the country each year.\n\nSome cellular antenna towers have been camouflaged to make them less obvious on the horizon, and make them look more like a tree.\n\nAn example of the way mobile phones and mobile networks have sometimes been perceived as a threat is the widely reported and later discredited claim that mobile phone masts are associated with the Colony Collapse Disorder (CCD) which has reduced bee hive numbers by up to 75% in many areas, especially near cities in the US. The Independent newspaper cited a scientific study claiming it provided evidence for the theory that mobile phone masts \"are\" a major cause in the collapse of bee populations, with controlled experiments demonstrating a rapid and catastrophic effect on individual hives near masts.\nMobile phones were in fact not covered in the study, and the original researchers have since emphatically disavowed any connection between their research, mobile phones, and CCD, specifically indicating that the Independent article had misinterpreted their results and created \"a horror story\".\nWhile the initial claim of damage to bees was widely reported, the corrections to the story were almost non-existent in the media.\n\nThere are more than 500 million used mobile phones in the US sitting on shelves or in landfills, and it is estimated that over 125 million will be discarded this year alone. The problem is growing at a rate of more than two million phones per week, putting tons of toxic waste into landfills daily. Several companies offer to buy back and recycle mobile phones from users. In the United States many unwanted but working mobile phones are donated to women's shelters to allow emergency communication.\n\nThere are two principal ways to pay for mobile telephony: the 'pay-as-you-go' model where conversation time is purchased and added to a phone unit via an Internet account or in shops or ATMs, or the contract model where bills are paid by regular intervals after the service has been consumed. It is increasingly common for a consumer to purchase a basic package and then bolt-on services and functionality to create a subscription customised to the users needs.\n\nPay as you go (also known as \"pre-pay\" or \"prepaid\") accounts were invented simultaneously in Portugal and Italy and today form more than half of all mobile phone subscriptions. USA, Canada, Costa Rica, Japan, Israel and Finland are among the rare countries left where most phones are still contract-based.\n\nIn the early days of mobile telephony, the operators (carriers) charged for all air time consumed by the mobile phone user, which included both outbound and inbound telephone calls. As mobile phone adoption rates increased, competition between operators meant that some decided not to charge for incoming calls in some markets (also called \"calling party pays\").\n\nThe European market adopted a calling party pays model throughout the GSM environment and soon various other GSM markets also started to emulate this model.\n\nIn Hong Kong, Singapore, Canada, and the United States, it is common for the party receiving the call to be charged per minute, although a few carriers are beginning to offer unlimited received phone calls. This is called the \"Receiving Party Pays\" model. In China, it was reported that both of its two operators will adopt the caller-pays approach as early as January 2007.\n\nOne disadvantage of the receiving party pays systems is that phone owners keep their phones turned off to avoid receiving unwanted calls, which results in the total voice usage rates (and profits) in Calling Party Pays countries outperform those in Receiving Party Pays countries. To avoid the problem of users keeping their phone turned off, most Receiving Party Pays countries have either switched to Calling Party Pays, or their carriers offer additional incentives such as a large number of monthly minutes at a sufficiently discounted rate to compensate for the inconvenience.\n\nNote that when a user roaming in another country, international roaming tariffs apply to all calls received, regardless of the model adopted in the home country.\n\n", "related": "\n- Cellular network\n- Mobile Internet\n- Mobile phone\n- OpenBTS\n\n- Chen, Adrian, \"The Confidence Game: How Silicon Valley broke the economy\", \"The Nation\", vol. 309, no. 11 (4 November 2019), pp. 27–30. The multifarious abuses perpetrated by individuals, organizations, corporations, and governments, using the Internet and mobile telephony, prompt Adrian Chen to muse whether \"a technical complex born... of Cold War militarism and mainstreamed in a free-market frenzy might not be fundamentally always at odds with human flourishing.\" (p. 30.)\n"}
{"id": "164174", "url": "https://en.wikipedia.org/wiki?curid=164174", "title": "Optical communication", "text": "Optical communication\n\nOptical communication, also known as optical telecommunication, is communication at a distance using light to carry information. It can be performed visually or by using electronic devices. The earliest basic forms of optical communication date back several millennia, while the earliest electrical device created to do so was the photophone, invented in 1880.\n\nAn optical communication system uses a transmitter, which encodes a message into an optical signal, a channel, which carries the signal to its destination, and a receiver, which reproduces the message from the received optical signal. When electronic equipment is not employed the 'receiver' is a person visually observing and interpreting a signal, which may be either simple (such as the presence of a beacon fire) or complex (such as lights using color codes or flashed in a Morse code sequence).\n\nFree-space optical communication has been deployed in space, while terrestrial forms are naturally limited by geography, weather and the availability of light. This article provides a basic introduction to different forms of optical communication.\n\nVisual techniques such as smoke signals, beacon fires, hydraulic telegraphs, ship flags and semaphore lines were the earliest forms of optical communication. Hydraulic telegraph semaphores date back to the 4th century BCE Greece. Distress flares are still used by mariners in emergencies, while lighthouses and navigation lights are used to communicate navigation hazards.\n\nThe heliograph uses a mirror to reflect sunlight to a distant observer. When a signaler tilts the mirror to reflect sunlight, the distant observer sees flashes of light that can be used to transmit a prearranged signaling code. Naval ships often use signal lamps and Morse code in a similar way.\n\nAircraft pilots often use visual approach slope indicator (VASI) projected light systems to land safely, especially at night. Military aircraft landing on an aircraft carrier use a similar system to land correctly on a carrier deck. The coloured light system communicates the aircraft's height relative to a standard landing glideslope. As well, airport control towers still use Aldis lamps to transmit instructions to aircraft whose radios have failed.\n\nIn the present day a variety of electronic systems optically transmit and receive information carried by pulses of light. Fiber-optic communication cables are now employed to send the great majority of the electronic data and long distance telephone calls that are not conveyed by either radio, terrestrial microwave or satellite. Free-space optical communications are also used every day in various applications.\n\nA 'semaphore telegraph', also called a 'semaphore line', 'optical telegraph', 'shutter telegraph chain', 'Chappe telegraph', or 'Napoleonic semaphore', is a system used for conveying information by means of visual signals, using towers with pivoting arms or shutters, also known as blades or paddles. Information is encoded by the position of the mechanical elements; it is read when the shutter is in a fixed position.\n\nSemaphore lines were a precursor of the electrical telegraph. They were far faster than post riders for conveying a message over long distances, but far more expensive and less private than the electrical telegraph lines which would later replace them. The maximum distance that a pair of semaphore telegraph stations can bridge is limited by geography, weather and the availability of light; thus, in practical use, most optical telegraphs used lines of relay stations to bridge longer distances. Each relay station would also require its complement of skilled operator-observers to convey messages back and forth across the line.\n\nThe modern design of semaphores was first foreseen by the British polymath Robert Hooke, who first gave a vivid and comprehensive outline of visual telegraphy in a 1684 submission to the Royal Society. His proposal (which was motivated by military concerns following the Battle of Vienna the preceding year) was not put into practice during his lifetime.\n\nThe first operational optical semaphore line arrived in 1792, created by the French engineer Claude Chappe and his brothers, who succeeded in covering France with a network of 556 stations stretching a total distance of . It was used for military and national communications until the 1850s.\n\nMany national services adopted signaling systems different from the Chappe system. For example, Britain and Sweden adopted systems of shuttered panels (in contradiction to the Chappe brothers' contention that angled rods are more visible). In Spain, the engineer Agustín de Betancourt developed his own system which was adopted by that state. This system was considered by many experts in Europe better than Chappe's, even in France.\n\nThese systems were popular in the late 18th to early 19th century but could not compete with the electrical telegraph, and went completely out of service by 1880.\n\nSemaphore Flags is the system for conveying information at a distance by means of visual signals with hand-held flags, rods, disks, paddles, or occasionally bare or gloved hands. Information is encoded by the position of the flags, objects or arms; it is read when they are in a fixed position.\n\nSemaphores were adopted and widely used (with hand-held flags replacing the mechanical arms of shutter semaphores) in the maritime world in the 19th century. They are still used during underway replenishment at sea and are acceptable for emergency communication in daylight or, using lighted wands instead of flags, at night.\n\nThe newer flag semaphore system uses two short poles with square flags, which a signaler holds in different positions to convey letters of the alphabet and numbers. The transmitter holds one pole in each hand, and extends each arm in one of eight possible directions. Except for in the rest position, the flags cannot overlap. The flags are colored differently based on whether the signals are sent by sea or by land. At sea, the flags are colored red and yellow (the Oscar flags), while on land, they are white and blue (the Papa flags). Flags are not required, they just make the characters more obvious.\n\nOptical fiber is the most common type of channel for optical communications. The transmitters in optical fiber links are generally light-emitting diodes (LEDs) or laser diodes. Infrared light, rather than visible light is used more commonly, because optical fibers transmit infrared wavelengths with less attenuation and dispersion. The signal encoding is typically simple intensity modulation, although historically optical phase and frequency modulation have been demonstrated in the lab. The need for periodic signal regeneration was largely superseded by the introduction of the erbium-doped fiber amplifier, which extended link distances at significantly lower cost.\n\nSignal lamps (such as Aldis lamps), are visual signaling devices for optical communication (typically using Morse code). Modern signal lamps are a focused lamp which can produce a pulse of light. In large versions this pulse is achieved by opening and closing shutters mounted in front of the lamp, either via a manually operated pressure switch or, in later versions, automatically.\n\nWith hand held lamps, a concave mirror is tilted by a trigger to focus the light into pulses. The lamps are usually equipped with some form of optical sight, and are most commonly deployed on naval vessels and also used in airport control towers with coded aviation light signals.\n\nAviation light signals are used in the case of a radio failure, an aircraft not equipped with a radio, or in the case of a hearing-impaired pilot. Air traffic controllers have long used signal light guns to direct such aircraft. The light gun's lamp has a focused bright beam capable of emitting three different colors: red, white and green. These colors may be flashing or steady, and provide different instructions to aircraft in flight or on the ground (for example, \"cleared to land\" or \"cleared for takeoff\"). Pilots can acknowledge the instructions by wiggling their plane's wings, moving their ailerons if they are on the ground, or by flashing their landing or navigation lights during night time. Only 12 simple standardized instructions are directed at aircraft using signal light guns as the system is not utilized with Morse code.\n\nThe photophone (originally given an alternate name, radiophone) is a communication device which allowed for the transmission of speech on a beam of light. It was invented jointly by Alexander Graham Bell and his assistant Charles Sumner Tainter on February 19, 1880, at Bell's 1325 'L' Street laboratory in Washington, D.C. Both were later to become full associates in the Volta Laboratory Association, created and financed by Bell.\n\nOn June 21, 1880, Bell's assistant transmitted a wireless voice telephone message of considerable distance, from the roof of the Franklin School to the window of Bell's laboratory, some 213 meters (about 700 ft.) away.\n\nBell believed the photophone was his most important invention. Of the 18 patents granted in Bell's name alone, and the 12 he shared with his collaborators, four were for the photophone, which Bell referred to as his\" 'greatest achievement\"', telling a reporter shortly before his death that the photophone was \"the greatest invention [I have] ever made, greater than the telephone\".\n\nThe photophone was a precursor to the fiber-optic communication systems which achieved popular worldwide usage starting in the 1980s. The master patent for the photophone ( \"Apparatus for Signalling and Communicating, called Photophone\"), was issued in December 1880, many decades before its principles came to have practical applications.\n\nFree-space optics (FSO) systems are employed for 'last mile' telecommunications and can function over distances of several kilometers as long as there is a clear line of sight between the source and the destination, and the optical receiver can reliably decode the transmitted information. Other free-space systems can provide high-data-rate, long-range links using small, low-mass, low-power-consumption subsystems which make them suitable for communications in space. Various planned satellite constellations intended to provide global broadband coverage take advantage of these benefits and employ laser communication for inter-satellite links between the several hundred to thousand satellites effectively creating a space-based optical mesh network.\n\nMore generally, transmission of unguided optical signals is known as optical wireless communications (OWC). Examples include medium-range visible light communication and short-distance IrDA, using infrared LEDs.\n\nA heliograph ( \"helios\", meaning \"sun\", and \"graphein\", meaning \"write\") is a wireless solar telegraph that signals by flashes of sunlight (generally using Morse code) reflected by a mirror. The flashes are produced by momentarily pivoting the mirror, or by interrupting the beam with a shutter.\n\nThe heliograph was a simple but effective instrument for instantaneous optical communication over long distances during the late 19th and early 20th century. Its main uses were in military, surveys and forest protection work. They were standard issue in the British and Australian armies until the 1960s, and were used by the Pakistani army as late as 1975.\n\n", "related": "\n- Fiber tapping\n- Interconnect bottleneck\n- Jun-Ichi Nishizawa an inventor of optical communication.\n- Modulating retro-reflector\n- OECC (OptoElectronics and Communications Conference)\n- Optical interconnect\n- Opto-isolator\n- Parallel optical interface\n\n- Alwayn, Vivek. Fiber-Optic Technologies, Cisco Press, Apr 23, 2004.\n- Bruce, Robert V \"Bell: Alexander Bell and the Conquest of Solitude\", Ithaca, New York: Cornell University Press, 1990. .\n- Mims III, Forest M. The First Century of Lightwave Communications, \"Fiber Optics Weekly Update\", Information Gatekeepers, February 10–26, 1982, pp. 6–23.\n- Paschotta, Rüdiger. Encyclopedia of Laser Physics and Technology, RP-Photonics.com website, 2012.\n- Bayvel, Polina Future High-Capacity Optical Telecommunication Networks, \"Philosophical Transactions: Mathematical, Physical and Engineering Sciences\", Vol. 358, No. 1765, January 2000, Science into the Next Millennium: Young Scientists Give Their Visions of the Future: II. Mathematics, Physics and Engineering, pp. 303–329, stable article URL: https://www.jstor.org/stable/2666790, published by The Royal Society.\n- Dilhac, J-M. The Telegraph of Claude Chappe -An Optical Telecommunication Network For The XVIII Century, Toulouse: Institut National des Sciences Appliquées de Toulouse. Retrieved from IEEE Global History Network.\n"}
{"id": "41782", "url": "https://en.wikipedia.org/wiki?curid=41782", "title": "Telecommunications service", "text": "Telecommunications service\n\nIn telecommunication, a telecommunications service is a service provided by a telecommunications provider, or a specified set of user-information transfer capabilities provided to a group of users by a telecommunications system.\n\nThe telecommunications service user is responsible for the information content of the message. The telecommunications service provider has the responsibility for the acceptance, transmission, and delivery of the message.\n\nFor purposes of regulation by the Federal Communications Commission under the U.S. Communications Act of 1934 and Telecommunications Act of 1996, the definition of telecommunications service is \"the offering of telecommunications for a fee directly to the public, or to such classes of users as to be effectively available directly to the public, regardless of the facilities used.\" \"Telecommunications\", in turn, is defined as \"the transmission, between or among points specified by the user, of information of the user’s choosing, without change in the form or content of the information as sent and received.\" \n\n", "related": "\n- Communications service provider\n- Intelligent network service (IN service)\n- Internet service provider (ISP)\n- Service layer\n- Value-added service (content provider redirects here)\n\n"}
{"id": "46256", "url": "https://en.wikipedia.org/wiki?curid=46256", "title": "Telemetry", "text": "Telemetry\n\nTelemetry is the collection of measurements or other data at remote or inaccessible points and their automatic transmission to receiving equipment for monitoring. The word is derived from the Greek roots \"tele\", \"remote\", and \"metron\", \"measure\". Systems that need external instructions and data to operate require the counterpart of telemetry, telecommand.\n\nAlthough the term commonly refers to wireless data transfer mechanisms (e.g., using radio, ultrasonic, or infrared systems), it also encompasses data transferred over other media such as a telephone or computer network, optical link or other wired communications like power line carriers. Many modern telemetry systems take advantage of the low cost and ubiquity of GSM networks by using SMS to receive and transmit telemetry data.\n\nA telemeter is a device used to remotely measure any quantity. It consists of a sensor, a transmission path, and a display, recording, or control device. Telemeters are the physical devices used in telemetry. Electronic devices are widely used in telemetry and can be wireless or hard-wired, analog or digital. Other technologies are also possible, such as mechanical, hydraulic and optical.\n\nTelemetry may be commutated to allow the transmission of multiple data streams in a fixed frame.\n\nTelemetering information over wire had its origins in the 19th century. One of the first data-transmission circuits was developed in 1845 between the Russian Tsar's Winter Palace and army headquarters. In 1874, French engineers built a system of weather and snow-depth sensors on Mont Blanc that transmitted real-time information to Paris. In 1901 the American inventor C. Michalke patented the selsyn, a circuit for sending synchronized rotation information over a distance. In 1906 a set of seismic stations were built with telemetering to the Pulkovo Observatory in Russia. In 1912, Commonwealth Edison developed a system of telemetry to monitor electrical loads on its power grid. The Panama Canal (completed 1913–1914) used extensive telemetry systems to monitor locks and water levels.\n\nWireless telemetry made early appearances in the radiosonde, developed concurrently in 1930 by Robert Bureau in France and Pavel Molchanov in Russia. Molchanov's system modulated temperature and pressure measurements by converting them to wireless Morse code. The German V-2 rocket used a system of primitive multiplexed radio signals called \"Messina\" to report four rocket parameters, but it was so unreliable that Wernher von Braun once claimed it was more useful to watch the rocket through binoculars. In the US and the USSR, the Messina system was quickly replaced with better systems (in both cases, based on pulse-position modulation).\n\nEarly Soviet missile and space telemetry systems which were developed in the late 1940s used either pulse-position modulation (e.g., the Tral telemetry system developed by OKB-MEI) or pulse-duration modulation (e.g., the RTS-5 system developed by NII-885). In the United States, early work employed similar systems, but were later replaced by pulse-code modulation (PCM) (for example, in the Mars probe Mariner 4). Later Soviet interplanetary probes used redundant radio systems, transmitting telemetry by PCM on a decimeter band and PPM on a centimeter band.\n\nTelemetry has been used by weather balloons for transmitting meteorological data since 1920.\n\nTelemetry is used to transmit drilling mechanics and formation evaluation information uphole, in real time, as a well is drilled. These services are known as Measurement while drilling and Logging while drilling. Information acquired thousands of feet below ground, while drilling, is sent through the drilling hole to the surface sensors and the demodulation software. The pressure wave (sana) is translated into useful information after DSP and noise filters. This information is used for Formation evaluation, Drilling Optimization, and Geosteering.\n\nTelemetry is a key factor in modern motor racing, allowing race engineers to interpret data collected during a test or race and use it to properly tune the car for optimum performance. Systems used in series such as Formula One have become advanced to the point where the potential lap time of the car can be calculated, and this time is what the driver is expected to meet. Examples of measurements on a race car include accelerations (G forces) in three axes, temperature readings, wheel speed, and suspension displacement. In Formula One, driver input is also recorded so the team can assess driver performance and (in case of an accident) the FIA can determine or rule out driver error as a possible cause.\n\nLater developments include two-way telemetry which allows engineers to update calibrations on the car in real time (even while it is out on the track). In Formula One, two-way telemetry surfaced in the early 1990s and consisted of a message display on the dashboard which the team could update. Its development continued until May 2001, when it was first allowed on the cars. By 2002, teams were able to change engine mapping and deactivate engine sensors from the pit while the car was on the track. For the 2003 season, the FIA banned two-way telemetry from Formula One; however, the technology may be used in other types of racing or on road cars.\n\nOne way telemetry system has also been applied in R/C racing car to get information by car's sensors like: engine RPM, voltage, temperatures, throttle.\n\nIn the transportation industry, telemetry provides meaningful information about a vehicle or driver's performance by collecting data from sensors within the vehicle. This is undertaken for various reasons ranging from staff compliance monitoring, insurance rating to predictive maintenance.\n\nTelemetry is also used to link traffic counter devices to data recorders to measure traffic flows and vehicle lengths and weights.\n\nMost activities related to healthy crops and good yields depend on timely availability of weather and soil data. Therefore, wireless weather stations play a major role in disease prevention and precision irrigation. These stations transmit parameters necessary for decision-making to a base station: air temperature and relative humidity, precipitation and leaf wetness (for disease prediction models), solar radiation and wind speed (to calculate evapotranspiration), water deficit stress (WDS) leaf sensors and soil moisture (crucial to irrigation decisions).\n\nBecause local micro-climates can vary significantly, such data needs to come from within the crop. Monitoring stations usually transmit data back by terrestrial radio, although occasionally satellite systems are used. Solar power is often employed to make the station independent of the power grid.\n\nTelemetry is important in water management, including water quality and stream gauging functions. Major applications include AMR (automatic meter reading), groundwater monitoring, leak detection in distribution pipelines and equipment surveillance. Having data available in almost real time allows quick reactions to events in the field. Telemetry control allows engineers to intervene with assets such as pumps and by remotely switching pumps on or off depending on the circumstances. Watershed telemetry is an excellent strategy of how to implement a water management system.\nTelemetry is used in complex systems such as missiles, RPVs, spacecraft, oil rigs, and chemical plants since it allows the automatic monitoring, alerting, and record-keeping necessary for efficient and safe operation. Space agencies such as NASA, ISRO, the European Space Agency (ESA), and other agencies use telemetry and/or telecommand systems to collect data from spacecraft and satellites.\n\nTelemetry is vital in the development of missiles, satellites and aircraft because the system might be destroyed during or after the test. Engineers need critical system parameters to analyze (and improve) the performance of the system. In the absence of telemetry, this data would often be unavailable.\n\nTelemetry is used by manned or unmanned spacecraft for data transmission. Distances of more than 10 billion kilometres have been covered, e.g., by Voyager 1.\n\nIn rocketry, telemetry equipment forms an integral part of the rocket range assets used to monitor the position and health of a launch vehicle to determine range safety flight termination criteria (Range purpose is for public safety). Problems include the extreme environment (temperature, acceleration and vibration), the energy supply, antenna alignment and (at long distances, e.g., in spaceflight) signal travel time.\n\nToday nearly every type of aircraft, missiles, or spacecraft carries a wireless telemetry system as it is tested. Aeronautical mobile telemetry is used for the safety of the pilots and persons on the ground during flight tests. Telemetry from an on-board flight test instrumentation system is the primary source of real-time measurement and status information transmitted during the testing of manned and unmanned aircraft.\n\nIntercepted telemetry was an important source of intelligence for the United States and UK when Soviet missiles were tested; for this purpose, the United States operated a listening post in Iran. Eventually, the Russians discovered the United States intelligence-gathering network and encrypted their missile-test telemetry signals. Telemetry was also a source for the Soviets, who operated listening ships in Cardigan Bay to eavesdrop on UK missile tests performed in the area.\n\nIn factories, buildings and houses, energy consumption of systems such as HVAC are monitored at multiple locations; related parameters (e.g., temperature) are sent via wireless telemetry to a central location. The information is collected and processed, enabling the most efficient use of energy. Such systems also facilitate predictive maintenance.\n\nMany resources need to be distributed over wide areas. Telemetry is useful in these cases, since it allows the logistics system to channel resources where they are needed, as well as provide security for those assets; principal examples of this are dry goods, fluids, and granular bulk solids.\nDry goods, such as packaged merchandise, may be tracked and remotely monitored, tracked and inventoried by RFID sensing systems, barcode reader, optical character recognition (OCR) reader, or other sensing devices -- coupled to telemetry devices, to detect RFID tags, barcode labels or other identifying markers affixed to the item, its package, or (for large items and bulk shipments) affixed to its shipping container or vehicle. This facilitates knowledge of their location, and can record their status and disposition, as when merchandise with barcode labels is scanned through a checkout scanner at point-of-sale systems in a retail store. Stationary or hand-held barcode scanners or RFID scanners, with remote communications, can be used to expedite inventory tracking and counting in stores, warehouses, shipping terminals, transportation carriers and factories.\nFluids stored in tanks are a principal object of constant commercial telemetry. This typically includes monitoring of tank farms in gasoline refineries and chemical plants -- and distributed or remote tanks, which must be replenished when empty (as with gas station storage tanks, home heating oil tanks, or ag-chemical tanks at farms), or emptied when full (as with production from oil wells, accumulated waste products, and newly produced fluids). Telemetry is used to communicate the variable measurements of flow and tank level sensors detecting fluid movements and/or volumes by pneumatic, hydrostatic, or differential pressure; tank-confined ultrasonic, radar or Doppler effect echoes; or mechanical or magnetic sensors.\n\nTelemetry of bulk solids is common for tracking and reporting the volume status and condition of grain and livestock feed bins, powdered or granular food, powders and pellets for manufacturing, sand and gravel, and other granular bulk solids. While technology associated with fluid tank monitoring also applies, in part, to granular bulk solids, reporting of overall container weight, or other gross characteristics and conditions, are sometimes required, owing to bulk solids' more complex and variable physical characteristics.\n\nTelemetry is used for patients (biotelemetry) who are at risk of abnormal heart activity, generally in a coronary care unit. Telemetry specialists are sometimes used to monitor many patients with a hospital. Such patients are outfitted with measuring, recording and transmitting devices. A data log can be useful in diagnosis of the patient's condition by doctors. An alerting function can alert nurses if the patient is suffering from an acute (or dangerous) condition.\n\nSystems are available in medical-surgical nursing for monitoring to rule out a heart condition, or to monitor a response to antiarrhythmic medications such as amiodarone.\n\nA new and emerging application for telemetry is in the field of neurophysiology, or neurotelemetry. Neurophysiology is the study of the central and peripheral nervous systems through the recording of bioelectrical activity, whether spontaneous or stimulated. In neurotelemetry (NT) the electroencephalogram (EEG) of a patient is monitored remotely by a registered EEG technologist using advanced communication software. The goal of neurotelemetry is to recognize a decline in a patient's condition before physical signs and symptoms are present.\n\nNeurotelemetry is synonymous with real-time continuous video EEG monitoring and has application in the epilepsy monitoring unit, neuro ICU, pediatric ICU and newborn ICU. Due to the labor-intensive nature of continuous EEG monitoring NT is typically done in the larger academic teaching hospitals using in-house programs that include R.EEG Technologists, IT support staff, neurologist and neurophysiologist and monitoring support personnel.\n\nModern microprocessor speeds, software algorithms and video data compression allow hospitals to centrally record and monitor continuous digital EEGs of multiple critically ill patients simultaneously.\n\nNeurotelemetry and continuous EEG monitoring provides dynamic information about brain function that permits early detection of changes in neurologic status, which is especially useful when the clinical examination is limited.\n\nTelemetry is used to study wildlife, and has been useful for monitoring threatened species at the individual level. Animals under study can be outfitted with instrumentation tags, which include sensors that measure temperature, diving depth and duration (for marine animals), speed and location (using GPS or Argos packages). Telemetry tags can give researchers information about animal behavior, functions, and their environment. This information is then either stored (with archival tags) or the tags can send (or transmit) their information to a satellite or handheld receiving device. Capturing and marking wild animals can put them at some risk, so it is important to minimize these impacts.\n\nAt a 2005 workshop in Las Vegas, a seminar noted the introduction of telemetry equipment which would allow vending machines to communicate sales and inventory data to a route truck or to a headquarters. This data could be used for a variety of purposes, such as eliminating the need for drivers to make a first trip to see which items needed to be restocked before delivering the inventory.\n\nRetailers also use RFID tags to track inventory and prevent shoplifting. Most of these tags passively respond to RFID readers (e.g., at the cashier), but active RFID tags are available which periodically transmit location information to a base station.\n\nTelemetry hardware is useful for tracking persons and property in law enforcement. An ankle collar worn by convicts on probation can warn authorities if a person violates the terms of his or her parole, such as by straying from authorized boundaries or visiting an unauthorized location. Telemetry has also enabled bait cars, where law enforcement can rig a car with cameras and tracking equipment and leave it somewhere they expect it to be stolen. When stolen the telemetry equipment reports the location of the vehicle, enabling law enforcement to deactivate the engine and lock the doors when it is stopped by responding officers.\n\nIn some countries, telemetry is used to measure the amount of electrical energy consumed. The electricity meter communicates with a concentrator, and the latter sends the information through GPRS or GSM to the energy provider's server. Telemetry is also used for the remote monitoring of substations and their equipment. For data transmission, phase line carrier systems operating on frequencies between 30 and 400 kHz are sometimes used.\n\nIn falconry, \"telemetry\" means a small radio transmitter carried by a bird of prey that will allow the bird's owner to track it when it is out of sight.\n\nTelemetry is used in testing hostile environments which are dangerous to humans. Examples include munitions storage facilities, radioactive sites, volcanoes, deep sea, and outer space.\n\nTelemetry is used in many battery operated wireless systems to inform monitoring personnel when the battery power is reaching a low point and the end item needs fresh batteries.\n\nIn the mining industry, telemetry serves two main purposes: the measurement of key parameters from mining equipment and the monitoring of safety practices. The information provided by the collection and analysis of key parameters allows for root-cause identification of inefficient operations, unsafe practices and incorrect equipment usage for maximizing productivity and safety. Further applications of the technology allow for sharing knowledge and best practices across the organization.\n\nIn software, telemetry is used to gather data on the use and performance of applications and application components, e.g. how often certain features are used, measurements of start-up time and processing time, hardware, application crashes, and general usage statistics and/or user behavior. In some cases, very detailed data is reported like individual window metrics, counts of used features, and individual function timings.\n\nThis kind of telemetry can be essential to software developers to receive data from a wide variety of endpoints that can't possibly all be tested in-house, as well as getting data on the popularity of certain features and whether they should be given priority or be considered for removal. Due to concerns about privacy since software telemetry can easily be used to profile users, telemetry in user software is often user choice, commonly presented as an opt-in feature (requiring explicit user action to enable it) or user choice during the software installation process.\n\nSee also: Phoning home\n\nAs in other telecommunications fields, international standards exist for telemetry equipment and software. International standards producing bodies include Consultative Committee for Space Data Systems (CCSDS) for space agencies, Inter-Range Instrumentation Group (IRIG) for missile ranges, and Telemetering Standards Coordination Committee (TSCC), an organisation of the International Foundation for Telemetering.\n\n", "related": "\n- Instrumentation\n- Machine to Machine (M2M)\n- MQ Telemetry Transport (MQTT)\n- Portable telemetry\n- Reconnaissance satellite, tapping of communications routing or switching centers (e.g., Echelon)\n- Remote monitoring and control\n- Remote sensing\n- Remote Terminal Unit (RTU)\n- SBMV Protocol\n- SCADA\n- Telecommand\n- Telematics\n- Wireless sensor network\n\n- International Foundation for Telemetering\n- IRIG 106 — Digital telemetry standard\n- The European Society of Telemetering\n"}
{"id": "41831", "url": "https://en.wikipedia.org/wiki?curid=41831", "title": "Telephony", "text": "Telephony\n\nTelephony ( ) is the field of technology involving the development, application, and deployment of telecommunication services for the purpose of electronic transmission of voice, fax, or data, between distant parties. The history of telephony is intimately linked to the invention and development of the telephone.\n\nTelephony is commonly referred to as the construction or operation of telephones and telephonic systems and as a system of telecommunications in which telephonic equipment is employed in the transmission of speech or other sound between points, with or without the use of wires. The term is also used frequently to refer to computer hardware, software, and computer network systems, that perform functions traditionally performed by telephone equipment. In this context the technology is specifically referred to as Internet telephony, or voice over Internet Protocol (VoIP).\n\nThe first telephones were connected directly in pairs. Each user had a separate telephone wired to each locations to be reached. This quickly became inconvenient and unmanageable when users wanted to communicate with more than a few people. The invention of the telephone exchange provided the solution for establishing telephone connections with any other telephone in service in the local area. Each telephone was connected to the exchange at first with one wire, later one wire pair, the local loop. Nearby exchanges in other service areas were connected with trunk lines, and long-distance service could be established by relaying the calls through multiple exchanges.\n\nInitially, exchange switchboards were manually operated by an attendant, commonly referred to as the \"switchboard operator\". When a customer cranked a handle on the telephone, it activated an indicator on the board in front of the operator, who would in response plug the operator headset into that jack and offer service. The caller had to ask for the called party by name, later by number, and the operator connected one end of a circuit into the called party jack to alert them. If the called station answered, the operator disconnected their headset and completed the station-to-station circuit. Trunk calls were made with the assistance of other operators at other exchangers in the network.\n\nUntil the 1970s, most telephones were permanently wired to the telephone line installed at customer premises. Later, conversion to installation of jacks that terminated the inside wiring permitted simple exchange of telephone sets with telephone plugs and allowed portability of the set to multiple locations in the premises where jacks were installed. The inside wiring to all jacks was connected in one place to the wire drop which connects the building to a cable. Cables usually bring a large number of drop wires from all over a district access network to one wire center or telephone exchange. When a telephone user wants to make a telephone call, equipment at the exchange examines the dialed telephone number and connects that telephone line to another in the same wire center, or to a trunk to a distant exchange. Most of the exchanges in the world are interconnected through a system of larger switching systems, forming the public switched telephone network (PSTN).\n\nIn the second half of the 20th century, fax and data became important secondary applications of the network created to carry voices, and late in the century, parts of the network were upgraded with ISDN and DSL to improve handling of such traffic.\n\nToday, telephony uses digital technology (digital telephony) in the provisioning of telephone services and systems. Telephone calls can be provided digitally, but may be restricted to cases in which the last mile is digital, or where the conversion between digital and analog signals takes place inside the telephone. This advancement has reduced costs in communication, and improved the quality of voice services. The first implementation of this, ISDN, permitted all data transport from end-to-end speedily over telephone lines. This service was later made much less important due to the ability to provide digital services based on the IP protocol.\n\nSince the advent of personal computer technology in the 1980s, computer telephony integration (CTI) has progressively provided more sophisticated telephony services, initiated and controlled by the computer, such as making and receiving voice, fax, and data calls with telephone directory services and caller identification. The integration of telephony software and computer systems is a major development in the evolution of office automation. The term is used in describing the computerized services of call centers, such as those that direct your phone call to the right department at a business you're calling. It's also sometimes used for the ability to use your personal computer to initiate and manage phone calls (in which case you can think of your computer as your personal call center). CTI is not a new concept and has been used in the past in large telephone networks, but only dedicated call centers could justify the costs of the required equipment installation. Primary telephone service providers are offering information services such as automatic number identification, which is a telephone service architecture that separates CTI services from call switching and will make it easier to add new services. Dialed Number Identification Service (DNIS) on a scale is wide enough for its implementation to bring real value to business or residential telephone usage. A new generation of applications (middleware) is being developed as a result of standardization and availability of low cost computer telephony links.\n\nDigital telephony is the use of digital electronics in the operation and provisioning of telephony systems and services. Since the late 20th century, a digital core network has replaced the traditional analog transmission and signaling systems, and much of the access network has also been digitized.\n\nStarting with the development of transistor technology, originating from Bell Telephone Laboratories in 1947, to amplification and switching circuits in the 1950s, the public switched telephone network (PSTN) has gradually moved towards solid-state electronics and automation. Following the development of computer-based electronic switching systems incorporating metal–oxide–semiconductor (MOS) and pulse-code modulation (PCM) technologies, the PSTN gradually evolved towards the digitization of signaling and audio transmissions. Digital telephony has since dramatically improved the capacity, quality and cost of the network. Digitization allows wideband voice on the same channel, with improved quality of a wider analog voice channel.\n\nThe earliest end-to-end analog telephone networks to be modified and upgraded to transmission networks with Digital Signal 1 (DS1/T1) carrier systems date back to the early 1960s. They were designed to support the basic 3 kHz voice channel by sampling the bandwidth-limited analog voice signal and encoding using pulse-code modulation (PCM). Early PCM codec-filters were implemented as passive resistorcapacitorinductor filter circuits, with analog-to-digital conversion (for digitizing voices) and digital-to-analog conversion (for reconstructing voices) handled by discrete devices. Early digital telephony was impractical due to the low performance and high costs of early PCM codec-filters.\n\nPractical digital telecommunication was enabled by the invention of the metal–oxide–semiconductor field-effect transistor (MOSFET), which led to the rapid development and wide adoption of PCM digital telephony. The MOSFET was invented by Mohamed M. Atalla and Dawon Kahng at Bell Telephone Laboratories in 1959, and the metal–oxide–semiconductor (MOS) integrated circuit (IC) chip was proposed soon after, but MOS technology was initially overlooked by Bell because they did not find it practical for analog telephone applications, before it was commercialized by Fairchild and RCA for digital electronics such as computers. MOS technology eventually became practical for telephone applications with the MOS mixed-signal integrated circuit, which combines analog and digital signal processing on a single chip, developed by former Bell engineer David A. Hodges with Paul R. Gray at UC Berkeley in the early 1970s. In 1974, Hodges and Gray worked with R.E. Suarez to develop MOS switched capacitor (SC) circuit technology, which they used to develop a digital-to-analog converter (DAC) chip, using MOS capacitors and MOSFET switches for data conversion. MOS analog-to-digital converter (ADC) and DAC chips were commercialized by 1974.\n\nMOS SC circuits led to the development of PCM codec-filter chips in the late 1970s. The silicon-gate CMOS (complementary MOS) PCM codec-filter chip, developed by Hodges and W.C. Black in 1980, has since been the industry standard for digital telephony. By the 1990s, telecommunication networks such as the public switched telephone network (PSTN) had been largely digitized with very-large-scale integration (VLSI) CMOS PCM codec-filters, widely used in electronic switching systems for telephone exchanges, private branch exchanges (PBX) and key telephone systems (KTS); user-end modems; data transmission applications such as digital loop carriers, pair gain multiplexers, telephone loop extenders, integrated services digital network (ISDN) terminals, digital cordless telephones and digital cell phones; and applications such as speech recognition equipment, voice data storage, voice mail and digital tapeless answering machines. The bandwidth of digital telecommunication networks has been rapidly increasing at an exponential rate, as observed by Edholm's law, largely driven by the rapid scaling and miniaturization of MOS technology.\n\nUncompressed PCM digital audio with 8-bit depth and 8kHz sample rate requires a bit rate of 64kbps, which was impractical for early digital telecommunication networks with limited network bandwidth. A solution to this issue was linear predictive coding (LPC), a speech coding data compression algorithm that was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966. LPC was capable of audio data compression down to 2.4kbps, leading to the first successful real-time conversations over digital networks in the 1970s. LPC has since been the most widely used speech coding method. Another audio data compression method, a discrete cosine transform (DCT) algorithm called the modified discrete cosine transform (MDCT), has been widely adopted for speech coding in voice-over-IP (VoIP) applications since the late 1990s.\n\nThe development of transmission methods such as SONET and fiber optic transmission further advanced digital transmission. Although analog carrier systems existed that multiplexed multiple analog voice channels onto a single transmission medium, digital transmission allowed lower cost and more channels multiplexed on the transmission medium. Today the end instrument often remains analog but the analog signals are typically converted to digital signals at the serving area interface (SAI), central office (CO), or other aggregation point. Digital loop carriers (DLC) and fiber to the x place the digital network ever closer to the customer premises, relegating the analog local loop to legacy status.\n\n- early experiments with pulse code modulation (PCM) in telephony\n- the 8-bit, 8 kHz standard is developed; Nyquist's theorem and the standard 3.5 kHz telephony bandwidth\n- DS0 as the basic digital telephony bitstream standard\n- non-linear quantization: A-law vs. μ-law, and transcoding between the two\n- bit error rate and intelligibility\n- development of metal–oxide–semiconductor (MOS) switched capacitor (SC) circuits and complementary MOS (CMOS) PCM codec-filter chips\n- development of speech coding data compression, particularly linear predictive coding (LPC) and modified discrete cosine transform (MDCT) algorithms\n- first practical digital telephone systems put into service\n- the U.S. T-carrier system and the European E-carrier system developed to carry digital telephony\n- introduction of space-time switching in fully digital electronic switching systems\n- replacement of tone signaling with digital signaling for trunks\n- in-band signaling vs. out-of-band signaling\n- the problem of bit-robbing\n- development of Signalling System No. 7 (SS7)\n- rapidly increasing network bandwidth of digital telecommunication networks (Edholm's law), largely driven by scaling and miniaturization of MOSFET (MOS transistor) technology\n- emergence of fiber optic networking allows greater reliability and call capacity\n- transition from plesiochronous transmission to synchronous systems like SONET/SDH\n- advances in wireless radio-frequency technology, particularly the development of MOSFET (power MOSFET and LDMOS) RF power amplifiers and RF CMOS circuits\n- optical self-healing ring networks further increase reliability\n- digital/optical systems revolutionize international long-distance networks, particularly undersea cables\n- digital telephone exchanges eliminate moving parts, make exchange equipment much smaller and more reliable\n- separation of exchange and concentrator functions\n- roll-out of digital systems throughout the PSTN\n- provision of intelligent network services\n- speech compression on international digital trunks\n- phone tapping in the digital environment\n- introduction of digital mobile telephony, specialized compression algorithms for high bit error rates\n- direct digital termination to customers via ISDN; PRI catches on, BRI mostly does not, except in Germany\n- the effects of digital telephony, and digital termination at the ISP, on modem performance\n- voice over IP as a carrier strategy\n- emergence of ADSL leads to voice over IP becoming a consumer product, and the slow demise of dial-up Internet access\n- expected convergence of VoIP, mobile telephony, etc.\n- flattening of telephony tariffs, increasing moves towards flat rate pricing as the marginal cost of telephony drops further and further.\n\nThe field of technology available for telephony has broadened with the advent of new communication technologies. Telephony now includes the technologies of Internet services and mobile communication, including video conferencing.\n\nThe new technologies based on Internet Protocol (IP) concepts are often referred to separately as voice over IP (VoIP) telephony, also commonly referred to as IP telephony or Internet telephony. Unlike traditional phone service, IP telephony service is relatively unregulated by government. In the United States, the Federal Communications Commission (FCC) regulates phone-to-phone connections, but says they do not plan to regulate connections between a phone user and an IP telephony service provider.\n\nA specialization of digital telephony, Internet Protocol (IP) telephony involves the application of digital networking technology that was the foundation to the Internet to create, transmit, and receive telecommunications sessions over computer networks. Internet telephony is commonly known as voice over Internet Protocol (VoIP), reflecting the principle, but it has been referred with many other terms. VoIP has proven to be a disruptive technology that is rapidly replacing traditional telephone infrastructure technologies. As of January 2005, up to 10% of telephone subscribers in Japan and South Korea have switched to this digital telephone service. A January 2005 \"Newsweek\" article suggested that Internet telephony may be \"the next big thing\". As of 2006, many VoIP companies offer service to consumers and businesses.\n\nIP telephony uses an Internet connection and hardware IP phones, analog telephone adapters, or softphone computer applications to transmit conversations encoded as data packets. In addition to replacing plain old telephone service (POTS), IP telephony services compete with mobile phone services by offering free or lower cost connections via WiFi hotspots. VoIP is also used on private networks which may or may not have a connection to the global telephone network.\n\nDirect person-to-person communication includes non-verbal cues expressed in facial and other bodily articulation, that cannot be transmitted in traditional voice telephony. Video telephony restores such interactions to varying degrees. Social Context Cues Theory is a model to measure the success of different types of communication in maintaining the non-verbal cues present in face-to-face interactions. The research examines many different cues, such as the physical context, different facial expressions, body movements, tone of voice, touch and smell.\n\nVarious communication cues are lost with the usage of the telephone. The communicating parties are not able to identify the body movements, and lack touch and smell. Although this diminished ability to identify social cues is well known, Wiesenfeld, Raghuram, and Garud point out that there is a value and efficiency to the type of communication for different tasks. They examine work places in which different types of communication, such as the telephone, are more useful than face-to-face interaction.\n\nThe expansion of communication to mobile telephone service has created a different filter of the social cues than the land-line telephone. The use of instant messaging, such as \"texting\", on mobile telephones has created a sense of community. In \"The Social Construction of Mobile Telephony\" it is suggested that each phone call and text message is more than an attempt to converse. Instead, it is a gesture which maintains the social network between family and friends. Although there is a loss of certain social cues through telephones, mobile phones bring new forms of expression of different cues that are understood by different audiences. New language additives attempt to compensate for the inherent lack of non-physical interaction.\n\nAnother social theory supported through telephony is the Media Dependency Theory. This theory concludes that people use media or a resource to attain certain goals. This theory states that there is a link between the media, audience, and the large social system. Telephones, depending on the person, help attain certain goals like accessing information, keeping in contact with others, sending quick communication, entertainment, etc.\n\n", "related": "\n- List of telephony terminology\n- History of the telephone\n- Invention of the telephone\n"}
{"id": "1536216", "url": "https://en.wikipedia.org/wiki?curid=1536216", "title": "Teletraffic engineering", "text": "Teletraffic engineering\n\nTelecommunications traffic engineering, teletraffic engineering, or traffic engineering is the application of traffic engineering theory to telecommunications. Teletraffic engineers use their knowledge of statistics including queuing theory, the nature of traffic, their practical models, their measurements and simulations to make predictions and to plan telecommunication networks such as a telephone network or the Internet. These tools and knowledge help provide reliable service at lower cost.\n\nThe field was created by the work of A. K. Erlang for circuit-switched networks but is applicable to packet-switched networks, as they both exhibit Markovian properties, and can hence be modeled by e.g. a Poisson arrival process.\n\nThe crucial observation in traffic engineering is that in large systems the law of large numbers can be used to make the aggregate properties of a system over a long period of time much more predictable than the behaviour of individual parts of the system.\n\nThe measurement of traffic in a public switched telephone network (PSTN) allows network operators to determine and maintain the quality of service (QoS) and in particular the grade of service (GoS) that they promise their subscribers. The performance of a network depends on whether all origin-destination pairs are receiving a satisfactory service.\n\nNetworks are handled as:\n- loss systems, where calls that cannot be handled are given equipment busy tone, or\n- queuing systems, where calls that cannot be handled immediately are queued.\n\nCongestion is defined as the situation when exchanges or circuit groups are inundated with calls and are unable to serve all the subscribers. Special attention must be given to ensure that such high loss situations do not arise. To help determine the probability of congestion occurring, operators should use the Erlang formulas or the Engset calculation.\n\nExchanges in the PSTN make use of trunking concepts to help minimize the cost of the equipment to the operator. Modern switches generally have full availability and do not make use of grading concepts.\n\nOverflow systems make use of alternative routing circuit groups or paths to transfer excess traffic and thereby reduce the possibility of congestion.\n\nA very important component in PSTNs is the SS7 network used to route signalling traffic. As a supporting network, it carries all the signalling messages necessary to set up, break down or provide extra services. The signalling enables the PSTN to control the manner in which traffic is routed from one location to another.\n\nTransmission and switching of calls is performed using the principle of time-division multiplexing (TDM). TDM allows multiple calls to be transmitted along the same physical path, reducing the cost of infrastructure.\n\nA good example of the use of teletraffic theory in practice is in the design and management of a call center. Call centers use teletraffic theory to increase the efficiency of their services and overall profitability through calculating how many operators are really needed at each time of the day.\n\nQueueing systems used in call centers have been studied as a science. For example, completed calls are put on hold and queued until they can be served by an operator. If callers are made to wait too long, they may lose patience and default from the queue (hang up), resulting in no service being provided.\n\nTeletraffic Engineering is a well-understood discipline in the traditional voice network, where traffic patterns are established, growth rates can be predicted, and vast amounts of detailed historical data are available for analysis. However, in modern broadband networks, the teletraffic engineering methodologies used for voice networks are inappropriate.\n\nOf great importance is the possibility that extremely infrequent occurrences are more likely than anticipated. This situation is known as long-tail traffic. In some designs, the network might be required to withstand the unanticipated traffic.\n\nAs mentioned in the introduction, the purpose of teletraffic theory is to reduce cost in telecommunications networks. An important tool in achieving this goal is forecasting. Forecasting allows network operators to calculate the potential cost of a new network / service for a given QoS during the planning and design stage, thereby ensuring that costs are kept to a minimum.\n\nAn important method used in forecasting is simulation, which is described as the most common quantitative modelling technique in use today. An important reason for this is that computing power has become far more accessible, making simulation the preferred analytical method for problems that are not easily solved mathematically.\n\nAs in any business environment, network operators must charge tariffs for their services. These charges must be balanced with the supplied QoS. When operators supply services internationally, this is described as trade in services and is governed by the General Agreement on Trade in Services (GATS).\n\n", "related": "\n- Asynchronous transfer mode\n- Busy hour call attempts\n- Cellular traffic\n- Erlang (unit)\n- Flow control (disambiguation)\n- Long-tail traffic\n- Mobile QoS\n- Routing\n- RSVP-TE\n- Traffic mix\n- Traffic generation model\n- Traffic contract\n- Traffic shaping\n\n- \"Deploying IP and MPLS QoS for Multiservice Networks: Theory and Practice\" by John Evans, Clarence Filsfils (Morgan Kaufmann, 2007, )\n- V. B. Iversen, Teletraffic Engineering handbook, ()\n- M. Zukerman, Introduction to Queueing Theory and Stochastic Teletraffic Models, PDF)\n"}
{"id": "2133133", "url": "https://en.wikipedia.org/wiki?curid=2133133", "title": "Visible light communication", "text": "Visible light communication\n\nVisible light communication (VLC) is a data communications variant which uses visible light between 400 and 800 THz (780–375 nm). VLC is a subset of optical wireless communications technologies.\n\nThe technology uses fluorescent lamps (ordinary lamps, not special communications devices) to transmit signals at 10 kbit/s, or LEDs for up to 500 Mbit/s over short distances. Systems such as RONJA can transmit at full Ethernet speed (10 Mbit/s) over distances of .\n\nSpecially designed electronic devices generally containing a photodiode receive signals from light sources, although in some cases a cell phone camera or a digital camera will be sufficient. The image sensor used in these devices is in fact an array of photodiodes (pixels) and in some applications its use may be preferred over a single photodiode. Such a sensor may provide either multi-channel (down to 1 pixel = 1 channel) or a spatial awareness of multiple light sources.\n\nVLC can be used as a communications medium for ubiquitous computing, because light-producing devices (such as indoor/outdoor lamps, TVs, traffic signs, commercial displays and car headlights/taillights) are used everywhere. \n\nThe history of visible light communications (VLC) dates back to the 1880s in Washington, D.C. when the Scottish-born scientist Alexander Graham Bell invented the photophone, which transmitted speech on modulated sunlight over several hundred meters. This pre-dates the transmission of speech by radio.\n\nMore recent work began in 2003 at Nakagawa Laboratory, in Keio University, Japan, using LEDs to transmit data by visible light. Since then there have been numerous research activities focussed on VLC.\n\nIn 2006, researchers from CICTR at Penn State proposed a combination of power line communication (PLC) and white light LED to provide broadband access for indoor applications. This research suggested that VLC could be deployed as a perfect last-mile solution in the future.\n\nIn January 2010 a team of researchers from Siemens and Fraunhofer Institute for Telecommunications, Heinrich Hertz Institute in Berlin demonstrated transmission at 500 Mbit/s with a white LED over a distance of , and 100 Mbit/s over longer distance using five LEDs.\n\nThe VLC standardization process is conducted within the working group.\n\nIn December 2010 St. Cloud, Minnesota, signed a contract with LVX Minnesota and became the first to commercially deploy this technology.\n\nIn July 2011 a presentation at TED Global. gave a live demonstration of high-definition video being transmitted from a standard LED lamp, and proposed the term Li-Fi to refer to a subset of VLC technology.\n\nRecently, VLC-based indoor positioning systems have become an attractive topic. ABI research forecasts that it could be a key solution to unlocking the $5 billion \"indoor location market\". Publications have been coming from Nakagawa Laboratory, ByteLight filed a patent on a light positioning system using LED digital pulse recognition in March 2012. COWA at Penn State and other researchers around the world.\n\nAnother recent application is in the world of toys, thanks to cost-efficient and low-complexity implementation, which only requires one microcontroller and one LED as optical front-end.\n\nVLCs can be used for providing security. They are especially useful in body sensor networks and personal area networks.\n\nRecently Organic LEDs (OLED) have been used as optical transceivers to build up VLC communication links up to 10 Mbit/s.\n\nIn October 2014, Axrtek launched a commercial bidirectional RGB LED VLC system called MOMO that transmits down and up at speeds of 300 Mbit/s and with a range of 25 feet.\n\nIn May 2015, Philips collaborated with supermarket company Carrefour to deliver VLC location-based services to shoppers' smartphones in a hypermarket in Lille, France. In June 2015, two Chinese companies, Kuang-Chi and Ping An Bank, partnered to introduce a payment card that communicates information through a unique visible light. \nIn March 2017, Philips set up the first VLC location-based services to shoppers' smartphones in Germany. The installation was presented at EuroShop in Düsseldorf (March 5 – 9 th). As first supermarket in Germany an Edeka supermarket in Düsseldorf-Bilk is using the system, which offers a 30 centimeter positioning accuracy can be achieved, which meets the special demands in food retail. Indoor positioning systems based on VLC can be used in places such as hospitals, eldercare homes, warehouses, and large, open offices to locate people and control indoor robotic vehicles.\n\nThere is wireless network that for data transmission uses visible light, and does not use intensity modulation of optical sources. The idea is to use vibration generator instead of optical sources for data transmission.\n\nColor shift keying (CSK), outlined in IEEE 802.15.7, is an intensity modulation based modulation scheme for VLC. CSK is intensity-based, as the modulated signal takes on an instantaneous color equal to the physical sum of three (red/green/blue) LED instantaneous intensities. This modulated signal jumps instantaneously, from symbol to symbol, across different visible colors; hence, CSK can be construed as a form of frequency shifting. However, this instantaneous variation in the transmitted color is not to be humanly perceptible, because of the limited temporal sensitivity in the human vision — the \"critical flicker fusion threshold\" (CFF) and the \"critical color fusion threshold\" (CCF), both of which cannot resolve temporal changes shorter than 0.01 second. The LEDs’ transmissions are, therefore, preset to time-average (over the CFF and the CCF) to a specific time-constant color. Humans can thus perceive only this preset color that seems constant over time, but cannot perceive the instantaneous color that varies rapidly in time. In other words, CSK transmission maintains a constant time-averaged luminous flux, even as its symbol sequence varies rapidly in chromaticity.\n\n", "related": "\n- Electric beacon\n- Fiber-optic communication\n- Free space optics\n- Free-space optical communication\n- IrDA—Same principle as VLC but uses infrared light instead of visible light\n- Li-Fi\n- Optical wireless communications\n- RONJA\n\n- David G. Aviv (2006): Laser Space Communications, ARTECH HOUSE. .\n\n- IEEE 802.15 WPAN Task Group 7 (TG7) Visible Light Communication\n"}
{"id": "37188939", "url": "https://en.wikipedia.org/wiki?curid=37188939", "title": "ITAD Subscriber Numbers", "text": "ITAD Subscriber Numbers\n\nITAD Subscriber Numbers, or ISNs, provide a way of interconnecting VOIP PBXs by adding a number to the internal phone number of the target phone. The ITAD number is added to the target phone number preceded by an asterisk. Therefore, only numbers and symbols which appear on a telephone keypad are used.\n", "related": "NONE"}
{"id": "37455194", "url": "https://en.wikipedia.org/wiki?curid=37455194", "title": "Wireless failover", "text": "Wireless failover\n\nWireless failover is an automated function in telephone networks and computer networks where a standard hardwired connection is switched to a redundant wireless connection upon failure or irregular closure of a default hardwired connection or component in the network such as a router, server, or computer. \n\nWireless failover is a business continuity function. That is, it allows businesses to continue operations even in the event of a network failure. In retail, wireless failover is typically used when a standard connection for a point of sale credit card machine fails. In this instance, the wireless failover allows business transactions to continue to be processed, ensuring business continuity.\n\nWireless failover solutions are offered in different forms. A radio may be installed into the network. Examples of this may include a 3G or 4G network connection. Additionally, 3G or 4G network cards may be used. Also, a router may be used with an Ethernet connection.\n", "related": "NONE"}
{"id": "37707058", "url": "https://en.wikipedia.org/wiki?curid=37707058", "title": "Phone bundle", "text": "Phone bundle\n\nPhone bundles are \"turn key\" products offered by various telecommunications companies. These products are \"bundled\" in that they include VoIP phones, internet, and in some cases television service.\n\nPhone bundles were created in a response to a demand from both the consumer and the small and medium businesses markets. These markets demanded a package which would include phone and internet communication hardware in one package which would be a turn key solution.\n\n- AT&T\n- Charter\n- Comcast\n- Century Link\n- Time Warner Cable\n- Verizon\n- Windstream\n\n- AT&T\n- BullsEye Telecom\n- Charter Communications\n- Comcast\n- Granite Telecom\n- Time Warner Cable\n- Verizon\n- Windstream\n\nAdvocates of phone bundles is that several services are being offered by one provider. This generally saves time, money, and streamlines the installation process.\n", "related": "NONE"}
{"id": "38108415", "url": "https://en.wikipedia.org/wiki?curid=38108415", "title": "FreePBX Distro", "text": "FreePBX Distro\n\nThe FreePBX Distro is a freeware unified communications software system that consists of a graphical user interface (GUI) for configuring, controlling, and managing Asterisk PBX software. The FreePBX Distro includes packages that offer VoIP, PBX, Fax,IVR, voice-mail and email functions.\n\nThe FreePBX Distro Linux distribution is based on CentOS, which maintains binary compatibility with Red Hat Enterprise Linux. FreePBX has contributed to the popularity of Asterisk.\n\nThe Official FreePBX Distro is installed from a CD-ROM image available by web download, that includes the system CentOS, Asterisk, FreePBX GUI and assorted dependencies.\n\nThe FreePBX Distro has built in support for cards from multiple vendors, including Digium, OpenVox, Alto, Rhino Equipment, Xorcom and Sangoma.\n\nThe FreePBX Distro supports a large number of phone models via open-source modules.\n\nFreePBX made its debut in 2004 as the AMP project (Asterisk Management Portal). The FreePBX Distro was released in 2011 as an All-In-One solution for building a PBX using Asterisk, CentOS and FreePBX.\n\nFreePBX has over 1 million active production PBXs and over 20,000 new systems added each month. Supported PBX phone manufacturers include Aastra Technologies, Algo, AND, Audiocodes, Cisco Systems, Cyberdata, Digium, Grandstream, Mitel, Panasonic, Polycom, Sangoma, Snom, Xorcom and Yealink.\n\nThe core telephony engine is Asterisk (PBX), as configured by the Open Source FreePBX GUI .\n\nThe version numbering system summarizes the versions of core components of the FreePBX Distro. As an example, the \"FreePBX Distro 2.210.62-1\" version string has the following components. The first number (2) represents the major track number. This second number (210) refers to \"FreePBX 2.10\" GUI. The third number (62) refers to \"CentOS 6.2\", and the final number (1) is used as the minor release revision of this major track number.\n\nThe latest stable release is FreePBX Distro Stable SNG7-PBX-64bit-1805-1 based on these main components:\n- FreePBX 14\n- CentOS 7.5\n- Asterisk 13 or 15\nShell update scripts for each major release track are available on wiki.freepbx.org.\n\n- FreePBX Project Home\n", "related": "NONE"}
{"id": "2889864", "url": "https://en.wikipedia.org/wiki?curid=2889864", "title": "Interference (communication)", "text": "Interference (communication)\n\nIn telecommunications, an interference is that which modifies a signal in a disruptive manner, as it travels along a communication channel between its source and receiver. The term is often used to refer to the addition of unwanted signals to a useful signal. Common examples are:\n\n- Electromagnetic interference (EMI)\n- Co-channel interference (CCI), also known as crosstalk\n- Adjacent-channel interference (ACI)\n- Intersymbol interference (ISI)\n- Inter-carrier interference (ICI), caused by doppler shift in OFDM modulation (multitone modulation).\n- Common-mode interference (CMI)\n- Conducted interference\n\nInterference is typically but not always distinguished from noise, for example white thermal noise.\n\nRadio resource management aims at reducing and controlling the co-channel and adjacent-channel interference.\n\nA solution to interference problems in wireless communication networks is interference alignment, which was discovered by Syed Ali Jafar at the University of California, Irvine. Specialized applications were previously studied by Yitzhak Birk and Tomer Kol for an index coding problem in 1998, and then by Mohammad Ali Maddah-Ali and Abolfazl S. Motahari in the specialized context of the X channel. Interference alignment was eventually established as a general principle by Jafar and Viveck R. Cadambe in 2008, when they introduced \"a mechanism to align an arbitrarily large number of interferers, leading to the surprising conclusion that wireless networks are not essentially interference limited.\" This led to the adoption of interference alignment in the design of wireless networks.\n\nJafar explained:\n\nAccording to New York University senior researcher Paul Horn:\n\n", "related": "\n- Distortion\n- Inter-flow interference\n- Intra-flow interference\n- Meaconing\n- Signal-to-interference ratio (SIR)\n- Signal-to-noise plus interference (SNIR)\n"}
{"id": "39011104", "url": "https://en.wikipedia.org/wiki?curid=39011104", "title": "Water-pouring algorithm", "text": "Water-pouring algorithm\n\nThe water-pouring algorithm is a technique used in digital communications systems for allocating power among different channels in multicarrier schemes. It was described by R. C. Gallager in 1968 along with the water-pouring theorem which proves its optimality for channels having Additive White Gaussian Noise (AWGN) and intersymbol interference (ISI).\nFor this reason, it is a standard baseline algorithm for various digital communications systems.\n\nThe intuition that gives the algorithm its name is to think of the communication medium as if it was some kind of water container with an uneven bottom. Each of the available channels is then a section of the container having its own depth, given by the reciprocal of the frequency-dependent SNR for the channel.\nTo allocate power, imagine pouring water into this container (the amount depends on the desired maximum average transmit power). After the water level settles, the largest amount of water is in the deepest sections of the container. This implies allocating more power to the channels with the most favourable SNR. Note, however, that the ratio allocation to each channel is not a fixed proportion but varies nonlinearly with the maximum average transmit power.\n", "related": "NONE"}
{"id": "25057013", "url": "https://en.wikipedia.org/wiki?curid=25057013", "title": "Broadcast and Multicast Service", "text": "Broadcast and Multicast Service\n\nBroadcast and Multicast Service (BCMCS) is an interface for providing broadcast and multicast services in 3GPP2 CDMA2000 mobile networks. BCMCS can be used to transfer light video and audio clips or other data to a large group of mobile subscribers in an efficient manner. To do so, BCMCS is a so-called point-to-multipoint service. This means that multiple users receive the same information using the same radio resources. \n\nBCMCS can be used for two different kind of services. Broadcast services in which all users within the broadcasting area can receive the same information and a multicast services in which only users that have subscribed to the service can receive the information \nAlthough BCMCS can be used for mobile TV, it has some limitations in the capacity that can be used for this kind of services within the network. \n\nEBCMCS is an enhanced version of BCMCS. EBCMCS uses a new radio interface based on OFDM to combat problems with echoes (multipath) in the transmission. \n\n", "related": "\n- Multimedia Broadcast Multicast Service (MBMS), a point-to-multipoint service defined for 3GPP systems\n"}
{"id": "1786529", "url": "https://en.wikipedia.org/wiki?curid=1786529", "title": "Network transparency", "text": "Network transparency\n\nNetwork transparency, in its most general sense, refers to the ability of a protocol to transmit data over the network in a manner which is transparent (invisible) to those using the applications that are using the protocol. In this way, users of a particular application may access remote resources in the same manner in which they would access their own local resources. An example of this is cloud storage, where remote files are presented as being locally accessible, and cloud computing where the resource in question is processing.\n\nThe term is often partially correctly applied in the context of the X Window System, which is able to transmit graphical data over the network and integrate it seamlessly with applications running and displaying locally; however, certain extensions of the X Window System are not capable of working over the network.\n\nIn a centralized database system, the only available resource that needs to be shielded from the user is the data (that is, the storage system). In a distributed DBMS, a second resource needs to be managed in much the same manner: the network. Preferably, the user should be protected from the network operational details. Then there would be no difference between database applications that would run on the centralized database and those that would run on a distributed one. This kind of transparency is referred to as network transparency or distribution transparency. From a database management system (DBMS) perspective, distribution transparency requires that users do not have to specify where data is located.\n\nSome have separated distribution transparency into location transparency and naming transparency.\n\nLocation transparency in commands used to perform a task is independent both of the locations of the data, and of the system on which an operation is carried out.\n\nNaming transparency means that a unique name is provided for each object in the database.\n\nTransparency in firewall technology can be defined at the networking (IP or Internet layer) or at the application layer.\n\nTransparency at the IP layer means the client targets the real IP address of the server. If a connection is non-transparent, then the client targets an intermediate host (address), which could be a proxy or a caching server. IP layer transparency could be also defined from the point of server's view. If the connection is transparent, the server sees the real client IP. If it is non-transparent, the server sees the IP of the intermediate host.\n\nTransparency at the application layer means the client application uses the protocol in a different way. An example of a transparent HTTP request for a server:\nGET / HTTP/1.1\nHost: example.org\nConnection: Keep-Alive\nAn example non-transparent HTTP request for a proxy (cache):\nGET http://foo.bar/ HTTP/1.1\nProxy-Connection: Keep-Alive\nApplication layer transparency is symmetric when the same working mode is used on both the sides. The transparency is asymmetric when the firewall (usually a proxy) converts server type requests to proxy type or vice versa.\n\nTransparency at the IP layer does not mean automatically application layer transparency.\n\n", "related": "\n- Data independence\n- Replication transparency\n"}
{"id": "41837", "url": "https://en.wikipedia.org/wiki?curid=41837", "title": "Telecommunications link", "text": "Telecommunications link\n\nIn a telecommunications network, a link is a communication channel that connects two or more devices for the purpose of data transmission. The link may be a dedicated physical link or a virtual circuit that uses one or more physical links or shares a physical link with other telecommunications links.\n\nA telecommunications link is generally based on one of several types of information transmission paths such as those provided by communication satellites, terrestrial radio communications infrastructure and computer networks to connect two or more points.\n\nThe term \"link\" is widely used in computer networking to refer to the communications facilities that connect nodes of a network. When the link is a logical link the type of physical link should always be specified (e.g., data link, uplink, downlink, fiber optic link, point-to-point link, etc.)\n\nA point-to-point link is a dedicated link that connects exactly two communication facilities (e.g., two nodes of a network, an intercom station at an entryway with a single internal intercom station, a radio path between two points, etc.).\n\nBroadcast links connect two or more nodes and support \"broadcast transmission\", where one node can transmit so that all other nodes can receive the same transmission. Ethernet is an example.\n\nAlso known as a \"multidrop\" link, a multipoint link is a link that connects \"two or more\" nodes. Also known as general topology networks, these include ATM and Frame Relay links, as well as X.25 networks when used as links for a network layer protocol like IP.\n\nUnlike broadcast links, there is no mechanism to efficiently send a single message to all other nodes without copying and retransmitting the message.\n\nA point-to-multipoint link (or simply a \"multipoint\") is a specific type of multipoint link which consists of a central connection endpoint (CE) that is connected to multiple peripheral CEs. Any transmission of data that originates from the central CE is received by all of the peripheral CEs while any transmission of data that originates from any of the peripheral CEs is only received by the central CE.\n\nLinks are often referred to by terms which refer to the ownership and / or accessibility of the link.\n- A \"private link\" is a link that is either owned by a specific entity or a link that is only accessible by a specific entity.\n- A \"public link\" is a link that uses the public switched telephone network or other public utility or entity to provide the link and which may also be accessible by anyone.\n\n- Pertaining to radiocommunication service, an uplink (UL or U/L) is the portion of a feeder link used for the transmission of signals from an earth station to a space radio station, space radio system or high altitude platform station.\n- Pertaining to GSM and cellular networks, the radio uplink is the transmission path from the mobile station (cell phone) to a base station (cell site). Traffic and signalling flowing within the BSS and NSS may also be identified as uplink and downlink.\n- Pertaining to computer networks, an uplink is a connection from data communications equipment toward the network core. This is also known as an upstream connection.\n\n- Pertaining to radiocommunication service, a downlink (DL or D/L) is the portion of a feeder link used for the transmission of signals from a space radio station, space radio system or high altitude platform station to an earth station.\n- In the context of satellite communications, a downlink (DL) is the link from a satellite to a ground station.\n- Pertaining to cellular networks, the radio downlink is the transmission path from a cell site to the cell phone. Traffic and signalling flowing within the base station subsystem (BSS) and network switching subsystem (NSS) may also be identified as uplink and downlink.\n- Pertaining to computer networks, a downlink is a connection from data communications equipment towards data terminal equipment. This is also known as a downstream connection.\n\nA forward link is the link from a fixed location (e.g., a base station) to a mobile user. If the link includes a communications relay satellite, the forward link will consist of both an uplink (base station to satellite) and a downlink (satellite to mobile user).\n\nThe reverse link (sometimes called a \"return channel\") is the link from a mobile user to a fixed base station.\n\nIf the link includes a communications relay satellite, the reverse link will consist of both an uplink (mobile station to satellite) and a downlink (satellite to base station) which together constitute a half hop.\n\n", "related": "NONE"}
{"id": "41404", "url": "https://en.wikipedia.org/wiki?curid=41404", "title": "Net operation", "text": "Net operation\n\nA radio net is three or more radio stations communicating with each other on a common channel or frequency. A net is essentially a moderated conference call conducted over two-way radio, typically in half-duplex operating conditions. The use of half-duplex operation requires a very particular set of operating procedures to be followed in order to avoid inefficiencies and chaos.\n\nNets operate either on schedule or continuously (continuous watch). Nets operating on schedule handle traffic only at definite, prearranged times and in accordance with a prearranged schedule of intercommunication. Nets operating continuously are prepared to handle traffic at any time; they maintain operators on duty at all stations in the net at all times. When practicable, messages relating to schedules will be transmitted by a means of signal communication other than radio.\n\nNet operations:\n- allow participants to conduct ordered conferences among participants who usually have common information needs or related functions to perform\n- are characterized by adherence to standard formats and procedures, and\n- are responsive to a common supervisory station, called the \"\"net control station\",\" which permits access to the net and maintains net operational discipline.\n\nA net manager is the person who supervises the creation and operation of a net over multiple sessions. This person will specify the format, date, time, participants, and the net control script. The net manager will also choose the Net Control Station for each net, and may occasionally take on that function, especially in smaller organizations.\n\nRadio nets are like conference calls in that both have a moderator who initiates the group communication, who ensures all participants follow the standard procedures, and who determines and directs when each other station may talk. The moderator in a radio net is called the Net Control Station, formally abbreviated NCS, and has the following duties:\n- Establishes the net and closes the net;\n- Directs Net activities, such as passing traffic, to maintain optimum efficiency;\n- Chooses net frequency, maintains circuit discipline and frequency accuracy;\n- Maintains a net log and records participation in the net and movement of messages; (always knows who is on and off net)\n- Appoints one or more Alternate Net Control Stations (ANCS);\n- Determines whether and when to conduct network continuity checks;\n- Determines when full procedure and full call signs may enhance communications;\n- Subject to Net Manager guidance, directs a net to be directed or free.\nThe Net Control Station will, for each net, appoint at least one Alternate Net Control Station, formally abbreviated ANCS (abbreviated NC2 in WWII procedures), who has the following duties:\n- Assists the NCS to maintain optimum efficiency;\n- Assumes NCS duties in event that the NCS develops station problems;\n- Assumes NCS duties for a portion of the net, as directed or as needed;\n- Serves as a resource for the NCS; echoes transmissions of the NCS if, and only if, directed to do so by the NCS;\n- Maintains a duplicate net log\n\nNets can be described as always having a net opening and a net closing, with a roll call normally following the net opening, itself followed by regular net business, which may include announcements, official business, and message passing. Military nets will follow a very abbreviated and opaque version of the structure outlined below, but will still have the critical elements of opening, roll call, late check-ins, and closing.\n\nA net should always operate on the same principle as the inverted pyramid used in journalism—the most important communications always come first, followed by content in ever lower levels of priority.\n1. Net opening\n1. Identification of the NCS\n2. Announcement of the regular date, time, and frequency of the net\n3. Purpose of the net\n2. Roll call\n1. A call for stations to check in, often times from a roster of regular stations\n2. A call for late check-ins (stations on the roster who did not respond to the first check-in period)\n3. A call for guest stations to check in\n3. Net business\n4. Optional conversion to a free net\n5. Net closing\nEach net will typically have a main purpose, which varies according to the organization conducting the net, which occurs during the net business phase. For amateur radio nets, it's typically for the purpose of allowing stations to discuss their recent operating activities (stations worked, antennas built, etc.) or to swap equipment. For Military Auxiliary Radio System and National Traffic System nets, net business will involve mainly the passing of formal messages, known as radiograms.\n\n- Directed Net\n- A net in which no station other than the net control station can communicate with any other station, except for the transmission of urgent messages, without first obtaining the permission of the net control station.\n- Free net\n- A net in which any station may communicate with any other station in the same net without first obtaining permission from the net control station to do so.\n\nU.S. Army Field Manual ACP 125(G) has the most complete set of procedure words used in radio nets:\nMaritime mobile nets serve the needs of seagoing vessels.\n\nThe Civil Air Patrol defines a different set of nets:\nThe International Amateur Radio Union defines six different types of nets in its IARU Emergency Telecommunications Guide:\n\nOther Amateur radio net types\n\nThe U.S. Army Field Manual FM 6-02.53, Tactical Radio Operations, defines the following types of radio nets:\n\nWhen boats or ships are in distress, they will operate a maritime broadcast communications net to communicate among the vessel in distress and all the other vessels, aircraft, and shore stations assisting in the distress response.\n\n", "related": "\n- National Traffic System\n- Amateur radio net\n\n- Air Force MARS Training Manual 2006\n- Air Force MARS National Training Manual 2016\n"}
{"id": "1473483", "url": "https://en.wikipedia.org/wiki?curid=1473483", "title": "Public data network", "text": "Public data network\n\nA public data network (PDN) is a network established and operated by a telecommunications administration, or a recognized private operating agency, for the specific purpose of providing data transmission services for the public. It was the common name given to the international collection of X.25 providers whose combined network had large global coverage during the 1980s and into the 1990s.\n\nIn communications, a PDN is a circuit- or packet-switched network that is available to the public and that can transmit data in digital form. A PDN provider is a company that provides access to a PDN and that provides any of X.25, frame relay, or cell relay (ATM) services. Access to a PDN generally includes a guaranteed bandwidth, known as the committed information rate (CIR). Costs for the access depend on the guaranteed rate. PDN providers differ in how they charge for temporary increases in required bandwidth (known as surges). Some use the amount of overrun; others use the surge duration.\n\nEarly examples include the following experimental/public networks: RETD/Iberpac in Spain; RCP/Transpac in France; Tymnet and Telenet in the United States; EPSS/Packet Switch Stream, in the United Kingdom; EIN/Euronet in the EEC; DATAPAC in Canada; and AUSTPAC in Australia. The International Packet Switched Service was a collaboration between US and UK telecom companies; \n\n", "related": "\n- Public data transmission service\n- Public switched data network\n- National research and education network\n- X.25 § History\n"}
{"id": "2700875", "url": "https://en.wikipedia.org/wiki?curid=2700875", "title": "Cisco Express Forwarding", "text": "Cisco Express Forwarding\n\nCisco Express Forwarding (CEF) is an advanced layer 3 switching technology used mainly in large core networks or the Internet to enhance the overall network performance. Although CEF is a Cisco proprietary protocol other vendors of multi-layer switches or high-capacity routers offer a similar functionality where layer-3 switching or routing is done in hardware (in an ASIC) instead of by software and the (central) CPU.\n\nCEF is mainly used to increase packet switching speed by reducing the overhead and delays introduced by other routing techniques. CEF consists of two key components: The Forwarding Information Base (FIB) and adjacencies.\n\nThe FIB is similar to the routing table generated by multiple routing protocols, maintaining only the next-hop address for a particular IP-route.\n\nThe adjacency table maintains layer 2 or switching information linked to a particular FIB entry, avoiding the need for an Address Resolution Protocol (ARP) request for each table lookup. There are several types of adjacencies. Some are listed below:\n\n- Cache adjacency: This type of entry contains the correct outbound interface and the correct Medium Access Control (MAC) address for its FIB entry. The MAC address is the IP address's MAC address if the destination's subnet is directly connected to the router, or is the MAC address of the router that the packet needs to be sent to if the destination's subnet is not directly connected to the router currently processing the packet.\n- Receive adjacency: This type of entry handles packets whose final destinations include the router itself. This includes packets whose IP addresses are assigned to the router itself, broadcast packets, and multicasts that have set up the router itself as one of the destinations.\n- Null adjacency: Handles packets destined to a NULL interface. Packets with FIB entries pointing to NULL adjacencies will normally be dropped.\n- Punt adjacency: Deals with packets that require special handling or can not be switched by CEF. Such packets are forwarded to the next switching layer (generally fast switching) where they can be forwarded correctly.\n- Glean adjacency: This adjacency is created when the router knows that either the destination IP's subnet is directly connected to the router itself and it does not know that destination device's MAC address, or the router knows the IP address of the router to forward a packet to for a destination, but it does not know that router's MAC address. Packets that trigger this entry will generate an ARP request.\n- Discard adjacency: FIB entries pointing to this type of adjacency will be discarded.\n- Drop adjacency: Packets pointing to this entry are dropped, but the prefix will be checked.\n\nIn order to take full advantage of CEF, it is recommended to use distributed CEF (dCEF), where there is a FIB table on each of the line cards. This avoids the need for querying the main processor or routing table in order to get the next-hop information. Instead, fast switching will be performed on the line card itself.\n\nCEF currently supports Ethernet, Frame Relay, ATM, PPP, FDDI, tunnels, and Cisco HDLC.\n\n- CEF (Cisco Express Forwarding) site (link broken)\n- Choosing the best routing switching path\n", "related": "NONE"}
{"id": "12192262", "url": "https://en.wikipedia.org/wiki?curid=12192262", "title": "Turing switch", "text": "Turing switch\n\nIn theoretical network science, the Turing switch is a logical construction modeling the operation of the network switch, just as in theoretical computer science a Turing machine models the operation of a computer. Both are named in honor of the English logician Alan Turing, although the research in Turing switches is not based on Turing's research. Some introductory research on the Turing switch was started at the University of Cambridge by Jon Crowcroft (Homepage).\n\nIn essence, Crowcroft suggests that instead of using general-purpose computers to do packet switching, the required operations should be reduced to application specific logic and then that application specific logic should be implemented using optical components. The work is not actually based on Turing's research.\n\nA Turing switch consists of a switched fabric, one or more ingress interfaces (also referred to as sources), one or more egress interfaces (sinks), and a decision procedure to determine an egress interface given an ingress interface. Interfaces are sometimes referred to as ports. A packet (cell or switched unit) arrives at an ingress interface, the appropriate egress interface is determined by the decision procedure, and the packet is then transported across the switching fabric to the egress interface. A packet is a symbol or sequence of 1's and 0's. An ingress interface is connected to an ingress line and an egress interface to an egress line. The ingress line is said to feed the ingress interface; the egress interface feeds the egress line.\n\n", "related": "\n- Network switch\n- Software-defined networking\n"}
{"id": "40014290", "url": "https://en.wikipedia.org/wiki?curid=40014290", "title": "Greedy embedding", "text": "Greedy embedding\n\nIn distributed computing and geometric graph theory, greedy embedding is a process of assigning coordinates to the nodes of a telecommunications network in order to allow greedy geographic routing to be used to route messages within the network. Although greedy embedding has been proposed for use in wireless sensor networks, in which the nodes already have positions in physical space, these existing positions may differ from the positions given to them by greedy embedding, which may in some cases be points in a virtual space of a higher dimension, or in a non-Euclidean geometry. In this sense, greedy embedding may be viewed as a form of graph drawing, in which an abstract graph (the communications network) is embedded into a geometric space.\n\nThe idea of performing geographic routing using coordinates in a virtual space, instead of using physical coordinates, is due to Rao et al. Subsequent developments have shown that every network has a greedy embedding with succinct vertex coordinates in the hyperbolic plane, that certain graphs including the polyhedral graphs have greedy embeddings in the Euclidean plane, and that unit disk graphs have greedy embeddings in Euclidean spaces of moderate dimensions with low stretch factors.\n\nIn greedy routing, a message from a source node \"s\" to a destination node \"t\" travels to its destination by a sequence of steps through intermediate nodes, each of which passes the message on to a neighboring node that is closer to \"t\". If the message reaches an intermediate node \"x\" that does not have a neighbor closer to \"t\", then it cannot make progress and the greedy routing process fails. A greedy embedding is an embedding of the given graph with the property that a failure of this type is impossible. Thus, it can be characterized as an embedding of the graph with the property that for every two nodes \"x\" and \"t\", there exists a neighbor \"y\" of \"x\" such that \"d\"(\"x\",\"t\") > \"d\"(\"y\",\"t\"), where \"d\" denotes the distance in the embedded space.\n\nNot every graph has a greedy embedding into the Euclidean plane; a simple counterexample is given by the star \"K\", a tree with one internal node and six leaves. Whenever this graph is embedded into the plane, some two of its leaves must form an angle of 60 degrees or less, from which it follows that at least one of these two leaves does not have a neighbor that is closer to the other leaf.\n\nIn Euclidean spaces of higher dimensions, more graphs may have greedy embeddings; for instance, \"K\" has a greedy embedding into three-dimensional Euclidean space, in which the internal node of the star is at the origin and the leaves are a unit distance away along each coordinate axis. However, for every Euclidean space of fixed dimension, there are graphs that cannot be embedded greedily: whenever the number \"n\" is greater than the kissing number of the space, the graph \"K\" has no greedy embedding.\n\nUnlike the case for the Euclidean plane, every network has a greedy embedding into the hyperbolic plane. The original proof of this result, by Robert Kleinberg, required the node positions to be specified with high precision, but subsequently it was shown that, by using a heavy path decomposition of a spanning tree of the network, it is possible to represent each node succinctly, using only a logarithmic number of bits per point. In contrast, there exist graphs that have greedy embeddings in the Euclidean plane, but for which any such embedding requires a polynomial number of bits for the Cartesian coordinates of each point.\n\nThe class of trees that admit greedy embeddings into the Euclidean plane has been completely characterized, and a greedy embedding of a tree can be found in linear time when it exists.\n\nFor more general graphs, some greedy embedding algorithms such as the one by Kleinberg start by finding a spanning tree of the given graph, and then construct a greedy embedding of the spanning tree. The result is necessarily also a greedy embedding of the whole graph. However, there exist graphs that have a greedy embedding in the Euclidean plane but for which no spanning tree has a greedy embedding.\n\n conjectured that every polyhedral graph (a 3-vertex-connected planar graph, or equivalently by Steinitz's theorem the graph of a convex polyhedron) has a greedy embedding into the Euclidean plane. By exploiting the properties of cactus graphs, proved the conjecture; the greedy embeddings of these graphs can be defined succinctly, with logarithmically many bits per coordinate. However, the greedy embeddings constructed according to this proof are not necessarily planar embeddings, as they may include crossings between pairs of edges. For maximal planar graphs, in which every face is a triangle, a greedy planar embedding can be found by applying the Knaster–Kuratowski–Mazurkiewicz lemma to a weighted version of a straight-line embedding algorithm of Schnyder. The strong Papadimitriou–Ratajczak conjecture, that every polyhedral graph has a planar greedy embedding in which all faces are convex, remains unproven.\n\nThe wireless sensor networks that are the target of greedy embedding algorithms are frequently modeled as unit disk graphs, graphs in which each node is represented as a unit disk and each edge corresponds to a pair of disks with nonempty intersection. For this special class of graphs, it is possible to find succinct greedy embeddings into a Euclidean space of polylogarithmic dimension, with the additional property that distances in the graph are accurately approximated by distances in the embedding, so that the paths followed by greedy routing are short.\n", "related": "NONE"}
{"id": "37943112", "url": "https://en.wikipedia.org/wiki?curid=37943112", "title": "Path protection", "text": "Path protection\n\nPath protection in telecommunications is an end-to-end protection scheme used in connection oriented circuits in different network architectures to protect against inevitable failures on service providers’ network that might affect the services offered to end customers. Any failure occurred at any point along the path of a circuit will cause the end nodes to move/pick the traffic to/from a new route. Finding paths with protection, especially in elastic optical networks, was considered a difficult problem, but an efficient and optimal algorithm was proposed .\n\nOther techniques to protect telecommunications networks against failures are: Channel Protection, Link Protection, Segment-Protection, and P-cycle Protection\n\nIn ring-based networks topology where the setup is to form a closed loop among the Add Drop Multiplexers, there is basically one path related ring protection scheme available in Unidirectional Path-Switched Ring architecture. In SDH networks, the equivalent of UPSR is Sub-Network Connection Protection (SNCP). Note that SNCP does not assume a ring topology, and can also be used in mesh topologies.\n\nIn UPSR, the data is transmitted in both directions, clock and counter clock wise, at the source ADM. At the destination then, both signals are compared and the best one of the two is selected. If a failure occurs then the destination just needs to switch to the unaffected path.\n\nCircuits in optical mesh networks can be unprotected, protected to a single failure, and protected to multiple failures. The end optical switches in protected circuits are in charge of detecting the failure, in some cases requesting digital cross connects or optical cross-connects in intermediate devices, and switching the traffic to/from the backup path. When the primary and backup paths are calculated, it is important that they are at least link diverse so that a single link failure does not affect both of them at the same time. They can also be node diverse, which offers more protection in case a node failure occurs; depending on the network sometimes the primary and backup path cannot be provisioned to be node diverse at the edges, ingress and egress, node.\n\nThere are two types of path protection in Optical Mesh Networks: Dedicated Backup Path Protection and Shared Backup Path Protection\n\nIn DBPP, both the primary and backup path carry the traffic end to end, then it is up to the receiver to decide which of the two incoming traffic it is going to pick; this is exactly the same concept as in Ring Based Path Protection. Since the optics along both paths are already active, DBPP is the fastest protection scheme available, usually in the order of a few tens of milliseconds, because there is no signaling involved in between ingress and egress nodes thus only needing the egress node to detect the failure and switch the traffic over to the unaffected path. Being the fastest protection scheme also makes it the most expensive; normally using more than double of the provisioned capacity for the primary because the backup path is usually longer due to the link and/or node diversity rule of thumb.\n\nThe concept behind this protection scheme is to share a backup channel among different, link/node diverse, primary paths. In other words, one backup channel can be used to protect various primary paths as shown on the figure below where the link between S and T is used to protect both AB and CD primaries. Under normal operations, assuming no failure on the network, the traffic is carried on the primary paths only; the shared backup path is only used when there is a failure in one of those primary paths.\n\nThere are two approaches to provision or reserve backups channels. First, there is the failure dependent assignment or approach also known as restoration in which the backup path is calculated in real time after the failure occurs. This technique is found in early versions of Mesh networks. However, in today’s Optical Mesh Network it can be used as a re-provisioning technique to help recover a second failure when the backup resources are already in use. The down side to restoration as a protection technique is that the recovery time is not fast enough.\n\nThe second approach is to have a predefined backup path computed before the failure. This approach is said to be failure independent and it takes less processing time to recover as compared to the failure dependent approach. Here the backup path is calculated together with the primary at provisioning time. Even though the backup path is calculated, it is not assigned to a specific circuit before a failure occurs; cross connect requests are initiated after the fact on a first-come, first-served basis. Since this approach can only protect from a single failure at a time, if a second primary path fails and at least a portion of its backup path is already in used, this path won't be able to recover unless restoration technique is in place for such cases.\n\nThere is a general down side to both of the above approaches and is that assuming there is a link failure with several paths running through it, each path in that link is going to be recovered individually. This implies that the total time the last path on that link is going to take to be back in service through the secondary path will be the sum of all other previous recovery times plus its own. This could affect the committed SLA (Service Level Agreement) to the customer.\n\nMulti-Protocol Label Switching (MPLS) architecture is described in the RFC-3031. It is a packet-based network technology that provides a framework for recovery through the creation of point to point paths called Label Switched Paths (LSP). These LSPs creation are between a head-end and a tail-end Label Switch Router (LSR). In the former case, the head-end router is the input or ingress router. In the latter case the tail-end represents the output or egress router in the path. \nThere are a few protection techniques for MPLS very similar in the general concept to those for Optical Mesh Networks, such as link protection (e.g., MPLS local protection) and path protection. The path protection schemes for MPLS are as follow:\n\nThis protection scheme is similar in a sense to Ring-based path protection and Dedicated Backup Path Protection (DBPP) schemes described before. Here, same traffic is transmitted over two, link and/or node disjoint, LSPs; primary and backup. The transmission is done by the head-end LSR. The tail-end LSR then receives and compares both traffics; when a failure occurs, the tail-end detects it and switches the traffic to the secondary LSP. As with DBPP in Optical Mesh Network, there is no signaling involved in this protection scheme. This technique is the simplest and fastest of all, but as it reserves and transmits packets on both LSP, it takes away bandwidth that could be shared and used by other LSPs.\n\nIn this protection scheme, a primary and a backup LSP are computed and setup at the provisioning time prior to failures. The backup LSP does not necessarily need to have the same constrain in terms of bandwidth as the primary; it is possible to reserve less bandwidth on the backup LSP and not incur in packet loss when in use. This is because the bandwidth of the link is shared among the different LSPs and the reason why the previous explained protection scheme is not preferred. It is also true that the Backup LSP does not necessarily carry traffic unless the primary LSP fails. When this occurs, a fault indication signal (FIS) is sent back to the head-end LSR that will immediately switch the traffic to the backup LSP. The drawback in this protection scheme is that the longer the LSPs, the longer the recovery time will be because of the travel time of the FIS notification.\n\n", "related": "\n- SONET\n- Add-drop Multiplexer (ADM)\n- Optical Mesh Networks\n- Shortest Path Problem\n- K Shortest Path Routing\n- Link Protection\n- Segment Protection\n- Shared Risk Resource Group\n- MPLS\n- Service Level Agreement\n\n- An Overview of DWDM Networks\n- \"Path Routing in Mesh Optical Networks\", by Eric Bouillet, Georgios Ellinas, Jean-Francois Labourdette, and Ramu Ramamurthy , ,\n- \"Network Recovery: Protection and Restoration of Optical, SONET-SDH, IP, and MPLS\", by Jean-Philippe Vasseur, Mario Pickavet, and Piet Demeester\n- \"Gmpls Technologies: Broadband Backbone Networks and Systems\" by Naoaki Yamanaka, Kohei Shiomoto, and EIJI AUTOR OKI\n- Jean-Philippe Vasseur, Mario Pickavet, and Piet Demeester. Network Recovery, Protection and Restoration of Optical, SONET-SDH, IP, and MPLS. Morgan Kaufmann Publishers, 2004.\n- Addressing Transparency in DWDM mesh survivable networks by Sid Chaudhuri, Eric Bouillet, and Georgios Ellinas\n- Shared Path Protection in DWDM Mesh Networks\n- The Multiple Path Protection of DWDM Backbone Optical Networks\n- RFC-3031\n- G.841\n"}
{"id": "18930109", "url": "https://en.wikipedia.org/wiki?curid=18930109", "title": "European Information Technology Observatory", "text": "European Information Technology Observatory\n\nThe European Information Technology Observatory (EITO) gathers information on European and global markets for information technology, telecommunications and consumer electronics. The EITO is managed by Bitkom Research GmbH, a wholly owned subsidiary of BITKOM, the German Association for Information Technology, Telecommunications and New Media. EITO is sponsored by Deutsche Telekom, KPMG and Telecom Italia. The research activities of the EITO Task Force are supported by the European Commission and the OECD.\n\nThe EITO exists thanks to an initiative of Enore Deotto (Milano, † August, 9th, 2008 in Carnia) and the support of Luis-Alberto Petit Herrera (Madrid), Jörg Schomburg (Hannover) and Günther Möller (Frankfurt am Main). Between 1993 and 2007 the market reports were published as printed annual reports (\"EITO yearbook\"). Since 2008 the market reports are available in electronic version and can be purchased on the EITO online portal.\nCurrently, the ICT market reports are divided in following categories:\n- International Reports\nInternational Reports include ICT market information of all EITO countries and all market segments or only specific segments. The newest ICT Market Report 2013/14, published in October 2013, includes market data of 36 countries: 28 European markets, BRIC countries, Japan, Turkey and the USA as well as a deep analysis of ICT market developments in 9 European countries. The detailed market data and forecasts are available for the period 2010-2014.\n- Country Reports\nThis category includes EITO reports on a single country's ICT market. The Country ICT Market Reports are published biannually for France, Germany, Italy, Spain and the United Kingdom.\n- Thematic Reports\nThematic studies focusing on a specific topic.\n- Customized Reports\nMarket Reports made upon order.\n- Online portal of EITO\n", "related": "NONE"}
{"id": "41565231", "url": "https://en.wikipedia.org/wiki?curid=41565231", "title": "ISO/IEC JTC 1/SC 6", "text": "ISO/IEC JTC 1/SC 6\n\nISO/IEC JTC 1/SC 6 Telecommunications and information exchange between systems is a standardization subcommittee of the Joint Technical Committee ISO/IEC JTC 1 of the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC), that develops and facilitates standards within the field of telecommunications and information exchange between systems. ISO/IEC JTC 1/SC 6 was established in 1964, following the creation of a Special Working Group under ISO/TC 97 on Data Link Control Procedures and Modem Interfaces. The international secretariat of ISO/IEC JTC 1/SC 6 is the Korean Agency for Technology and Standards (KATS), located in the Republic of Korea.\n\nThe scope of ISO/IEC JTC 1/SC 6 is “Standardization in the field of telecommunications dealing with the exchange of information between open systems including system functions, procedures, parameters as well as the conditions for their use. The standardization encompasses protocols and services of lower layers, including physical, data link, network, and transport as well as those of upper layers including but not limited to Directory and ASN.1.”\n\nFuture Network has recently been added as an important work scope. A considerable part of the work is done in effective cooperation with ITU-T and other standardization bodies including IEEE 802 and Ecma International.\n\nISO/IEC JTC 1/SC 6 has three active working groups (WGs), each of which carries out specific tasks in standards development within the field of telecommunications and information exchange between systems. The focus of each working group is described in the group’s terms of reference. Working groups can be established if new working areas arise, or disbanded if the group’s working area is no longer relevant to standardization needs. Active working groups of ISO/IEC JTC 1/SC 6 are:\nISO/IEC JTC 1/SC 6 works in close collaboration with a number of other organizations or subcommittees, both internal and external to ISO or IEC. Organizations internal to ISO or IEC that collaborate with or are in liaison with ISO/IEC JTC 1/SC 6 include:\n\n- ISO/IEC JTC 1/WG 7, Sensor networks\n- ISO/IEC JTC 1/SC 17, Cards and personal identification\n- ISO/IEC JTC 1/SC 25, Interconnection of information technology equipment\n- ISO/IEC JTC 1/SC 27, IT security techniques\n- ISO/IEC JTC 1/SC 29, Coding of audio, picture, multimedia and hypermedia information\n- ISO/IEC JTC 1/SC 31, Automatic identification and data capture techniques\n- ISO/IEC JTC 1/SC 38, Distributed application platforms & services (DAPS)\n- ISO/TC 68, Financial services\n- ISO/TC 122, Packaging\n- ISO/TC 184/SC 5, Interoperability, integration, and architectures for enterprise systems and automation applications\n- ISO/TC 215, Health Informatics\n- IEC/SC 46A, Coaxial cables\n- IEC/SC 46C, Wires and symmetric cables\n- IEC/TC 48, Electrical connectors and mechanical structures for electrical and electronic equipment\n- IEC/SC 48B, Electrical connectors\n- IEC/TC 65, Industrial-process measurement, control and automation\n- IEC/SC 65C, Industrial networks\n- IEC/TC 86, Fibre optics\n- IEC/SC 86C, Fibre optic systems and active devices\n- IEC/TC 93, Design automation\n\nSome organizations external to ISO or IEC that collaborate with or are in liaison to ISO/IEC JTC 1/SC 6 include:\n- European Conference of Postal and Telecommunications Administrations (CEPT)\n- European Organization for Nuclear Research (CERN)\n- European Commission (EC)\n- European Telecommunications Standards Institute (ETSI)\n- Ecma International\n- International Civil Aviation Organization (ICAO)\n- IEEE 802 LMSC (LAN/MAN Standards Committee)\n- Internet Society (ISOC)\n- International Telecommunications Satellite Organization (ITSO)\n- ITU-T\n- Organization for the Advancement of Structured Information Standards (OASIS)\n- NFC Forum\n- MFA Forum\n- United Nations Conference on Trade and Development (UNCTAD)\n- United Nations Economic Commission for Europe (UNECE)\n- Universal Postal Union (UPU)\n- World Meteorological Organization (WMO)\n- CEN/TC 247/WG 4\n\nCountries pay a fee to ISO to be members of subcommittees.\n\nThe 19 \"P\" (participating) members of ISO/IEC JTC 1/SC 6 are: Austria, Belgium, Canada, China, Czech Republic, Finland, Germany, Greece, Jamaica, Japan, Kazakhstan, Republic of Korea, Netherlands, Russian Federation, Spain, Switzerland, Tunisia, United Kingdom, and United States.\n\nThe 31 \"O\" (observing) members of ISO/IEC JTC 1/SC 6 are: Argentina, Bosnia and Herzegovina, Colombia, Cuba, Cyprus, France, Ghana, Hong Kong, Hungary, Iceland, India, Indonesia, Islamic Republic of Iran, Ireland, Italy, Kenya, Luxembourg, Malaysia, Malta, New Zealand, Norway, Philippines, Poland, Romania, Saudi Arabia, Serbia, Singapore, Slovenia, Thailand, Turkey, and Ukraine.\n\nThere are 365 published standards under the direct responsibility of ISO/IEC JTC 1/SC 6. Published standards by ISO/IEC JTC 1/SC 6 include:\n", "related": "\n- ISO/IEC JTC1\n- List of ISO standards\n- Korean Agency for Technology and Standards\n- International Organization for Standardization\n- International Electrotechnical Commission\n\n- ISO/IEC JTC 1/SC 6 page at ISO\n"}
{"id": "16870447", "url": "https://en.wikipedia.org/wiki?curid=16870447", "title": "TL 9000", "text": "TL 9000\n\nTL 9000 is a quality management practice designed by the QuEST Forum in 1998. It was created to focus on supply chain directives throughout the international telecommunications industry, including the USA. As with ISO/TS 16949 for the automotive industry and AS9000 for the aerospace industry, TL 9000 specializes the generic ISO 9001 to meet the needs of one industrial sector, which for TL 9000 is the information and communications technology (ICT)—extending from service providers through ICT equipment manufacturers through the suppliers and contractors and subcontractors that provide electronic components and software components to those ICT equipment manufacturers.\n\nTL 9000 is defined by two documents:\n- TL 9000 Requirements Handbook, at release 5.5, which includes the full text of ISO 9001:2008\n- TL 9000 Measurements Handbook, at release 5.0\nReports on defect tracking and other measurements at various levels of granularity are accumulated by TL 9000 compliant facilities of certified organizations by the University of Texas at Dallas, which is the official TL 9000 administrator. These reports are provided at no additional charge to TL 9000 member companies and for an additional fee to TL 9000 Liaison members and non-members. Generally, these measurement data permit a service provider to compare the defect rates among various equipment manufacturers and against each other.\n\n- QuEST Forum\n", "related": "NONE"}
{"id": "41219795", "url": "https://en.wikipedia.org/wiki?curid=41219795", "title": "Access-independent services", "text": "Access-independent services\n\nAccess-independent service (AIS) is a service concept in which a service does not depend on guaranteed access network cooperation for service delivery. Telecoms industry analyst Dean Bubley first used the term in a report on Telco-OTT in February 2012.\n\nTraditionally, most telecom company or internet service provider services are access-dependent, because they rely heavily on guaranteed access cooperation on the network the service is delivered over. For instance, traditional IP-based TV service (IPTV) delivered by a telecom company is generally a managed service. This means that IPTV service assumes the IPTV service provider has control over the access network that the IPTV service is delivered over, and network quality of service (QoS) guarantees are available for IPTV service delivery. As a result, the reach of a telecom company's IPTV service is generally restricted by the reach of the telecom company's access network.\n\nIn contrast, services offered by non-traditional video content delivery service providers such as Netflix, Hulu, and Amazon Video are considered access-independent services. Netflix's video content streaming service, for example, dynamically adapts to network conditions in real-time to strive for the best overall quality of experience (QoE) and does not assume guaranteed cooperation from the underlying IP network, such as QoS. As a result, without considering content rights and different countries' government restrictions, the reach of Netflix's video content streaming service is, in theory, the reach of the Internet. Skype is another example of AIS, because Skype offers an IP-based telephony service over the Internet without depending on IP network cooperation guarantees other than basic IP network connectivity.\n\nIn the context of telecom service delivery, the concept of access independent services is also commonly described by the term \"over-the-top\" (OTT) services. OTT service providers such as but not limited to Facebook, WeChat, and Netflix generally do not own or directly manage any wide-area access network to begin with, so they design their services for overall quality of experience, with no assumptions on guaranteed access network cooperation.\n", "related": "NONE"}
{"id": "41015991", "url": "https://en.wikipedia.org/wiki?curid=41015991", "title": "Telecommunications lease", "text": "Telecommunications lease\n\nA telecommunications lease is a lease that exists between a telecommunications provider or wireless company, and a landowner. Similar to other real estate leases, a telecommunications lease is put in place as an agreement to lease space on the landowner’s property for a telecommunications site or cellular tower for a specified length of time. In exchange for the use of space, the telecommunications provider (also referenced as a tenant) agrees to pay the landowner (a monthly or annual) rent. Telecom leases can be excellent sources of ancillary income, in some cases providing the landowner with thousands of dollars per month.\n\nThe telecommunication industry is growing as the need for 4G and 5G networks flourishes. As a result of this growth there is a constant demand for cellular networks to increase their coverage. Therefore, more cellular towers are constructed and more leases are drawn up between the cellular provider and landowners, which can include municipalities and private landowners, such as homeowners.\n\nIn the telecommunications industry, there are two types of telecommunications leases: a rooftop lease agreement and a ground lease agreement. In some cases, cellular sites are installed on the roofs of commercial office buildings and even residential living complexes. These rooftop installations take advantage of the height of the buildings on which they are installed to provide quality cellular coverage. Ground leases, on the other hand are contracts typically made between the cellular provider and the landowner of a property for space at the ground level on which a cellular tower is installed.\n\nRooftops are leased for many different communication purposes, including many different types of antennas. Panel antennas are commonly placed on rooftops in urban and densely populated residential areas. These antennas typically range from 1–10 feet in height and have the ability to service multiple technologies, including: cellular antennas, PCS antennas, specialized mobile radios, fixed wireless services, and paging services.\n\nSatellite dishes are also mounted on some rooftops, primarily for satellite TV service, but in other cases much larger dishes are used. These antennas generally address Internet and cable needs and therefore are used for services such as video conferencing.\n\nRooftop leases include details about the amount of space leased, installation methods, and upgrade procedures that allow the tenant to operate at the site as needed, while protecting the landlords building.\n\nGround leases generally address antenna towers or billboards in which the landowner leases the space, or land, to the cellular provider to build the tower. Antenna towers range between 50 and 300 feet tall. These large, free standing cellular towers can sometimes be “disguised” to blend in with the natural architecture of the building or the surrounding landscape. An example of this is a church property that may have a tower built to resemble, or in some cases built into an existing steeple. Alternatively, a property owner for another type of property may have a monopine or monopalm cellular structure. These are built to resemble pine or palm trees respectively.\n\nCellular providers such as Verizon Wireless and AT&T most commonly use ground leases.\n\nProposals for new cell towers sometimes face public opposition in zoning proceedings from residents who raise aesthetic objections and fear health hazards.\n\nLocal zoning boards must follow the rules set forth in the Telecommunications Act of 1996. which sets guidelines for what are acceptable reasons to not permit the construction of a new cellular tower.\n\nGenerally cellular providers look for property that is in a densely populated area and that falls outside of a five-mile radius from the nearest tower. For a cellular company, redundancy occurs when two or more towers serve the same area. This often causes a loss of income for the cellular provider, as they generally need one tower rather than multiple. As companies continue to merge, redundancy has become a rising issue within the telecommunication industry.\n\nGenerally, telecom leases are for an initial five-year term followed by additional five-year renewal terms. Leases typically also have a 30- to 90-day cancellation period when the cellular provider has the right to terminate the lease within 30 to 90 days of giving notice to the landowner. This specific portion of a telecom lease is due to recent mergers in the industry, which render some towers useless. Due to cellular providers merging with other cellular companies, one company can double its number of towers. This often causes redundancy, as previously mentioned, which often leads to the termination of leases and removal of redundant towers.\n\nThe fair market value of a lease is generally determined by the importance of the location to the cellular carrier's network, or the value of the coverage the location provides. Value will also be driven by the availability of surrounding alternate sites. Determining the fair market value of a cellular lease is difficult for most landowners due to lack of available information. Cell tower lease rates are not public information, and these rates vary widely. There are however companies that specialize in providing information and assistance to property owners in this highly specialized field.\n\nIn order to make money, cellular carriers often undervalue a lease. Leasing agents typically receive bonuses for signing low-priced leases, and therefore undervalue leases because the worse the deal is for the landowner, the greater the benefits are for the leasing agent. There are several methods for a landowner to evaluate their property:\n1. Are there cell towers owned by the cellular company near by?\n2. Is your property located in a densely populated area?\n3. Is there a high demand for cellular coverage near your property?\n\nCollocation is when the cellular company allows other companies to build on their tower. As a result, the cellular company that owns the tower receives a rent from the co-locators. Within a lease, landowners can address collocation and receive a portion of the rent received by the cellular company.\n\nProperty owners have the ability to sell their cell tower lease separate from their parcel. Investors purchase the cell tower lease as an easement or lease assignment. Three main factors that influence cell tower buyout prices are: current rent, the rent escalator, and the date of lease expiration.\n\nDifferent types of cell tower lease buyout offers have different implications for landowners. For example, a cell tower lease buyout on farmland is much different than the purchase of a lease on a building rooftop. Some necessary considerations for cell tower lease buyout transactions are:\n- Access requirements.\n- Tax implications. (easement vs. lease assignment)\n- Property redevelopment rights.\n- For rooftop sites, how is property damage addressed.\n\nThe challenges of selling a cellular leasehold is the acquisition market is highly unregulated. Lease Acquisition agents have the ability to modify and deliver information to the landowner to acquire leaseholds at a highly discounted price. Similar the oil barons of the 1800s, these agents are compensated heavily to obtain these rights, and often the underlying value of expiration and an expanded sale market is shielded from the landowner.\n", "related": "NONE"}
{"id": "41783", "url": "https://en.wikipedia.org/wiki?curid=41783", "title": "Teleconference", "text": "Teleconference\n\nA teleconference or teleseminar is the live exchange and mass articulation of information among several persons and machines remote from one another but linked by a telecommunications system. Terms such as audio conferencing, telephone conferencing and phone conferencing are also sometimes used to refer to teleconferencing.\n\nThe telecommunications system may support the teleconference by providing one or more of the following: audio, video, and/or data services by one or more means, such as telephone, computer, telegraph, teletypewriter, radio, and television.\n\nInternet teleconferencing includes internet telephone conferencing, videoconferencing, web conferencing, and augmented reality conferencing.\n\nInternet telephony involves conducting a teleconference over the Internet or a Wide Area Network. One key technology in this area is Voice over Internet Protocol (VOIP). Popular software for personal use includes Skype, Google Talk, Windows Live Messenger and Yahoo! Messenger.\n\nA working example of an augmented reality conferencing was demonstrated at the Salone di Mobile in Milano by AR+RFID Lab. is another AR teleconferencing tool.\n\nNotable vendors with articles:\n- ACT Conferencing\n- Adobe Acrobat Connect\n- AT Conference, Inc.\n- Compunetix\n- Elluminate\n- Glance\n- Google Hangouts\n- GoToMeeting\n- InterCall\n- LifeSize\n- Livestorm Meet\n- LoopUp\n- Microsoft Office Live Meeting\n- Polycom\n- Premiere Global Services\n- Skype\n- TrueConf\n- Voxeet\n- WebEx\n- Zoom\n\n", "related": "NONE"}
{"id": "34779099", "url": "https://en.wikipedia.org/wiki?curid=34779099", "title": "User-in-the-loop", "text": "User-in-the-loop\n\nUser-in-the-Loop (UIL) refers to the notion that a technology (e.g., network) can improve a performance objective by engaging its human users (Layer 8). The idea can be applied in various technological fields. UIL assumes that human users of a network are among the smartest but also most unpredictable units of that network. Furthermore, human users often have a certain set of (input) values that they sense (more or less observe, but also acoustic or haptic feedback is imaginable: imagine a gas pedal in a car giving some resistance, like for a speedomat). Both elements of smart decision-making and observed values can help towards improving the bigger objective.\n\nThe input values are meant to encourage/discourage human users to behave in certain ways that improve the overall performance of the system. One example of a historic implementation related to UIL has appeared in electric power networks where a price chart is introduced to users of electrical power. This price chart differentiates the values of electricity based on off-peak, mid-peak and on-peak periods, for instance. Faced with a non-homogenous pattern of pricing, human users respond by changing their power consumption accordingly that eventually leads to the overall improvement of access to electrical power (reduce peak hour consumption). Recently, UIL has been also introduced for wireless telecommunications (cellular networks).\n\nWireless resources including the bandwidth (frequency) are an increasingly scarce resource and the while current demand on wireless network is below the supply in most of the times (potentials capacity of the wireless links based on technology limitations), the rapid and exponential increase in demand will render wireless access an increasingly expensive resource in a matter of few years. While usual technological responses to this perspective such as innovative new generations of cellular systems, more efficient resource allocations, cognitive radio and machine learning are certainly necessary, it seems that they ignore a major resource in the system, namely the users. Wireless users can be encouraged to change their \"wireless behavior\" by introducing incentives, e.g., differentiated pricing. In addition, the increasing concern for the environment and the considerable yet invisible environmental effects of wireless use can be tapped into in order to convince \"greener\" user to change their wireless behavior in order to reduce their carbon footprint.\n\nUIL used in wireless communications is referred to as the Smart Grid of Communications. It aims for avoiding a location of bad link adaptation or excess use during the busy hour.\n\nIndependent of the various ways of giving incentives and penalties\nthe outcome of the user block is either\na spatial, temporal or no reaction at all.\nSpatial UIL means the user changes location to a better one\n(like the common practice in WiFi networks).\nTemporal UIL means the demand is avoided at the current time\n(to be continued at another time, abandoned, or offloaded to the wired network at home).\nThe incentive usually is a fully dynamic tariff.\nThis shapes user demand during congestion.\nUIL aims at stabilizing the traffic demand to a sustainable level below the capacity.\nIn cellular networks, it helps keeping traffic below the capacity at all times.\n\nThe general perspective of UIL is shown in the figure.\nIn the UIL concept, the controller gives necessary information to the user,\nand so it is expected that the user voluntarily changes his current location\nfrom point A to B.\nThe current signal quality at point A and/or the spectral efficiency there are known by the controller.\nBesides, the average signal quality and/or the spectral efficiency\nare known for all locations of the network from a database of previous measurements.\nAfter that, the network provides the necessary information\nand suggests better positions to the user.\nBefore the movement, user knows his utility advantage\nbetween point B and A.\nThis utility advantage can be financial (discount for voice calls)\nand/or an increased data rate (best effort data traffic).\nThe network is providing the information\nwhere (in which direction to which location) to move.\nBefore making his decision,\nthe user should have all necessary information\n(discount rate, increased data rate, how far is the next improved step).\nAt the end, a certain portion of users participates in moving\nand the rest of them stays in place, which includes all users that cannot move, do not want to move,\nor do not have enough incentive to move.\nThe user block in the figure outputs the new location B, if the user decides to move.\nThis probability depends on the distance and the given incentive utility.\nThe target spectral efficiency is the minimum spectral efficiency that the user should achieve\nafter the movement (the target value must be greater than the current one).\n\nThe demand increase in cellular networks is fueled by a flat rate pricing policy. \nIt promotes heavy-tailed traffic distributions and leads to unbounded demand increase. \nNowadays the pricing policy is starting to change because of the unbounded demand increase.\nEventually some operators started to charge flat-rate with a cap, \nbut this is a temporal solution.\nA more elaborate solution, usage based pricing,\nis suggested in the literature, \nbut on its own it does not solve the congestion problem in the busy hours.\nOne step further in UIL, \na fully dynamic usage-based pricing is suggested.\nThis dynamic price is displayed on a user terminal (UT)\nso that user can decide to use or not to use the service. \nThe main idea is very clear, the user will generate less traffic when the session price goes up.\nAs a result, the pricing method will change the user behavior and the traffic as \nin electricity tariffs and smart-grid applications\nand even better than there, because of the immediate feedback and latency in the order of seconds,\nwhich allows for best response and training.\n\nUser-in-the-Loop applications are possible in all fields where limited resources are consumed\nand where a negative impact for society or environment must be avoided, e.g.,\nexcessive consumption of energy and fossil fuel.\n\nReasons for using UIL are manifold.\nIn wireless communications, there is a growing problem with\nincreasing data rates in the next 10 years.\nSmart phones and laptop dongles will continue to increase traffic by 100% per year -\na trend observed already in the last 5 years.\nThe traditional approach to oversize capacity in order to carry all traffic\nwill become harder as 4G, 5G and beyond\ncan never keep up with demand at this rate of increase.\nEnergy consumption and going green is also becoming more important in the future.\nWhatever increase of capacity technology will provide,\nwill soon be eaten up by even faster increasing traffic.\nNew approaches require to spend even more money and power, e.g. for pico- and femtocells.\nThe UIL approach is .\nUIL is able to boost the spectral efficiency by substantial amounts.\n\nThe interface between the UIL controller and the user box consists of information and incentive.\nInformation is simply the knowledge that a change of the user output would be beneficial (for the system, community, society).\nHowever, an extra incentive may be required in most cases to make the user really change his default behavior,\nbecause altruism is not far-reaching enough and people tend to prefer selfish strategies in free societies (see game theory).\nThis dilemma is called Tragedy of the commons. So it is rational to assume the homo economicus model driven by a utility maximization in the first order and homo reciprocans only for second-order effects.\n\nIncentives can be by financial aspects (cheaper rate for usage) or other beneficial bonuses which may be convertible into money or not.\nAn example are miles of a frequent-flyer program for every spatial move the user performs.\nAnother benefit in a wireless network is granting the user a higher bit rate, but only for the conforming user.\nNegative incentives are also possible in forms of penalties, but psychology suggests that positive incentives work better.\nA penalty could be in place when using the system is bad for the total goal at the current time or location (busy hour, congestion situation, bad link adaptation), in order to keep the user from using the system under these circumstances. Instead, at a better location or time of day the usage would be usable without penalty.\n\n- Motivating users to perform their action at another location (e.g. towards better spectral efficiency locations in a wireless cellular network)\n- Convincing users not to perform a certain action at this time (in the busy hours) but at a better time.\n- Demand response in the smart grid\n- Controlling user behavior towards a positive goal\n- capacity/demand, also known as load balancing\n- utility usage: electricity, gas, water\n- cyber-physical systems in emergency evacuation of infrastructure buildings\n- secure systems design\n- fossil fuel usage for transportation, heating, industry\n- fast dynamic pricing of any kind\n- example mobile display here\n- User interface by a fuel consumption monitor as shown in fuel consumption in automobiles\n\nIn general, UIL allows to control for a goal which is greener than if the user would act uncontrolled. This goal can be energy consumption, fossil fuel consumption, food consumption or even softer goals like social behavior. It is as if the rules (payoffs) can be changed in Game theory to make the outcome appear more cooperative.\n\nThe green aspect for a wireless network is as follows. Power consumed by wireless infrastructure like base stations, switching centers currently already accounts for 0.5% of the global electric power consumption and therefore the carbon emissions. Putting contemporary data together results in a carbon footprint of 34 g of CO (or 17 dm) for 1 MB of transmitted data. We can call this the current green index of wireless cellular communications. One bit corresponds to 5.8×10 molecules of CO is the specific bit emission. Wireless cellular networks consume 0.5% of the world total electricity which is approximately 20 PWh in 2010. The average monthly cellular wireless traffic is 240×10 bytes which is totally 2880 PB in 2010. Then energy per byte can be found as 0.0347×10 kWh and it is equal to 0.125 J. If the electricity is obtained from coal then 975 g of CO arises for 1 kWh of energy. Then for one byte of wireless data 0.0338325 mg of CO arises, which is approximately equal to 34 g of CO for 1 MB.\n\n", "related": "\n- Systems theory\n- Control theory\n- Human factors\n- User interface\n- Human-in-the-Loop\n- Website of the UIL project\n"}
{"id": "42579609", "url": "https://en.wikipedia.org/wiki?curid=42579609", "title": "First office application", "text": "First office application\n\nIn telecommunication, First Office Application (FOA) is a phase in development of new equipment or technology. The FOA phase is the first deployment (pilot) of the equipment or technology in an actual customer environment after internal test and acceptance phases are completed.\n", "related": "NONE"}
{"id": "43083432", "url": "https://en.wikipedia.org/wiki?curid=43083432", "title": "Magnetoquasistatic field", "text": "Magnetoquasistatic field\n\nA magnetoquasistatic field is a class of electromagnetic field in which a slowly oscillating magnetic field is dominant. A magnetoquasistatic field is typically generated by \"low-frequency\" induction from a magnetic dipole or a current loop. The magnetic near-field of such an emitter behaves differently from the more commonly used far-field electromagnetic radiation. At low frequencies the rate of change of the instantaneous field strength with each cycle is relatively slow, giving rise to the name \"magneto-quasistatic\". The near field or quasistatic region typically extends no more than a wavelength from the antenna, and within this region the electric and magnetic fields are approximately decoupled.\n\nWeakly conducting non-magnetic bodies, including the human body and many mineral rocks, are effectively transparent to magnetoquasistatic fields, allowing for the transmission and reception of signals through such obstacles. Also, long-wavelength (i.e. low-frequency) signals are better able to propagate round corners than shorter-wave signals. Communication therefore need not be line-of-sight.\n\nThe communication range of such signals depends on both the wavelength and the electromagnetic properties of the intervening medium at the chosen frequency, and is typically limited to a few tens of meters.\n\nThe laws of primary interest are Ampère's circuital law (with the displacement current density neglected) and the magnetic flux continuity law. These laws have associated with them continuity conditions at interfaces. In the absence of magnetizable materials, these laws determine the magnetic field intensity H given its source, the current density J. H is not everywhere irrotational. However, it is solenoidal everywhere.\n\nA typical antenna comprises a 50-turn coil around a polyoxymethylene tube with diameter 16.5 cm, driven by a class E oscillator circuit. Such a device is readily portable when powered by batteries. Similarly, a typical receiver consist of an active receiving loop with diameter of one meter, an ultra-low-noise amplifier, and a band-pass filter.\n\nIn operation the oscillator drives current through the transmitting loop to create an oscillating magnetic field. This field induces a voltage in the receiving loop, which is then amplified.\n\nBecause the quasistatic region is defined within one wavelength of the electromagnetic source, emitters are limited to a frequency range between about 1 kHz and 1 MHz. Reducing the oscillating frequency increases the wavelength and hence the range of the quasistatic region, but reduces the induced voltage in the receiving loops which worsens the signal-to-noise ratio. In experiments carried out by the Carnegie Institute of Technology, the maximum range reported by was 50 meters.\n\nIn resonant coupling, the source and receiver are tuned to resonate at the same frequency and are given similar impedances. This allows power as well as information to flow from the source to the receiver. Such coupling via the magnetoquasistatic field is called resonant inductive coupling and can be used for wireless energy transfer.\n\nApplications include induction cooking, induction charging of batteries and some kinds of RFID tag.\n\nConventional electromagnetic communication signals cannot pass through the ground. Most mineral rock is neither electrically conducting nor magnetic, allowing magnetic fields to penetrate. Magnetoquasistatic systems have been successfully used for underground wireless communication, both surface-to-underground and between underground parties.\n\nAt extremely low frequencies, below about 1 kHz, the wavelength is long enough for long-distance communication, although at a slow data rate. Such systems have been installed in submarines, with the local antenna comprising a wire up to several kilometers in length and trailed behind the vessel when at or near the surface.\n\nWireless position tracking is being increasingly used in applications such as navigation, security, and asset tracking. Conventional position tracking devices use high frequencies or microwaves, including global positioning systems (GPS), ultra-wide band (UWB) systems, and radio frequency identification systems (RFID), but these systems can easily be blocked by obstacles in their path. Magnetoquasistatic positioning takes advantage of the fact that the fields are largely undisturbed when in the presence of human beings and physical structures, and can be used for both position and orientation tracking for ranges up to 50 meters.\n\nTo accurately determine the orientation and position of a dipole/emitter, allowance must be made not only for the field pattern generated by the emitter, but also for the eddy-currents they induce in the earth, which create secondary fields detectable by the receivers. By using complex image theory to correct this field generation from earth, and by using frequencies on the order of a few hundred kilohertz to obtain the required signal-to-noise ratio (SNR), it is possible to analyze the position of the dipole through azimuthal orientation, formula_1, and inclination orientation, formula_2.\n\nA Disney research team has used this technology to effectively determine the position and orientation of an American football, something not traceable through conventional wave propagation techniques due to human body obstruction. They inserted an oscillator-driven coil, around the diameter of the center of the ball, to generate the magnetoquasistatic field. The signal was able to pass undisturbed through multiple players.\n\n- Markus Zahn. \"Chapter 8: Magnetoquasistatic fields: superposition integral and boundary value points of view\" \"MIT OpenCourseWare\", 10 October 2008.\n- Darmindra D. Arumugam \"Wireless orientation sensing using magnetoquasistatic fields and complex image theory\" 2012.\n", "related": "NONE"}
{"id": "480015", "url": "https://en.wikipedia.org/wiki?curid=480015", "title": "Traffic analysis", "text": "Traffic analysis\n\nTraffic analysis is the process of intercepting and examining messages in order to deduce information from patterns in communication, which can be performed even when the messages are encrypted. In general, the greater the number of messages observed, or even intercepted and stored, the more can be inferred from the traffic. Traffic analysis can be performed in the context of military intelligence, counter-intelligence, or pattern-of-life analysis, and is a concern in computer security.\n\nTraffic analysis tasks may be supported by dedicated computer software programs. Advanced traffic analysis techniques may include various forms of social network analysis.\n\nTraffic analysis method can be used to break the anonymity of anonymous networks, e.g., TORs . There are two methods of traffic-analysis attack, passive and active. \n\n- In passive traffic-analysis method, the attacker extracts features from the traffic of a specific flow on one side of the network and looks for those features on the other side of the network.\n- In active traffic-analysis method, the attacker alters the timings of the packets of a flow according to a specific pattern and looks for that pattern on the other side of the network; therefore, the attacker can link the flows in one side to the other side of the network and break the anonymity of it. It is shown, although timing noise is added to the packets, there are active traffic analysis methods robust against such a noise.\n\nIn a military context, traffic analysis is a basic part of signals intelligence, and can be a source of information about the intentions and actions of the target. Representative patterns include:\n\n- Frequent communications – can denote planning\n- Rapid, short communications – can denote negotiations\n- A lack of communication – can indicate a lack of activity, or completion of a finalized plan\n- Frequent communication to specific stations from a central station – can highlight the chain of command\n- Who talks to whom – can indicate which stations are 'in charge' or the 'control station' of a particular network. This further implies something about the personnel associated with each station\n- Who talks when – can indicate which stations are active in connection with events, which implies something about the information being passed and perhaps something about the personnel/access of those associated with some stations\n- Who changes from station to station, or medium to medium – can indicate movement, fear of interception\n\nThere is a close relationship between traffic analysis and cryptanalysis (commonly called codebreaking). Callsigns and addresses are frequently encrypted, requiring assistance in identifying them. Traffic volume can often be a sign of an addressee's importance, giving hints to pending objectives or movements to cryptanalysts.\n\nTraffic-flow security is the use of measures that conceal the presence and properties of valid messages on a network to prevent traffic analysis. This can be done by operational procedures or by the protection resulting from features inherent in some cryptographic equipment. Techniques used include:\n\n- changing radio callsigns frequently\n- encryption of a message's sending and receiving addresses (codress messages)\n- causing the circuit to appear busy at all times or much of the time by sending dummy traffic\n- sending a continuous encrypted signal, whether or not traffic is being transmitted. This is also called masking or link encryption.\n\nTraffic-flow security is one aspect of communications security.\n\nThe Communications' Metadata Intelligence, or COMINT metadata is a term in communications intelligence (COMINT) referring to the concept of producing intelligence by analyzing only the technical metadata, hence, is a great practical example for traffic analysis in intelligence.\n\nWhile traditionally information gathering in COMINT is derived from intercepting transmissions, tapping the target's communications and monitoring the content of conversations, the metadata intelligence is not based on content but on technical communicational data.\n\nNon-content COMINT is usually used to deduce information about the user of a certain transmitter, such as locations, contacts, activity volume, routine and its exceptions.\n\nFor example, if a certain emitter is known as the radio transmitter of a certain unit, and by using direction finding (DF) tools, the position of the emitter is locatable; hence the changes of locations can be monitored. That way we're able to understand that this certain unit is moving from one point to another, without listening to any orders or reports. If we know that this unit reports back to a command on a certain pattern, and we know that another unit reports on the same pattern to the same command, then the two units are probably related, and that conclusion is based on the metadata of the two units' transmissions, and not on the content of their transmissions.\n\nUsing all, or as much of the metadata available is commonly used to build up an Electronic Order of Battle (EOB) – mapping different entities in the battlefield and their connections. Of course the EOB could be built by tapping all the conversations and trying to understand which unit is where, but using the metadata with an automatic analysis tool enables a much faster and accurate EOB build-up that alongside tapping builds a much better and complete picture.\n\n- British analysts in World War I noticed that the call sign of German Vice Admiral Reinhard Scheer, commanding the hostile fleet, had been transferred to a land station. Admiral of the Fleet Beatty, ignorant of Scheer's practice of changing callsigns upon leaving harbor, dismissed its importance and disregarded Room 40 analysts' attempts to make the point. The German fleet sortied, and the British were late in meeting them at the Battle of Jutland. If traffic analysis had been taken more seriously, the British might have done better than a \"draw\".\n- French military intelligence, shaped by Kerckhoffs's legacy, had erected a network of intercept stations at the Western front in pre-war times. When the Germans crossed the frontier, the French worked out crude means for direction-finding based on intercepted signal intensity. Recording of call-signs and volume of traffic further enabled them to identify German combat groups and to distinguish between fast-moving cavalry and slower infantry.\n\n- In early World War II, the aircraft carrier was evacuating pilots and planes from Norway. Traffic analysis produced indications and were moving into the North Sea, but the Admiralty dismissed the report as unproven. The captain of \"Glorious\" did not keep sufficient lookout, and was subsequently surprised and sunk. Harry Hinsley, the young Bletchley Park liaison to the Admiralty, later said his reports from the traffic analysts were taken much more seriously thereafter.\n- During the planning and rehearsal for the attack on Pearl Harbor, very little traffic passed by radio, subject to interception. The ships, units, and commands involved were all in Japan and in touch by phone, courier, signal lamp, or even flag. None of that traffic was intercepted, and could not be analyzed.\n- The espionage effort against Pearl Harbor before December didn't send an unusual number of messages; Japanese vessels regularly called in Hawaii and messages were carried aboard by consular personnel. At least one such vessel carried some Japanese Navy Intelligence officers. Such messages cannot be analyzed. It has been suggested, however, the volume of diplomatic traffic to and from certain consular stations might have indicated places of interest to Japan, which might thus have suggested locations to concentrate traffic analysis and decryption efforts.\n- Admiral Nagumo's Pearl Harbor Attack Force sailed under radio silence, with its radios physically locked down. It is unclear if this deceived the U.S.; Pacific Fleet intelligence was unable to locate the Japanese carriers in the days immediately preceding the attack on Pearl Harbor .\n- The Japanese Navy played radio games to inhibit traffic analysis (see Examples, below) with the attack force after it sailed in late November. Radio operators normally assigned to carriers, with a characteristic Morse Code \"fist\", transmitted from inland Japanese waters, suggesting the carriers were still near Japan\n- Operation Quicksilver, part of the British deception plan for the Invasion of Normandy in World War II, fed German intelligence a combination of true and false information about troop deployments in Britain, causing the Germans to deduce an order of battle which suggested an invasion at the Pas-de-Calais instead of Normandy. The fictitious divisions created for this deception were supplied with real radio units, which maintained a flow of messages consistent with the deception.\n\nTraffic analysis is also a concern in computer security. An attacker can gain important information by monitoring the frequency and timing of network packets. A timing attack on the SSH protocol can use timing information to deduce information about passwords since, during interactive session, SSH transmits each keystroke as a message. The time between keystroke messages can be studied using hidden Markov models. Song, \"et al.\" claim that it can recover the password fifty times faster than a brute force attack.\n\nOnion routing systems are used to gain anonymity. Traffic analysis can be used to attack anonymous communication systems like the Tor anonymity network. Adam Back, Ulf Möeller and Anton Stiglic present traffic analysis attacks against anonymity providing systems \n. Steven J. Murdoch and George Danezis from University of Cambridge presented \nresearch showing that traffic-analysis allows adversaries to infer which nodes relay the anonymous streams. This reduces the anonymity provided by Tor. They have shown that otherwise unrelated streams can be linked back to the same initiator.\n\nRemailer systems can also be attacked via traffic analysis. If a message is observed going to a remailing server, and an identical-length (if now anonymized) message is seen exiting the server soon after, a traffic analyst may be able to (automatically) connect the sender with the ultimate receiver. Variations of remailer operations exist that can make traffic analysis less effective.\n\nIt is difficult to defeat traffic analysis without both encrypting messages and masking the channel. When no actual messages are being sent, the channel can be masked\n. \"It is very hard to hide information about the size or timing of messages. The known solutions require Alice to send a continuous stream of messages at the maximum bandwidth she will ever use...This might be acceptable for military applications, but it is not for most civilian applications.\" The military-versus-civilian problems applies in situations where the user is charged for the volume of information sent.\n\nEven for Internet access, where there is not a per-packet charge, ISPs make statistical assumption that connections from user sites will not be busy 100% of the time. The user cannot simply increase the bandwidth of the link, since masking would fill that as well. If masking, which often can be built into end-to-end encryptors, becomes common practice, ISPs will have to change their traffic assumptions.\n\n", "related": "\n- Chatter (signals intelligence)\n- Data warehouse\n- ECHELON\n- Electronic order of battle\n- ELINT\n- Pattern-of-life analysis\n- SIGINT\n- Social network analysis\n- Telecommunications data retention\n- Zendian Problem\n\n- FMV Sweden\n- Multi-source data fusion in NATO coalition operations\n\n- http://www.cyber-rights.org/interception/stoa/interception_capabilities_2000.htm — a study by Duncan Campbell\n- https://web.archive.org/web/20070713232218/http://www.onr.navy.mil/02/baa/docs/07-026_07_026_industry_briefing.pdf\n- Selected Papers in Anonymity — on Free Haven\n"}
{"id": "44069171", "url": "https://en.wikipedia.org/wiki?curid=44069171", "title": "Visual MIMO", "text": "Visual MIMO\n\nVisual MIMO is an optical communication system. The name is derived from MIMO, where the multiple transmitter multiple receiver model has been adopted for light in the visible and non-visible spectrum. In Visual MIMO, a LED or electronic visual display serves as the transmitter, while a camera serves as the receiver.\n\n- http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5981735\n- http://winlab.rutgers.edu/~aashok/visualmimo/Home.html\n- http://winlab.rutgers.edu/~aashok/papers/wyuan_wacv2012.pdf\n- http://winlab.rutgers.edu/~aashok/papers/wyuan_procams11.pdf\n", "related": "NONE"}
{"id": "8648241", "url": "https://en.wikipedia.org/wiki?curid=8648241", "title": "Modulation error ratio", "text": "Modulation error ratio\n\nThe modulation error ratio or MER is a measure used to quantify the performance of a digital radio (or digital TV) transmitter or receiver in a communications system using digital modulation (such as QAM). A signal sent by an ideal transmitter or received by a receiver would have all constellation points precisely at the ideal locations, however various imperfections in the implementation (such as noise, low image rejection ratio, phase noise, carrier suppression, distortion, etc.) or signal path cause the actual constellation points to deviate from the ideal locations. \n\nTransmitter MER can be measured by specialized equipment, which demodulates the received signal in a similar way to how a real radio demodulator does it. Demodulated and detected signal can be used as a reasonably reliable estimate for the ideal transmitted signal in MER calculation.\n\nAn error vector is a vector in the I-Q plane between the ideal constellation point and the point received by the receiver. The Euclidean distance between the two points is its magnitude.\n\nThe modulation error ratio is equal to the ratio of the root mean square (RMS) power (in Watts) of the reference vector to the power (in Watts) of the error. It is defined in dB as:\n\nwhere P is the RMS power of the error vector, and P is the RMS power of ideal transmitted signal.\n\nMER is defined as a percentage in a compatible (but reciprocal) way:\n\nwith the same definitions.\n\nMER is closely related to error vector magnitude (EVM), but MER is calculated from the average power of the signal. MER is also closely related to signal-to-noise ratio. MER includes all imperfections including deterministic amplitude imbalance, quadrature error and distortion, while noise is random by nature.\n\n", "related": "\n- Error vector magnitude\n- Carrier to Noise Ratio\n- Signal-to-noise ratio\n\n- \"ETSI technical report ETR 290: \"Measurement guidelines for DVB systems\"\", Errata 1, May 1997\n"}
{"id": "44890359", "url": "https://en.wikipedia.org/wiki?curid=44890359", "title": "Contact center telephony", "text": "Contact center telephony\n\nIn marketing, contact center telephony is the communication and collaboration system used by businesses to either manage high volumes of inbound queries or outbound telephone calls keeping their workforce or agents productive and in control to serve or acquire customers. This business communication system is an extension of computer telephony integration (CTI). \n\nThe interactions between callers and customer service representatives are supported by the collective system of computers, telephones and the Internet. The shift from CTI to contact center telephony is marked by the sheer change in the customer’s behavior when it comes to communication. Means customers are no longer confined only to voice-based communication i.e. phone to connect with their customer service departments. In addition, they are making use of email, SMS, chat, social media, and other virtual contact channels. This is also the reason for the shift in nomenclature from \"call centers\" to \"contact centers\", \"contact\" being a wider term than \"call\". Respecting the trend, contact center owners need to adopt unified communication or multi-channel approach to let customers get in touch with them via their preferred communication mediums, either voice or non-voice (data). Cloud-based phone system is a further advancement in the direction as it allows operators to access all the features and benefits of call center telephony over the Web against an affordable & flexible pay-as-you-go subscription model. Thus, in-house infrastructure deployment to manage public switched telephone networks, storage, communication applications, and collaboration servers is no more an obligation. Neither is the need to invest resources for their upgrade, repair, maintenance and security as cloud vendor would be responsible for the same.\n\nIndia, a popular call center business process outsourcing destination, often uses a cloud-based phone system in order to cut operational expenses and downtime, and increase connectivity.\n\nBusinesses can rely on contact center telephony services to respond to their customers’ queries over phone, email, chat, fax, etc. Integrating it with their customer relationship management tools, entire contact details of customers and their interaction sessions with different customer service representatives can be found at one place. The combination can manage not just sales and marketing but also deliver excellent post-sales customer service or technical support to allow customers derive the most from their products or services. Hence, it’s becoming instrumental in increasing customer satisfaction and loyalty and most of the call center services in India are taking refuge from it.\n\nThe entire contact center telephony service can be availed by professionals over a browser. Hence, businesses can leverage the concept of BYOD (bring your own device) and mobility and serve their customers well using mobile applications. According to market analysts, BYOD increases satisfaction among workforce, and hence their individual and collective productivity as well. BYOD programme significantly reduces the TCO (total cost of ownership) as professionals prefer to work with their own devices rather than using company-provisioned devices. Next, they tend to be more caring towards such devices and can even shell out money to update and upgrade those when required.\n\nIntegration of IM, along with audio and video conferencing services helps call center or contact center representatives to get real time assistance from their peers or seniors to resolve any complex issues. They can internally exchange information and knowledge articles as and when required. Real-time call monitoring/barging system can be used by quality assessment team to provide important guidelines to agents to maintain the standard of the service as per industry norms. Integrated recording feature is helpful for internal training and quality purposes to improve productivity and customer satisfaction in equal measures. It also helps in getting business insights and improving products or services to gain deeper penetration into the market.\n", "related": "NONE"}
{"id": "45352330", "url": "https://en.wikipedia.org/wiki?curid=45352330", "title": "Software-defined mobile network", "text": "Software-defined mobile network\n\nSoftware-defined mobile networking (SDMN) is an approach to the design of mobile networks where all protocol-specific features are implemented in software, maximizing the use of generic and commodity hardware and software in both the core network and radio access network.\n\nThrough the 20th century, telecommunications technology was driven by hardware development, with most functions implemented in special-purpose equipment.\nIn the early 2000s, generally available CPU’s became cheap enough to enable commercial software defined radio (SDR) technology and softswitches.\nSDMN extends these trends into the design of mobile networks, moving nearly all network functions into software.\n\nThe term \"software-defined mobile network\" first appeared in public literature in early 2014, used independently by Lime Microsystems and researchers from University of Oulu, Finland.\n\nMobile networks based on special-purpose hardware suffer from the following limitations:\n- They have limited provisions for upgrades and usually must be replaced entirely when new standards are introduced.\n- The individual components are not scalable in terms of performance and capacity, because the capacity of a component is fixed by the hardware implementation.\n- Specialized equipment and its associated specialized software require vendor-specific training for the mobile operator's staff.\n- Specialized hardware systems are usually supported and serviced by a single vendor, resulting in vendor lock-in.\n\nSDR is an important element of SDMN, because it replaces protocol-specific radio hardware with protocol-agnostic digital transceivers.\nWhile many earlier digital radio systems used field-programmable gate arrays (FPGAs) or special-purposed digital signal processors (DSPs) for calculations on baseband radio waveforms, the SDMN approach moves all of the baseband processing into general-purpose CPUs.\nSDMN radio systems also use hardware with publicly-documented interfaces that is designed to be readily reproducible by multiple manufacturers.\n\nSDMN designs avoid the use of components that are specialized as to their functions or that are available from only a single vendor.\nThis is true of both the hardware and software elements of the network.\n\nThe telephony switches of SDMN networks are software-based, including software transcoding for speech codecs.\n\nIn a new SDN architecture for wireless distribution systems (WDNs) is explored that eliminates the need for multi-hop flooding of route information and therefore enables WDNs to easily expand. The key idea is to split network control and data forwarding by using two separate frequency bands. The forwarding nodes and the SDN controller exchange link-state information and other network control signaling in one of the bands, while actual data forwarding takes place in the other band.\n\nThe SDMN approach has many advantages over hardware-based mobile network designs.\n- Because SDMN hardware is protocol-agnostic, upgrades are software-only, even across technology generations. In the radio network, these changes can even be made on a site-by-site basis.\n- Because SDMN hardware is designed to be easily sourced and reproduced:\n- SDMN equipment can be serviced by a wider range of vendors, lowering maintenance costs.\n- SDMN equipment can be manufactured anywhere in the world, lowering production costs.\n- Because SDMN software is based on commodity operating systems and development tools:\n- Support staff can be trained more quickly because they are already familiar with the underlying software systems.\n- Many aspects of the SDMN can be monitored and managed with pre-existing tools, because they are already available in the commodity operating systems.\n- Because SDMN network components run on general purpose computers, the network components can be scaled up in capacity by adding more computing power.\n", "related": "NONE"}
{"id": "203883", "url": "https://en.wikipedia.org/wiki?curid=203883", "title": "Interstellar communication", "text": "Interstellar communication\n\nInterstellar communication is the transmission of signals between planetary systems. Sending interstellar messages is potentially much easier than interstellar travel, being possible with technologies and equipment which are currently available. However, the distances from Earth to other potentially inhabited systems introduce prohibitive delays, assuming the limitations of the speed of light. Even an immediate reply to radio communications sent to stars tens of thousands of light-years away would take many human generations to arrive.\n\nThe SETI project has for the past several decades been conducting a search for signals being transmitted by extraterrestrial life located outside the Solar System, primarily in the radio frequencies of the electromagnetic spectrum. Special attention has been given to the Water Hole, the frequency of one of neutral hydrogen's absorption lines, due to the low background noise at this frequency and its symbolic association with the basis for what is likely to be the most common system of biochemistry (see Alternative biochemistry).\n\nThe regular radio pulses emitted by pulsars were briefly thought to be potential intelligent signals; the first pulsar to be discovered was originally designated \"LGM-1\", for \"Little Green Men.\" They were quickly determined to be of natural origin, however.\n\nSeveral attempts have been made to transmit signals to other stars as well. (See \"Realized projects\" at Active SETI.) One of the earliest and most famous was the 1974 radio message sent from the largest radio telescope in the world, the Arecibo Observatory in Puerto Rico. An extremely simple message was aimed at a globular cluster of stars known as M13 in the Milky Way Galaxy and at a distance of 30,000 light years from the Solar System. These efforts have been more symbolic than anything else, however. Further, a possible answer needs double the travel time, i.e. tens of years (near stars) or 60,000 years (M13).\n\nIt has also been proposed that higher frequency signals, such as lasers operating at visible light frequencies, may prove to be a fruitful method of interstellar communication; at a given frequency it takes surprisingly small energy output for a laser emitter to outshine its local star from the perspective of its target.\n\nOther more exotic methods of communication have been proposed, such as modulated neutrino or gravitational wave emissions. These would have the advantage of being essentially immune to interference by intervening matter.\n\nSending physical mail packets between stars may prove to be optimal for many applications. While mail packets would likely be limited to speeds far below that of electromagnetic or other light-speed signals (resulting in very high latency), the amount of information that could be encoded in only a few tons of physical matter could more than make up for it in terms of average bandwidth. The possibility of using interstellar messenger probes for interstellar communication — known as Bracewell probes — was first suggested by Ronald N. Bracewell in 1960, and the technical feasibility of this approach was demonstrated by the British Interplanetary Society's starship study Project Daedalus in 1978. Starting in 1979, Robert Freitas advanced arguments\n\n", "related": "\n- Interplanetary Internet\n- List of interstellar radio messages\n- Universal translator\n"}
{"id": "40837", "url": "https://en.wikipedia.org/wiki?curid=40837", "title": "Call-second", "text": "Call-second\n\nIn telecommunication, a call-second is a unit used to measure communications traffic density, equivalent to one call with a duration of one second. \n\nTraffic is measured independent of users. For example, one user making two 75-second calls is equivalent to two users each making one 75-second call, as each case produces 150 call-seconds of traffic. \n\nA CCS (centacall-second) is often used to describe 100 call-seconds, so 3600 call-seconds = 36 CCS = 1 call-hour. \n\nIn a communication network, a trunk (link) can carry numerous concurrent calls by means of multiplexing. Hence a particular number of call-seconds can be carried in infinitely many ways as calls are established and cleared over time. For example, one call-hour could be one call for an hour or two (possibly concurrent) calls for half an hour each. Call-seconds give a measure of the average number of concurrent calls.\n\nOffered load is defined as the traffic density per unit time, measured in erlangs. An erlang is defined as one call-hour per hour, or 3,600 call-seconds per hour.\n\nHence, if one CCS is measured over a one-hour period, the offered load is 1/36 erlangs.\n", "related": "NONE"}
{"id": "47888132", "url": "https://en.wikipedia.org/wiki?curid=47888132", "title": "Network Unaffiliated Virtual Operator", "text": "Network Unaffiliated Virtual Operator\n\nA Network Unaffiliated Virtual Operator (NUVO) is similar to a Mobile virtual network operator (MVNO) however it has one key difference — a NUVO is not affiliated with a specific carrier. \nNUVO's use real telephone numbers, and through these they combine with all other commercial operators, allowing NUVO users to communicate with anyone — not just other people who use a mobile App, for example.\n\nBy assigning telephone numbers to their users, NUVO's can transmit text messages and voice call to anyone who has a telephone number.\n\nThis allows an app user to communicate with anyone simply by dialing their phone number, rather than limiting their communications to just other app users, as most over the top content (OTT) apps do.\n\n", "related": "\n- MVNO\n- Over the top content\n- Mobile app\n- Voice call\n- Telephone number\n- Onoff telecom\n- Thumbtel\n"}
{"id": "48383737", "url": "https://en.wikipedia.org/wiki?curid=48383737", "title": "OSS/BSS", "text": "OSS/BSS\n\nOSS/BSS, in telecommunications, refer to operations support system and business support system. The distinction emphasizes a separation of concerns between maintaining network \"operations\" and the \"business\" around which that network is built. Communications service providers support a broad range of services and functions with their OSS/BSS. BSS primarily consists of order capture, Customer Relationship Management and Telecommunications billing whereas OSS covers Order Management, Network Inventory Management and Network Operations.\n\nPreviously OSS and BSS were more clearly separate entities but the term OSS/BSS (or occasionally BSS/OSS) has been in use since at least 2000.\n\n. The interface, for example, between the BSS capturing an order and the OSS fulfilling it could be quite simple.\n\nNow, with more complicated and differentiated products and services being offered much closer liaison between the two is required, for example processing an order may require information on the services the customer already has, the network they are using, and currently available resources.\n\nService providers in this area have even more requirements for an integrated OSS/BSS system.\nExamples include eCommerce, self-management, real time reporting, fraud prevention...\n", "related": "NONE"}
{"id": "48716424", "url": "https://en.wikipedia.org/wiki?curid=48716424", "title": "FS-FHSS", "text": "FS-FHSS\n\nFrequency selection and frequency hopping communication technology is a unique spread spectrum communication technology.\nFS-FHSS is developed to be applied in various wireless communication fields. It is innovated by GONSIN, a Chinese company. It has developed the unique FS-FHSS based on the spread spectrum communication technology. The new technology can monitor and select the undisturbed frequency band. FS-FHSS makes sure the stability of the communication. It is applied to GONSIN wireless conference system, which implements the discussion、simultaneous interpretation、voting and others comprehensive conference application functions. \n\nThe feature of FS-FHSS: it uses the 2.4 GHz global frequency band, it does not require certificate. The wireless frequency points are abundant, 80 frequency points could be used; 2.4 GHz has high frequency carrier, the signal diffractivity is relatively weak so that other 2.4 GHz signal could not interfere the conference signal. Adopt FS-FHSS technology, it detect the wireless environment and select the usable frequency point before the conference, during the conference, it hops between the backup frequency points, which can avoid the interference source. It utilizes the efficient digital audio encode and decode technology, one frequency point can transmit 4 channels, it just need two frequency points to transmit 8 channels simultaneous interpretation signals. Because the system occupies relatively less frequency points resource and utilizes the FS-FHSS technology to operate, it can co-work with WIFI and other 2.4 GHz system. It applies the digital audio encryption and digital modulation to avoid any interception and malicious interference; the signal transmitting power could be modified in according with the application occasion, the adjusting range is from 50 meters to 500 meters( the customized system can cover 2,000 meters).\n\nSPREAD SPECTRUM The idea of spread-spectrum radio transmission was proposed by the military who was seeking ways to prevent radio signals from being monitored or blocked by hostile parties. The two inventors came up with the notion of changing the frequency of a transmission at regular intervals faster than the enemy could retune. A special receiver that knew the frequency-hopping pattern could follow it and pick up the entire transmission. The hopping patterns were controlled by the\npunched holes in piano rolls became known as frequency-hopping spread spectrum(FHSS).\n", "related": "NONE"}
{"id": "334420", "url": "https://en.wikipedia.org/wiki?curid=334420", "title": "Telecommunications device for the deaf", "text": "Telecommunications device for the deaf\n\nA telecommunications device for the deaf (TDD) is a teleprinter, an electronic device for text communication over a telephone line, that is designed for use by persons with hearing or speech difficulties. Other names for the device include teletypewriter (TTY), textphone (common in Europe), and minicom (United Kingdom).\n\nThe typical TDD is a device about the size of a typewriter or laptop computer with a QWERTY keyboard and small screen that uses an LED, LCD, or VFD screen to display typed text electronically. In addition, TDDs commonly have a small spool of paper on which text is also printedold versions of the device had only a printer and no screen. The text is transmitted live, via a telephone line, to a compatible device, i.e. one that uses a similar communication protocol.\n\nSpecial telephone services have been developed to carry the TDD functionality even further. In certain countries, there are systems in place so that a deaf person can communicate with a hearing person on an ordinary voice phone using a human relay operator. There are also \"carry-over\" services, enabling people who can hear but cannot speak (\"hearing carry-over,\" a.k.a. \"HCO\"), or people who cannot hear but are able to speak (\"voice carry-over,\" a.k.a. \"VCO\") to use the telephone.\n\nThe term TDD is sometimes discouraged because people who are deaf are increasingly using mainstream devices and technologies to carry out most of their communication. The devices described here were developed for use on the partially-analog Public Switched Telephone Network (PSTN). They do not work well on the new internet protocol (IP) networks. Thus as society increasingly moves toward IP based telecommunication, the telecommunication devices used by people who are deaf will not be TDDs. In the US the devices are referred to as TTYs.\n\nTeletype Corporation, of Skokie, Illinois, made page printers for text, notably for news wire services and telegrams, but these used standards different from those for deaf communication, and although in quite widespread use, were technically incompatible. Furthermore, these were sometimes referred to by the \"TTY\" initialism, short for \"Teletype\". When computers had keyboard input mechanisms and page printer output, before CRT terminals came into use, Teletypes were the most widely used devices. They were called \"console typewriters\". (Telex used similar equipment, but was a separate international communication network.)\n\nThe TDD concept was developed by James C. Marsters (1924–2009), a dentist and private airplane pilot who became deaf as an infant because of scarlet fever, and Robert Weitbrecht, a deaf physicist. In 1964, Marsters, Weitbrecht and Andrew Saks, an electrical engineer and grandson of the founder of the Saks Fifth Avenue department store chain, founded APCOM (Applied Communications Corp.), located in the San Francisco Bay area, to develop the acoustic coupler, or modem; their first product was named the PhoneType. APCOM collected old teleprinter machines (TTYs) from the Department of Defense and junkyards. Acoustic couplers were cabled to TTYs enabling the AT&T standard Model 500 telephone to couple, or fit, into the rubber cups on the coupler, thus allowing the device to transmit and receive a unique sequence of tones generated by the different corresponding TTY keys. The entire configuration of teleprinter machine, acoustic coupler, and telephone set became known as the TTY. Weitbrecht invented the acoustic coupler modem in 1964. The actual mechanism for TTY communications was accomplished electro-mechanically through frequency shift keying (FSK) allowing only half-duplex communication, where only one person at a time can transmit.\n\nDuring the late 1960s, Paul Taylor combined Western Union Teletype machines with modems to create teletypewriters, known as TTYs. He distributed these early, non-portable devices to the homes of many in the deaf community in St. Louis, Missouri. He worked with others to establish a local telephone wake-up service. In the early 1970s, these small successes in St. Louis evolved into the nation's first local telephone relay system for the deaf.\n\nIn 1973, the Manual Communications Module (MCM), which was the world's first electronic portable TTY allowing two-way telecommunications, premiered at the California Association of the Deaf convention in Sacramento, California. The battery-powered MCM was invented and designed by a deaf news anchor and interpreter, Kit Patrick Corson, in conjunction with Michael Cannon and physicist Art Ogawa. It was manufactured by Michael Cannon's company, Micon Industries, and initially marketed by Kit Corson's company, Silent Communications. In order to be compatible with the existing TTY network, the MCM was designed around the five-bit Baudot code established by the older TTY machines instead of the ASCII code used by computers. The MCM was an instant success with the deaf community despite the drawback of a $599 cost. Within six months there were more MCMs in use by the deaf and hard of hearing than TTY machines. After a year Micon took over the marketing of the MCM and subsequently concluded a deal with Pacific Bell (who coined the term \"TDD\") to purchase MCMs and rent them to deaf telephone subscribers for $30 per month.\n\nAfter Micon formed an alliance with APCOM, Michael Cannon (Micon), Paul Conover (Micon), and Andrea Saks (APCOM) successfully petitioned the California Public Utilities Commission (CPUC), resulting in a tariff that paid for TTY devices to be distributed free of cost to deaf persons. Micon produced over 1,000 MCMs per month, resulting in approximately 50,000 MCMs being disseminated into the deaf community.\n\nBefore he left Micon in 1980, Michael Cannon developed several computer compatible variations of the MCM and a portable, battery operated printing TTY, but they were never as popular as the original MCM. Newer model TTYs could communicate with selectable codes that allow communications at a higher bit rate on those models similarly equipped. However, the lack of true computer interface functionality spelled the demise of the original TTY and its clones. During the mid-1970s, other so-called portable telephone devices were being cloned by other companies, and this was the time period when the term \"TDD\" began being used largely by those outside the deaf community.\n\nThis relay system became known commonly as the Def-Tone System (DTS) because the tones representing letters of the alphabet were eventually carried in tones outside the range of human hearing. In 1994 Joseph Alan Poirier, a college student-worker, recommended using the system to send texts to fork lifts to improve delivery of parts to the assembly line at GM Powertrain in Toledo, Ohio, & sending a text to pagers. He recommended taking pagers to alphanumeric displays incorporating the same system in discussions with the pager supplier for Outback Steakhouse. & having relays put in the forklifts to ping alert messages to the pagers used in that system. He called it text messaging. It is theorized that when Toyota forklift was allegedly hired by GM for this work, one of the subcontractors, Kyocera, utilized the work for the Toyota forklift company to create text messaging for cell phones.\n\nIn 2009, AT&T received the James C. Marsters Promotion Award from TDI (formerly Telecommunications for the Deaf, Inc.) for its efforts to increase accessibility to communication for people with disabilities. The award holds some irony; it was AT&T that, in the 1960s, resisted efforts to implement TTY technology, claiming it would damage its communication equipment. In 1968, the Federal Communications Commission struck down AT&T's policy and forced it to offer TTY access to its network.\n\nThere are many different standards for TDDs and textphones.\n\nThe original standard used by TTYs is a variant of the Baudot code. The maximum speed of this protocol is 10 characters per second. This is a half-duplex protocol, which means that only one person at a time may transmit characters. If both try to transmit at the same time, the characters will be garbled on the other end.\n\nThis protocol is commonly used in the United States.\n\nThis is a variant of the Baudot code, implemented as 5-bits per character transmitted asynchronously using frequency shift key-modulation at either 45.5 or 50 baud, 1 start bit, 5 data bits, and 1.5 stop bits. Details of the protocol implementation are available in TIA-825-A and also in T-REC V.18 Annex A \"5-bit operational mode\".\n\nThe UltraTec company implements another protocol known as Enhanced TTY, which it calls \"Turbo Code,\" in its products. Turbo Code has some advantages over Baudot protocols, such as a higher data rate, full ASCII compliance, and full-duplex capability. However, Turbo Code is proprietary, and UltraTec gives its specifications only to parties who are willing to license it, although some information concerning it is disclosed in .\n\nOther protocols used for text telephony are European Deaf Telephone (EDT) and dual-tone multi-frequency signaling (DTMF).\n\nThe ITU V series recommendations are a collection of early modem standards approved by the ITU in 1988.\n\n- ITU V.21 specifies 300 bits per second duplex mode.\n- ITU V.23 specifies audio frequency-shift keying modulation to encode and transfer data at 600/1200 bits per second.\n\nIn 1994, the ITU approved the V.18 standard, which comprises two major parts, a dual standard. It is both an umbrella protocol that allows recognition and interoperability of some of the most commonly used textphone protocols, as well as offering a native V.18 mode, which is an ASCII full- or half-duplex modulation method.\n\nComputers can, with appropriate software and modem, emulate a V.18 TTY. Some voice modems, coupled with appropriate software, can now be converted to TTY modems by using a software-based decoder for TTY tones. Same can be done with such software using a computer's sound card, when coupled to the telephone line.\n\nIn the UK, a virtual V.18 network, called TextDirect, exists as part of the Public Switched Telephone Network (PSTN), thereby offering interoperability between textphones using different protocols. The platform also offers additional functionality like call progress and status information in text and automatic invocation of a relay service for speech-to-text calls.\n\nMany digital cell phones are compatible with TTY devices.\n\nMany people want to replace TTY with real-time text over IP (RTT), which can be used on a digital cell phone or tablet without a separate TTY device.\n\nAs TDDs are increasingly considered legacy devices, with the emergence of modern technologies such as email, texting and instant messaging, text from TDD are increasingly being sent over Text over IP gateways, or other real-time text protocols. However, these newer methods require IP connections and will not work with regular analog phone lines, unless a data connection is used (i.e. dial-up Internet, or the modem method of multiplexing text and voice that is done on a Captioned Telephone hardware handset). Because some people have no access to any kind of data connection, and it is not even available in some parts within many countries, TTYs are still the only method for analog landline text phone calls, although TTYs include any device with a suitable modem and software.\n\nIn addition to TDD, there are a number of pieces of equipment that can be coupled to telephones to improve their utility. For those with hearing difficulties the telephone ring and conversation sound level can be amplified or pitch adjusted; ambient noise can also be filtered. The amplifier can be a simple addition or through an inductive coupler to interact with suitable hearing aids. The ring can also be supplemented with extension bells or a visual call indicator.\n\nThere are some etiquette rules that users of TTYs must be aware of. Because of the inability to detect when a person has finished speaking, (and the fact that two people typing will scramble the text on both ends) the term \"Go Ahead\" (GA) is used to denote the end of a turn, and an indication for the other person to begin typing. \n\nCaller A: HELLO JOHN, WHAT TIME WILL YOU BE COMING AROUND TODAY Q GA <br>\nCaller B: HI FRED, I WILL BE AROUND NOON GA <br>\nCaller A: OK, NO PROBLEM, DON'T FORGET TO BRING THE BOOKS AND THE WORK SO FAR GA <br>\nCaller B: WILL DO SK <br>\nCaller A: BYE BYE SKSK\n\nSK is used to allow the users to say their farewells, while SKSK indicates an immediate call hang-up.\n\nCaller A HI, THIS IS JOHN, CAN I ASK WHO IS CALLING? GA <br>\nCaller B HI JOHN, ITS ME FRED, I AM WONDERING WHERE YOU ARE, ITS GETTING LATE TO GO OUT TO THE PUB GA <br>\nCaller A HI FRED, SORRY I DONT THINK I CAN GO GA <br>\nCaller B WHY CANT YOU GO? GA <br>\nCaller A MY WIFE IS NOT FEELING WELL AND I HAVE NO BABYSITTER FOR MY KIDS! GA <br>\nCaller B AWWWW DARN. I WANTED YOU THERE. OH WELL WHAT CAN YOU DO ? GA <br>\nCaller A I KNOW.. I GOTTA GO. THE KIDS NEED ME. SEE YOU AROUND! BYE FOR NOW SK <br>\nCaller B OK NO WORRIES SEE YOU SOON! BYE BYE SK GA <br>\nCaller A SKSK (THE PARTY HAS HUNG UP)\n\nCaller A TXD DIALING.. TXD RING... TXD OPERATOR CONNECTED.. EXPLAINING TEXT RELAY SERVICE. PLEASE WAIT... HI THIS IS JOHN GA <br>\nCaller B HI JOHN ITS ME FRED. I AM WONDERING WHAT YOU ARE DOING TONIGHT? GA <br>\nCaller A HI FRED. I AM THINKING OF HAVING A POKER NIGHT AT MINE, WHAT DO YOU THINK? GA <br>\nCaller B GOOD IDEA, I'LL CALL A FEW MATES TO COME ROUND AND HAVE A GOOD GAME GA <br>\nCaller A OK SEE YOU AT 7PM. BYE BYE SK GA <br>\nCaller B OK SEE YOU AT 7PM BYE BYE SKSKSKSK GA <br>\nCaller A THANK YOU FOR USING TEXT RELAY SERVICE. GOODBYE\n\n\"Note: TTYs use only capital letters except when there are computer screens.\" <br>\n\"Note: In the UK, Text relay service used to be called typetalk (RNID) but have since merged with the phone line using the dialling prefix 18001 (TTY) or the 18002 (voice relay). The emergency line is 18000 (TTY).\n\nOne of the most common uses for a TTY is to place calls to a Telecommunications Relay Service (TRS), which makes it possible for the deaf to successfully make phone calls to users of regular phone systems.\n\nThe voice recognition systems are in limited use, due to problems with the technology. A new development called the captioned telephone now uses voice recognition to assist the human operators. Newer text-based communication methods, such as short message service (SMS), Internet Relay Chat (IRC), and instant messaging have also been adopted by the deaf as an alternative or adjunct to TTY.\n\n", "related": "\n- List of video telecommunication services and product brands\n- Paul Taylor (engineer)\n- Robert H. Weitbrecht\n- Telecommunications relay service\n- Video relay service (VRS), using videotelephony\n\n- Lang, Harry G. (2000). \"A Phone of Our Own: the Deaf Insurrection Against Ma Bell.\" Washington, D.C.: Gallaudet University Press. ;\n- Readmond, Kim. \"Paul and Sally Taylor Background Sheet,\" Central Institute for the Deaf (St. Louis, Missouri).\n- Strauss, Karen Peltz. (2006). \"A New Civil Right: Telecommunications Equality for Deaf and Hard of Hearing Americans.\" Washington, D.C.: Gallaudet University Press. ;\n"}
{"id": "11288562", "url": "https://en.wikipedia.org/wiki?curid=11288562", "title": "Cloud9 (service provider)", "text": "Cloud9 (service provider)\n\nCloud9 is a mobile network operator focussed on providing mobile subscriptions over the air to programmable SIM cards, SoftSIMs and eSIMs. Their service is used in both smartphones and IoT devices.\n\nCloud9, originally owned by Wire9 Telecom Plc, funded and established by investor and telecom specialist, Lee Jones, before being sold for an undisclosed sum by Jones to billionaire Romain Zaleski. It established in the UK, Gibraltar, and Isle of Man as a domestic Mobile Network Operator. Cloud9 obtained spectrum licenses in the Isle of Man in 2007 and Gibraltar in 2010. Around 2011, Cloud9 decided to focus on supplying global SIM cards to save roaming charges. The Gibraltar spectrum licence was sold to another company. The business relocated its core network to Telehouse in London and became a subsidiary of BlueMango Technologies Ltd.\n\nThe company is privately held with headquarters in the United Kingdom.\n\nCloud9 have shipped several million 'Travel SIMs'. They do not supply end users instead preferring to offer a white label service to travel and telecoms resellers. All SIM cards have been branded with the logo of these resellers.\n\nIn addition the company now provides the digital signatures ( 'profiles' or 'IMSIs' ) that provide a SIM card with the ability to register with a network and function. These can be provisioned over the air to dynamic SIM cards such as programmable removable UICCs, SoftSIMs and eSIMs. They are members of the GSM Association and are involved in the GSMA remote SIM provisioning standard for eSIMs that will be released soon.\n\nRemotely provisioned SIMs are gaining traction with smartphone manufacturers (SoftSIMs) and IoT devices (eSIMs).\n\nCloud9 continue to sell SIMs for travellers on a white label basis in addition to the above.\n\nIts Mobile Country Code is 234 and its Mobile Network Code is 18. TADIG code is GBRC9.\n\nThe company has been allocated the following UK number ranges by Ofcom:\n\n4478722, 4477000, 4474409, 4479782, 4479783 and 4475588\n\nIn 2013 they acquired the IPR of a UK manufacturer of core networks, Zynetix Ltd. This means that they now possess all of their own IPR with regards to their core network (HLR/SMSC/GGSN/GMSC etc.). and supply core network components to other companies. Through this they have achieved sales as an MVNE. The Cloud9 core network additionally supports 4G (HSS/PDG).\n\nThe core network is hosted on Cloud9 servers at Telehouse near Canary Wharf in London. Additional components are hosted in Amazon Web Services facilities around the world in order to minimise latency and provide scalability.\n\nThe company has been voted as a Red Herring Top 100 Europe finalist.\n", "related": "NONE"}
{"id": "113604", "url": "https://en.wikipedia.org/wiki?curid=113604", "title": "Broadcasting", "text": "Broadcasting\n\nBroadcasting is the distribution of audio or video content to a dispersed audience via any electronic mass communications medium, but typically one using the electromagnetic spectrum (radio waves), in a one-to-many model. Broadcasting began with AM radio, which came into popular use around 1920 with the spread of vacuum tube radio transmitters and receivers. Before this, all forms of electronic communication (early radio, telephone, and telegraph) were one-to-one, with the message intended for a single recipient. The term \"broadcasting\" evolved from its use as the agricultural method of sowing seeds in a field by casting them broadly about. It was later adopted for describing the widespread distribution of information by printed materials or by telegraph. Examples applying it to \"one-to-many\" radio transmissions of an individual station to multiple listeners appeared as early as 1898.\n\nOver the air broadcasting is usually associated with radio and television, though in recent years, both radio and television transmissions have begun to be distributed by cable (cable television). The receiving parties may include the general public or a relatively small subset; the point is that anyone with the appropriate receiving technology and equipment (e.g., a radio or television set) can receive the signal. The field of broadcasting includes both government-managed services such as public radio, community radio and public television, and private commercial radio and commercial television. The U.S. Code of Federal Regulations, title 47, part 97 defines \"broadcasting\" as \"transmissions intended for reception by the general public, either direct or relayed\". Private or two-way telecommunications transmissions do not qualify under this definition. For example, amateur (\"ham\") and citizens band (CB) radio operators are not allowed to broadcast. As defined, \"transmitting\" and \"broadcasting\" are not the same.\n\nTransmission of radio and television programs from a radio or television station to home receivers by radio waves is referred to as \"over the air\" (OTA) or terrestrial broadcasting and in most countries requires a broadcasting license. Transmissions using a wire or cable, like cable television (which also retransmits OTA stations with their consent), are also considered broadcasts but do not necessarily require a license (though in some countries, a license is required). In the 2000s, transmissions of television and radio programs via streaming digital technology have increasingly been referred to as broadcasting as well.\n\nThe earliest broadcasting consisted of sending telegraph signals over the airwaves, using Morse code, a system developed in the 1830s by Samuel F.B. Morse, physicist Joseph Henry and Alfred Vail. They developed an electrical telegraph system which sent pulses of electric current along wires which controlled an electromagnet that was located at the receiving end of the telegraph system. A code was needed to transmit natural language using only these pulses, and the silence between them. Morse therefore developed the forerunner to modern International Morse code. This was particularly important for ship-to-ship and ship-to-shore communication, but it became increasingly important for business and general news reporting, and as an arena for personal communication by radio amateurs (Douglas, op. cit.). Audio broadcasting began experimentally in the first decade of the 20th century. By the early 1920s radio broadcasting became a household medium, at first on the AM band and later on FM. Television broadcasting started experimentally in the 1920s and became widespread after World War II, using VHF and UHF spectrum. Satellite broadcasting was initiated in the 1960s and moved into general industry usage in the 1970s, with DBS (Direct Broadcast Satellites) emerging in the 1980s.\n\nOriginally all broadcasting was composed of analog signals using analog transmission techniques but in the 2000s, broadcasters have switched to digital signals using digital transmission. In general usage, broadcasting most frequently refers to the transmission of information and entertainment programming from various sources to the general public.\n- Analog audio vs. HD Radio\n- Analog television vs. Digital television\n- Wireless\n\nThe world's technological capacity to receive information through one-way broadcast networks more than quadrupled during the two decades from 1986 to 2007, from 432 exabytes of (optimally compressed) information, to 1.9 zettabytes. This is the information equivalent of 55 newspapers per person per day in 1986, and 175 newspapers per person per day by 2007.\n\nHistorically, there have been several methods used for broadcasting electronic media audio and video to the general public:\n- Telephone broadcasting (1881–1932): the earliest form of electronic broadcasting (not counting data services offered by stock telegraph companies from 1867, if ticker-tapes are excluded from the definition). Telephone broadcasting began with the advent of Théâtrophone (\"Theatre Phone\") systems, which were telephone-based distribution systems allowing subscribers to listen to live opera and theatre performances over telephone lines, created by French inventor Clément Ader in 1881. Telephone broadcasting also grew to include telephone newspaper services for news and entertainment programming which were introduced in the 1890s, primarily located in large European cities. These telephone-based subscription services were the first examples of electrical/electronic broadcasting and offered a wide variety of programming.\n- Radio broadcasting (experimentally from 1906, commercially from 1920); audio signals sent through the air as radio waves from a transmitter, picked up by an antenna and sent to a receiver. Radio stations can be linked in radio networks to broadcast common radio programs, either in broadcast syndication, simulcast or subchannels.\n- Television broadcasting (telecast), experimentally from 1925, commercially from the 1930s: an extension of radio to include video signals.\n- Cable radio (also called \"cable FM\", from 1928) and cable television (from 1932): both via coaxial cable, originally serving principally as transmission media for programming produced at either radio or television stations, but later expanding into a broad universe of cable-originated channels.\n- Direct-broadcast satellite (DBS) (from c. 1974) and satellite radio (from c. 1990): meant for direct-to-home broadcast programming (as opposed to studio network uplinks and downlinks), provides a mix of traditional radio or television broadcast programming, or both, with dedicated satellite radio programming. (See also: Satellite television)\n- Webcasting of video/television (from c. 1993) and audio/radio (from c. 1994) streams: offers a mix of traditional radio and television station broadcast programming with dedicated Internet radio and Internet television.\n\nThere are several means of providing financial support for continuous broadcasting:\n- Commercial broadcasting: for-profit, usually privately owned stations, channels, networks, or services providing programming to the public, supported by the sale of air time to advertisers for radio or television advertisements during or in breaks between programs, often in combination with cable or pay cable subscription fees.\n- Public broadcasting: usually non-profit, publicly owned stations or networks supported by license fees, government funds, grants from foundations, corporate underwriting, audience memberships, contributions or a combination of these.\n- Community broadcasting: a form of mass media in which a television station, or a radio station, is owned, operated or programmed, by a community group to provide programs of local interest known as local programming. Community stations are most commonly operated by non-profit groups or cooperatives; however, in some cases they may be operated by a local college or university, a cable company or a municipal government.\n\nBroadcasters may rely on a combination of these business models. For example, in the United States, National Public Radio (NPR) and the Public Broadcasting Service (PBS, television) supplement public membership subscriptions and grants with funding from the Corporation for Public Broadcasting (CPB), which is allocated bi-annually by Congress. US public broadcasting corporate and charitable grants are generally given in consideration of underwriting spots which differ from commercial advertisements in that they are governed by specific FCC restrictions, which prohibit the advocacy of a product or a \"call to action\".\n\nThe first regular television broadcasts started in 1937. Broadcasts can be classified as \"recorded\" or \"live\". The former allows correcting errors, and removing superfluous or undesired material, rearranging it, applying slow-motion and repetitions, and other techniques to enhance the program. However, some live events like sports television can include some of the aspects including slow-motion clips of important goals/hits, etc., in between the live television telecast. American radio-network broadcasters habitually forbade prerecorded broadcasts in the 1930s and 1940s requiring radio programs played for the Eastern and Central time zones to be repeated three hours later for the Pacific time zone (See: Effects of time on North American broadcasting). This restriction was dropped for special occasions, as in the case of the German dirigible airship \"Hindenburg\" disaster at Lakehurst, New Jersey, in 1937. During World War II, prerecorded broadcasts from war correspondents were allowed on U.S. radio. In addition, American radio programs were recorded for playback by Armed Forces Radio radio stations around the world.\n\nA disadvantage of recording first is that the public may know the outcome of an event from another source, which may be a \"spoiler\". In addition, prerecording prevents live radio announcers from deviating from an officially approved script, as occurred with propaganda broadcasts from Germany in the 1940s and with Radio Moscow in the 1980s. Many events are advertised as being live, although they are often \"recorded live\" (sometimes called \"live-to-tape\"). This is particularly true of performances of musical artists on radio when they visit for an in-studio concert performance. Similar situations have occurred in television production (\"\"The Cosby Show\" is recorded in front of a live television studio audience\") and news broadcasting.\n\nA broadcast may be distributed through several physical means. If coming directly from the radio studio at a single station or television station, it is simply sent through the studio/transmitter link to the transmitter and hence from the television antenna located on the radio masts and towers out to the world. Programming may also come through a communications satellite, played either live or recorded for later transmission. Networks of stations may simulcast the same programming at the same time, originally via microwave link, now usually by satellite. Distribution to stations or networks may also be through physical media, such as magnetic tape, compact disc (CD), DVD, and sometimes other formats. Usually these are included in another broadcast, such as when electronic news gathering (ENG) returns a story to the station for inclusion on a news programme.\n\nThe final leg of broadcast distribution is how the signal gets to the listener or viewer. It may come over the air as with a radio station or television station to an antenna and radio receiver, or may come through cable television or cable radio (or \"wireless cable\") via the station or directly from a network. The Internet may also bring either internet radio or streaming media television to the recipient, especially with multicasting allowing the signal and bandwidth to be shared. The term \"broadcast network\" is often used to distinguish networks that broadcast an over-the-air television signals that can be received using a tuner (television) inside a television set with a television antenna from so-called networks that are broadcast only via cable television (cablecast) or satellite television that uses a dish antenna. The term \"broadcast television\" can refer to the television programs of such networks.\n\nThe sequencing of content in a broadcast is called a schedule. As with all technological endeavors, a number of technical terms and slang have developed. A list of these terms can be found at List of broadcasting terms. Television and radio programs are distributed through radio broadcasting or cable, often both simultaneously. By coding signals and having a cable converter box with decoding equipment in homes, the latter also enables subscription-based channels, pay-tv and pay-per-view services. In his essay, John Durham Peters wrote that communication is a tool used for dissemination. Durham stated, \"Dissemination is a lens—sometimes a usefully distorting one—that helps us tackle basic issues such as interaction, presence, and space and time...on the agenda of any future communication theory in general\" (Durham, 211). Dissemination focuses on the message being relayed from one main source to one large audience without the exchange of dialogue in between. It is possible for the message to be changed or corrupted by government officials once the main source releases it. There is no way to predetermine how the larger population or audience will absorb the message. They can choose to listen, analyze, or simply ignore it. Dissemination in communication is widely used in the world of broadcasting.\n\nBroadcasting focuses on getting a message out and it is up to the general public to do what they wish with it. Durham also states that broadcasting is used to address an open-ended destination (Durham, 212). There are many forms of broadcasting, but they all aim to distribute a signal that will reach the target audience. Broadcasters typically arrange audiences into entire assemblies (Durham, 213). In terms of media broadcasting, a radio show can gather a large number of followers who tune in every day to specifically listen to that specific disc jockey. The disc jockey follows the script for his or her radio show and just talks into the microphone. He or she does not expect immediate feedback from any listeners. The message is broadcast across airwaves throughout the community, but there the listeners cannot always respond immediately, especially since many radio shows are recorded prior to the actual air time.\n\n- Carey, James (1989) \"Communication as Culture\", Routledge, New York and London, pp. 201–30\n- Kahn, Frank J., ed. \"Documents of American Broadcasting,\" fourth edition (Prentice-Hall, Inc., 1984).\n- Lichty Lawrence W., and Topping Malachi C., eds. \"American Broadcasting: A Source Book on the History of Radio and Television\" (Hastings House, 1975).\n- Meyrowitz, Joshua., \"Mediating Communication: What Happens?\" in Downing, J., Mohammadi, A., and Sreberny-Mohammadi, A., (eds) \"Questioning The Media\" (Sage, Thousand Oaks, 1995) pp. 39–53\n- Peters, John Durham. \"Communication as Dissemination.\" Communication as...Perspectives on Theory. Thousand Oakes, CA: Sage, 2006. 211–22.\n- Thompson, J., \"The Media and Modernity,\" in Mackay, H and O'Sullivan, T (eds) \"The Media Reader: Continuity and Transformation\"., (Sage, London, 1999) pp. 12–27\n\n- International bibliography – History of wireless and radio broadcasting\n\n- Gilbert, Sean; Nelson, John; Jacobs, George, \"World Radio TV Handbook 2007\", Watson-Guptill, 2006. . The 2007 edition of the \"World Radio TV Handbook\".\n- Wells, Alan, \"World Broadcasting: A Comparative View\", Greenwood Publishing Group, 1996.\n\n- Radio Locator, for American radio station with format, power, and coverage information.\n- Jim Hawkins' Radio and Broadcast Technology Page – History of broadcast transmitter\n- Indie Digital Cinema Services – Broadcast Industry Glossary\n", "related": "NONE"}
{"id": "41705", "url": "https://en.wikipedia.org/wiki?curid=41705", "title": "Signal-to-crosstalk ratio", "text": "Signal-to-crosstalk ratio\n\nThe signal-to-crosstalk ratio at a specified point in a circuit is the ratio of the power of the wanted signal to the power of the unwanted signal from another channel. \n\nThe signals are adjusted in each channel so that they are of equal power at the zero transmission level point in their respective channels. \n\nThe signal-to-crosstalk ratio is usually expressed in dB. \n", "related": "NONE"}
{"id": "15199671", "url": "https://en.wikipedia.org/wiki?curid=15199671", "title": "Common-mode signal", "text": "Common-mode signal\n\nCommon-mode signal is the component of an analog signal which is present with one sign on all considered conductors. In telecommunication, common-mode signal on a transmission line is known as longitudinal voltage.\n\nIn electronics where the signal is transferred by differential voltage, the common-mode signal is a half-sum of voltages\n\nWhen referenced to the local common or ground, a common-mode signal appears on both lines of a two-wire cable, in-phase and with equal amplitudes. Technically, a common-mode voltage is one-half the vector sum of the voltages from each conductor of a balanced circuit to local ground or common. Such signals can arise from one or more of the following sources:\n- Radiated signals coupled equally to both lines,\n- An offset from signal common created in the driver circuit, or\n- A ground differential between the transmitting and receiving locations.\n\nNoise induced into a cable, or transmitted from a cable usually occurs in the common mode; i.e. the same signal tends to be picked up by both conductors in a two wire cable. Likewise, RF noise transmitted from a cable tends to emanate from both conductors. Elimination of common mode signals on cables entering or leaving electronic equipment is important to ensure electromagnetic compatibility. Unless the intention is to transmit or receive radio signals, an electronic designer will generally design electronic circuits to minimise or eliminate common mode effects.\n\n- Differential amplifiers or receivers that respond only to voltage differences, \"e.g.,\" those between the wires that constitute a pair. This method is particularly suited for instrumentation where signals are transmitted through DC bias.\n- An inductor where a pair of signalling wires follow the same path through the inductor. E.g. in a bifilar winding configuration such as used in Ethernet magnetics. Useful for AC and DC signals, but will filter only higher frequency common mode signals.\n- A transformer, which is useful for AC signals only, and will filter any form of common mode noise, but may be used in combination with a bifilar wound coil to eliminate capacitive coupling of higher frequency common mode signals across the transformer. Used in twisted pair Ethernet.\n\nCommon mode filtering may also be used to prevent egress of noise for electromagnetic compatibility purposes.\nHigh frequency common mode signals, for example, RF noise from a computing circuit, may be blocked using a ferrite bead clamped to the outside of a cable. These are often observable on laptop computer power supplies near the jack socket, and good quality mouse or printer USB cables and HDMI cables.\n\nSwitch mode power supplies include common and differential mode filtering inductors to block the switching signal noise returning into mains wiring.\n\n", "related": "\n- Common-mode rejection ratio\n"}
{"id": "14503680", "url": "https://en.wikipedia.org/wiki?curid=14503680", "title": "Unger model", "text": "Unger model\n\nThe Unger Model is an empirical standard model for near end crosstalk (NEXT) power spectra as experienced by communication systems over unshielded twisted pair (UTP).\n\nTwisted pair cables are usually grouped together in a binder where they experience crosstalk. Based on empirical observations, Unger proposed that, at the 1% worst case, the NEXT power spectra formula_1, due to a single disturber, can be bounded by\n<br>\nwhile the NEXT power spectra due to 49 disturbers (full binder) can be bounded by\n<br>\n\n", "related": "\n- DSL\n- Crosstalk\n"}
{"id": "40546894", "url": "https://en.wikipedia.org/wiki?curid=40546894", "title": "Signal-to-interference-plus-noise ratio", "text": "Signal-to-interference-plus-noise ratio\n\nIn information theory and telecommunication engineering, the signal-to-interference-plus-noise ratio (SINR) (also known as the signal-to-noise-plus-interference ratio (SNIR)) is a quantity used to give theoretical upper bounds on channel capacity (or the rate of information transfer) in wireless communication systems such as networks. Analogous to the signal-to-noise ratio (SNR) used often in wired communications systems, the SINR is defined as the power of a certain signal of interest divided by the sum of the interference power (from all the other interfering signals) and the power of some background noise. If the power of noise term is zero, then the SINR reduces to the signal-to-interference ratio (SIR). Conversely, zero interference reduces the SINR to the SNR, which is used less often when developing mathematical models of wireless networks such as cellular networks.\n\nThe complexity and randomness of certain types of wireless networks and signal propagation has motivated the use of stochastic geometry models in order to model the SINR, particularly for cellular or mobile phone networks.\n\nSINR is commonly used in wireless communication as a way to measure the quality of wireless connections. Typically, the energy of a signal fades with distance, which is referred to as a path loss in wireless networks. Conversely, in wired networks the existence of a wired path between the sender or transmitter and the receiver determines the correct reception of data. In a wireless network one has to take other factors into account (e.g. the background noise, interfering strength of other simultaneous transmission). The concept of SINR attempts to create a representation of this aspect.\n\nThe definition of SINR is usually defined for a particular receiver (or user). In particular, for a receiver located at some point \"x\" in space (usually, on the plane), then its corresponding SINR given by\n\nwhere \"P\" is the power of the incoming signal of interest, \"I\" is the interference power of the other (interfering) signals in the network, and \"N\" is some noise term, which may be a constant or random. Like other ratios in electronic engineering and related fields, the SINR is often expressed in decibels or dB.\n\nTo develop a mathematical model for estimating the SINR, a suitable mathematical model is needed to represent the propagation of the incoming signal and the interfering signals. A common model approach is to assume the propagation model consists of a random component and non-random (or deterministic) component.\n\nThe deterministic component seeks to capture how a signal decays or attenuates as it travels a medium such as air, which is done by introducing a path-loss or attenuation function. A common choice for the path-loss function is a simple power-law. For example, if a signal travels from point \"x\" to point \"y\", then it decays by a factor given by the path-loss function\n\nwhere the path-loss exponent \" α>2\", and \"|x-y|\" denotes the distance between point \"y\" of the user and the signal source at point \"x\". Although this model suffers from a singularity (when \"x=y\"), its simple nature results in it often being used due to the relatively tractable models it gives. Exponential functions are sometimes used to model fast decaying signals.\n\nThe random component of the model entails representing multipath fading of the signal, which is caused by signals colliding with and reflecting off various obstacles such as buildings. This is incorporated into the model by introducing a random variable with some probability distribution. The probability distribution is chosen depending on the type of fading model and include Rayleigh, Rician, log-normal shadow (or shadowing), and Nakagami.\n\nThe propagation model leads to a model for the SINR. Consider a collection of 'n' base stations located at points \"x\" to \"x\" in the plane or 3D space. Then for a user located at, say \"x=0\", then the SINR for a signal coming from base station, say, \"x\", is given by\n\nwhere \"F\" are fading random variables of some distribution. Under the simple power-law path-loss model becomes\n\nIn wireless networks, the factors that contribute to the SINR are often random (or appear random) including the signal propagation and the positioning of network transmitters and receivers. Consequently, in recent years this has motivated research in developing tractable stochastic geometry models in order to estimate the SINR in wireless networks. The related field of continuum percolation theory has also been used to derive bounds on the SINR in wireless networks.\n\n", "related": "\n- Signal-to-noise ratio\n- Stochastic geometry models of wireless networks\n- Continuum percolation theory\n"}
{"id": "8774050", "url": "https://en.wikipedia.org/wiki?curid=8774050", "title": "Telecommunications engineering", "text": "Telecommunications engineering\n\nTelecommunications Engineering is an engineering discipline centered on electrical and computer engineering which seeks to support and enhance telecommunication systems. The work ranges from basic circuit design to strategic mass developments. A telecommunication engineer is responsible for designing and overseeing the installation of telecommunications equipment and facilities, such as complex electronic switching systems, and other plain old telephone service facilities, optical fiber cabling, IP networks, and microwave transmission systems. Telecommunications engineering also overlaps with broadcast engineering.\n\nTelecommunication is a diverse field of engineering connected to electronic, civil and systems engineering. They help find the cost of money for different types of computers and technological objects. Ultimately, telecom engineers are responsible for providing high-speed data transmission services. They use a variety of equipment and transport media to design the telecom network infrastructure; the most common media used by wired telecommunications today are twisted pair, coaxial cables, and optical fibers. Telecommunications engineers also provide solutions revolving around wireless modes of communication and information transfer, such as wireless telephony services, radio and satellite communications, and internet and broadband technologies.\n\nTelecommunication systems are generally designed by telecommunication engineers which sprang from technological improvements in the telegraph industry in the late 19th century and the radio and the telephone industries in the early 20th century. Today, telecommunication is widespread and devices that assist the process, such as the television, radio and telephone, are common in many parts of the world. There are also many networks that connect these devices, including computer networks, public switched telephone network (PSTN), radio networks, and television networks. Computer communication across the Internet is one of many examples of telecommunication. Telecommunication plays a vital role in the world economy, and the telecommunication industry's revenue has been placed at just under 3% of the gross world product.\n\nSamuel Morse independently developed a version of the electrical telegraph that he unsuccessfully demonstrated on 2 September 1837. Soon after he was joined by Alfred Vail who developed the register — a telegraph terminal that integrated a logging device for recording messages to paper tape. This was demonstrated successfully over three miles (five kilometres) on 6 January 1838 and eventually over forty miles (sixty-four kilometres) between Washington, D.C. and Baltimore on 24 May 1844. The patented invention proved lucrative and by 1851 telegraph lines in the United States spanned over 20,000 miles (32,000 kilometres).\n\nThe first successful transatlantic telegraph cable was completed on 27 July 1866, allowing transatlantic telecommunication for the first time. Earlier transatlantic cables installed in 1857 and 1858 only operated for a few days or weeks before they failed. The international use of the telegraph has sometimes been dubbed the \"Victorian Internet\".\n\nThe first commercial telephone services were set up in 1878 and 1879 on both sides of the Atlantic in the cities of New Haven and London. Alexander Graham Bell held the master patent for the telephone that was needed for such services in both countries. The technology grew quickly from this point, with inter-city lines being built and telephone exchanges in every major city of the United States by the mid-1880s. Despite this, transatlantic voice communication remained impossible for customers until January 7, 1927 when a connection was established using radio. However no cable connection existed until TAT-1 was inaugurated on September 25, 1956 providing 36 telephone circuits.\n\nIn 1880, Bell and co-inventor Charles Sumner Tainter conducted the world's first wireless telephone call via modulated lightbeams projected by photophones. The scientific principles of their invention would not be utilized for several decades, when they were first deployed in military and fiber-optic communications.\n\nOver several years starting in 1894 the Italian inventor Guglielmo Marconi built the first complete, commercially successful wireless telegraphy system based on airborne electromagnetic waves (radio transmission). In December 1901, he would go on to established wireless communication between Britain and Newfoundland, earning him the Nobel Prize in physics in 1909 (which he shared with Karl Braun). In 1900 Reginald Fessenden was able to wirelessly transmit a human voice. On March 25, 1925, Scottish inventor John Logie Baird publicly demonstrated the transmission of moving silhouette pictures at the London department store Selfridges. In October 1925, Baird was successful in obtaining moving pictures with halftone shades, which were by most accounts the first true television pictures. This led to a public demonstration of the improved device on 26 January 1926 again at Selfridges. Baird's first devices relied upon the Nipkow disk and thus became known as the mechanical television. It formed the basis of semi-experimental broadcasts done by the British Broadcasting Corporation beginning September 30, 1929.\n\nThe first U.S. satellite to relay communications was Project SCORE in 1958, which used a tape recorder to store and forward voice messages. It was used to send a Christmas greeting to the world from U.S. President Dwight D. Eisenhower. In 1960 NASA launched an Echo satellite; the aluminized PET film balloon served as a passive reflector for radio communications. Courier 1B, built by Philco, also launched in 1960, was the world's first active repeater satellite. Satellites these days are used for many applications such as uses in GPS, television, internet and telephone uses.\n\nTelstar was the first active, direct relay commercial communications satellite. Belonging to AT&T as part of a multi-national agreement between AT&T, Bell Telephone Laboratories, NASA, the British General Post Office, and the French National PTT (Post Office) to develop satellite communications, it was launched by NASA from Cape Canaveral on July 10, 1962, the first privately sponsored space launch. Relay 1 was launched on December 13, 1962, and became the first satellite to broadcast across the Pacific on November 22, 1963.\n\nThe first and historically most important application for communication satellites was in intercontinental long distance telephony. The fixed Public Switched Telephone Network relays telephone calls from land line telephones to an earth station, where they are then transmitted a receiving satellite dish via a geostationary satellite in Earth orbit. Improvements in submarine communications cables, through the use of fiber-optics, caused some decline in the use of satellites for fixed telephony in the late 20th century, but they still exclusively service remote islands such as Ascension Island, Saint Helena, Diego Garcia, and Easter Island, where no submarine cables are in service. There are also some continents and some regions of countries where landline telecommunications are rare to nonexistent, for example Antarctica, plus large regions of Australia, South America, Africa, Northern Canada, China, Russia and Greenland.\n\nAfter commercial long distance telephone service was established via communication satellites, a host of other commercial telecommunications were also adapted to similar satellites starting in 1979, including mobile satellite phones, satellite radio, satellite television and satellite Internet access. The earliest adaption for most such services occurred in the 1990s as the pricing for commercial satellite transponder channels continued to drop significantly.\n\nOn 11 September 1940, George Stibitz was able to transmit problems using teleprinter to his Complex Number Calculator in New York and receive the computed results back at Dartmouth College in New Hampshire. This configuration of a centralized computer or mainframe computer with remote \"dumb terminals\" remained popular throughout the 1950s and into the 1960s. However, it was not until the 1960s that researchers started to investigate packet switching — a technology that allows chunks of data to be sent between different computers without first passing through a centralized mainframe. A four-node network emerged on 5 December 1969. This network soon became the ARPANET, which by 1981 would consist of 213 nodes.\n\nARPANET's development centered around the Request for Comment process and on 7 April 1969, RFC 1 was published. This process is important because ARPANET would eventually merge with other networks to form the Internet, and many of the communication protocols that the Internet relies upon today were specified through the Request for Comment process. In September 1981, RFC 791 introduced the Internet Protocol version 4 (IPv4) and RFC 793 introduced the Transmission Control Protocol (TCP) — thus creating the TCP/IP protocol that much of the Internet relies upon today.\n\nOptical fiber can be used as a medium for telecommunication and computer networking because it is flexible and can be bundled into cables. It is especially advantageous for long-distance communications, because light propagates through the fiber with little attenuation compared to electrical cables. This allows long distances to be spanned with few repeaters.\n\nIn 1966 Charles K. Kao and George Hockham proposed optical fibers at STC Laboratories (STL) at Harlow, England, when they showed that the losses of 1000 dB/km in existing glass (compared to 5-10 dB/km in coaxial cable) was due to contaminants, which could potentially be removed.\n\nOptical fiber was successfully developed in 1970 by Corning Glass Works, with attenuation low enough for communication purposes (about 20dB/km), and at the same time GaAs (Gallium arsenide) semiconductor lasers were developed that were compact and therefore suitable for transmitting light through fiber optic cables for long distances.\n\nAfter a period of research starting from 1975, the first commercial fiber-optic communications system was developed, which operated at a wavelength around 0.8 µm and used GaAs semiconductor lasers. This first-generation system operated at a bit rate of 45 Mbps with repeater spacing of up to 10 km. Soon on 22 April 1977, General Telephone and Electronics sent the first live telephone traffic through fiber optics at a 6 Mbit/s throughput in Long Beach, California.\n\nThe first wide area network fibre optic cable system in the world seems to have been installed by Rediffusion in Hastings, East Sussex, UK in 1978. The cables were placed in ducting throughout the town, and had over 1000 subscribers. They were used at that time for the transmission of television channels, not available because of local reception problems.\n\nThe first transatlantic telephone cable to use optical fiber was TAT-8, based on Desurvire optimized laser amplification technology. It went into operation in 1988.\n\nIn the late 1990s through 2000, industry promoters, and research companies such as KMI, and RHK predicted massive increases in demand for communications bandwidth due to increased use of the Internet, and commercialization of various bandwidth-intensive consumer services, such as video on demand. Internet protocol data traffic was increasing exponentially, at a faster rate than integrated circuit complexity had increased under Moore's Law.\n\nTransmitter (information source) that takes information and converts it to a signal for transmission. In electronics and telecommunications a transmitter or radio transmitter is an electronic device which, with the aid of an antenna, produces radio waves. In addition to their use in broadcasting, transmitters are necessary component parts of many electronic devices that communicate by radio, such as cell phones, \n\nTransmission medium over which the signal is transmitted. For example, the transmission medium for sounds is usually air, but solids and liquids may also act as transmission media for sound. Many transmission media are used as communications channel. One of the most common physical medias used in networking is copper wire. Copper wire is used to carry signals to long distances using relatively low amounts of power. Another example of a physical medium is optical fiber, which has emerged as the most commonly used transmission medium for long-distance communications. Optical fiber is a thin strand of glass that guides light along its length.\n\nThe absence of a material medium in vacuum may also constitute a transmission medium for electromagnetic waves such as light and radio waves.\n\nReceiver (information sink) that receives and converts the signal back into required information. In radio communications, a radio receiver is an electronic device that receives radio waves and converts the information carried by them to a usable form. It is used with an antenna. The information produced by the receiver may be in the form of sound (an audio signal), images (a video signal) or digital data.\n\nWired communications make use of underground communications cables (less often, overhead lines), electronic signal amplifiers (repeaters) inserted into connecting cables at specified points, and terminal apparatus of various types, depending on the type of wired communications used.\n\nWireless communication involves the transmission of information over a distance without help of wires, cables or any other forms of electrical conductors. Wireless operations permit services, such as long-range communications, that are impossible or impractical to implement with the use of wires. The term is commonly used in the telecommunications industry to refer to telecommunications systems (e.g. radio transmitters and receivers, remote controls etc.) which use some form of energy (e.g. radio waves, acoustic energy, etc.) to transfer information without the use of wires. Information is transferred in this manner over both short and long distances.\n\nA telecom equipment engineer is an electronics engineer that designs equipment such as routers, switches, multiplexers, and other specialized computer/electronics equipment designed to be used in the telecommunication network infrastructure.\n\nA network engineer is a computer engineer who is in charge of designing, deploying and maintaining computer networks. In addition, they oversee network operations from a network operations center, designs backbone infrastructure, or supervises interconnections in a data center.\n\nA central-office engineer is responsible for designing and overseeing the implementation of telecommunications equipment in a central office (CO for short), also referred to as a wire center or telephone exchange A CO engineer is responsible for integrating new technology into the existing network, assigning the equipment's location in the wire center, and providing power, clocking (for digital equipment), and alarm monitoring facilities for the new equipment. The CO engineer is also responsible for providing more power, clocking, and alarm monitoring facilities if there are currently not enough available to support the new equipment being installed. Finally, the CO engineer is responsible for designing how the massive amounts of cable will be distributed to various equipment and wiring frames throughout the wire center and overseeing the installation and turn up of all new equipment.\n\nAs structural engineers, CO engineers are responsible for the structural design and placement of racking and bays for the equipment to be installed in as well as for the plant to be placed on.\n\nAs electrical engineers, CO engineers are responsible for the resistance, capacitance, and inductance (RCL) design of all new plant to ensure telephone service is clear and crisp and data service is clean as well as reliable. Attenuation or gradual loss in intensity and loop loss calculations are required to determine cable length and size required to provide the service called for. In addition, power requirements have to be calculated and provided to power any electronic equipment being placed in the wire center.\n\nOverall, CO engineers have seen new challenges emerging in the CO environment. With the advent of Data Centers, Internet Protocol (IP) facilities, cellular radio sites, and other emerging-technology equipment environments within telecommunication networks, it is important that a consistent set of established practices or requirements be implemented.\n\nInstallation suppliers or their sub-contractors are expected to provide requirements with their products, features, or services. These services might be associated with the installation of new or expanded equipment, as well as the removal of existing equipment.\n\nSeveral other factors must be considered such as:\n- Regulations and safety in installation\n- Removal of hazardous material\n- Commonly used tools to perform installation and removal of equipment\n\nOutside plant (OSP) engineers are also often called field engineers because they frequently spend much time in the field taking notes about the civil environment, aerial, above ground, and below ground. OSP engineers are responsible for taking plant (copper, fiber, etc.) from a wire center to a distribution point or destination point directly. If a distribution point design is used, then a cross-connect box is placed in a strategic location to feed a determined distribution area.\n\nThe cross-connect box, also known as a serving area interface, is then installed to allow connections to be made more easily from the wire center to the destination point and ties up fewer facilities by not having dedication facilities from the wire center to every destination point. The plant is then taken directly to its destination point or to another small closure called a terminal, where access can also be gained to the plant if necessary. These access points are preferred as they allow faster repair times for customers and save telephone operating companies large amounts of money.\n\nThe plant facilities can be delivered via underground facilities, either direct buried or through conduit or in some cases laid under water, via aerial facilities such as telephone or power poles, or via microwave radio signals for long distances where either of the other two methods is too costly.\n\nAs structural engineers, OSP engineers are responsible for the structural design and placement of cellular towers and telephone poles as well as calculating pole capabilities of existing telephone or power poles onto which new plant is being added. Structural calculations are required when boring under heavy traffic areas such as highways or when attaching to other structures such as bridges. Shoring also has to be taken into consideration for larger trenches or pits. Conduit structures often include encasements of slurry that needs to be designed to support the structure and withstand the environment around it (soil type, high traffic areas, etc.).\n\nAs electrical engineers, OSP engineers are responsible for the resistance, capacitance, and inductance (RCL) design of all new plant to ensure telephone service is clear and crisp and data service is clean as well as reliable. Attenuation or gradual loss in intensity and loop loss calculations are required to determine cable length and size required to provide the service called for. In addition power requirements have to be calculated and provided to power any electronic equipment being placed in the field. Ground potential has to be taken into consideration when placing equipment, facilities, and plant in the field to account for lightning strikes, high voltage intercept from improperly grounded or broken power company facilities, and from various sources of electromagnetic interference.\n\nAs civil engineers, OSP engineers are responsible for drafting plans, either by hand or using Computer-aided design (CAD) software, for how telecom plant facilities will be placed. Often when working with municipalities trenching or boring permits are required and drawings must be made for these. Often these drawings include about 70% or so of the detailed information required to pave a road or add a turn lane to an existing street. Structural calculations are required when boring under heavy traffic areas such as highways or when attaching to other structures such as bridges. As civil engineers, telecom engineers provide the modern communications backbone for all technological communications distributed throughout civilizations today.\n\nUnique to telecom engineering is the use of air-core cable which requires an extensive network of air handling equipment such as compressors, manifolds, regulators and hundreds of miles of air pipe per system that connects to pressurized splice cases all designed to pressurize this special form of copper cable to keep moisture out and provide a clean signal to the customer.\n\nAs political and social ambassador, the OSP engineer is a telephone operating company's face and voice to the local authorities and other utilities. OSP engineers often meet with municipalities, construction companies and other utility companies to address their concerns and educate them about how the telephone utility works and operates. Additionally, the OSP engineer has to secure real estate in which to place outside facilities, such as an easement to place a cross-connect box.\n\n", "related": "\n- Computer engineering\n- Computer networking\n- Electronic design automation\n- Electronic engineering\n- Electronic media\n- Fiber-optic communication\n- History of telecommunication\n- Information theory\n- List of electrical engineering topics (alphabetical)\n- List of electrical engineering topics (thematic)\n- Professional engineer\n- Radio\n- Receiver (radio)\n- Telecommunication\n- Telephone\n- Television\n- Transmission medium\n- Transmitter\n- Two-way radio\n- Wired communication\n- Wireless\n"}
{"id": "1152833", "url": "https://en.wikipedia.org/wiki?curid=1152833", "title": "IP Multimedia Subsystem", "text": "IP Multimedia Subsystem\n\nThe IP Multimedia Subsystem or IP Multimedia Core Network Subsystem (IMS) is an architectural framework for delivering IP multimedia services. Historically, mobile phones have provided voice call services over a circuit-switched-style network, rather than strictly over an IP packet-switched network. Alternative methods of delivering voice (VoIP) or other multimedia services have become available on smartphones, but they have not become standardized across the industry. IMS is an architectural framework to provide such standardization.\n\nIMS was originally designed by the wireless standards body 3rd Generation Partnership Project (3GPP), as a part of the vision for evolving mobile networks beyond GSM. Its original formulation (3GPP Rel-5) represented an approach for delivering Internet services over GPRS. This vision was later updated by 3GPP, 3GPP2 and ETSI TISPAN by requiring support of networks other than GPRS, such as Wireless LAN, CDMA2000 and fixed lines.\n\nIMS uses IETF protocols wherever possible, e.g., the Session Initiation Protocol (SIP). According to the 3GPP, IMS is not intended to standardize applications, but rather to aid the access of multimedia and voice applications from wireless and wireline terminals, i.e., to create a form of fixed-mobile convergence (FMC). This is done by having a horizontal control layer that isolates the access network from the service layer. From a logical architecture perspective, services need not have their own control functions, as the control layer is a common horizontal layer. However, in implementation this does not necessarily map into greater reduced cost and complexity.\n\nAlternative and overlapping technologies for access and provisioning of services across wired and wireless networks include combinations of Generic Access Network, softswitches and \"naked\" SIP.\n\nSince it is becoming increasingly easier to access content and contacts using mechanisms outside the control of traditional wireless/fixed operators, the interest of IMS is being challenged.\n\nExamples of global standards based on IMS are MMTel which is the basis for Voice over LTE (VoLTE), Wifi Calling and Rich Communication Services (RCS) which is also known as joyn or Advanced Messaging.\n\n- IMS defined by an industry forum called 3G.IP, formed in 1999. 3G.IP developed the initial IMS architecture, which was brought to the 3rd Generation Partnership Project (3GPP), as part of their standardization work for 3G mobile phone systems in UMTS networks. It first appeared in Release 5 (evolution from 2G to 3G networks), when SIP-based multimedia was added. Support for the older GSM and GPRS networks was also provided.\n- 3GPP2 (a different organization from 3GPP) based their CDMA2000 Multimedia Domain (MMD) on 3GPP IMS, adding support for CDMA2000.\n- 3GPP release 6 added interworking with WLAN, inter-operability between IMS using different IP-connectivity networks, routing group identities, multiple registration and forking, presence, speech recognition and speech-enabled services (Push to talk).\n- 3GPP release 7 added support for fixed networks by working together with TISPAN release R1.1, the function of AGCF (access gateway control function) and PES (PSTN emulation service) are introduced to the wire-line network for the sake of inheritance of services which can be provided in PSTN network. AGCF works as a bridge interconnecting the IMS networks and the Megaco/H.248 networks. Megaco/H.248 networks offers the possibility to connect terminals of the old legacy networks to the new generation of networks based on IP networks. AGCF acts a SIP User agent towards the IMS and performs the role of P-CSCF. SIP User Agent functionality is included in the AGCF, and not on the customer device but in the network itself. Also added voice call continuity between circuit switching and packet switching domain (VCC), fixed broadband connection to the IMS, interworking with non-IMS networks, policy and charging control (PCC), emergency sessions.\n- 3GPP release 8 added support for LTE / SAE, multimedia session continuity, enhanced emergency sessions and IMS centralized services.\n- 3GPP release 9 added support for IMS emergency calls over GPRS and EPS, enhancements to multimedia telephony, IMS media plane security, enhancements to services centralization and continuity.\n- 3GPP release 10 added support for inter device transfer, enhancements to the single radio voice call continuity (SRVCC), enhancements to IMS emergency sessions.\n- 3GPP release 11 added USSD simulation service, network-provided location information for IMS, SMS submit and delivery without MSISDN in IMS, and overload control.\n\nEach of the functions in the diagram is explained below.\n\nThe IP multimedia core network subsystem is a collection of different functions, linked by standardized interfaces, which grouped form one IMS administrative network. A function is not a node (hardware box): An implementer is free to combine two functions in one node, or to split a single function into two or more nodes. Each node can also be present multiple times in a single network, for dimensioning, load balancing or organizational issues.\n\nThe user can connect to IMS in various ways, most of which use the standard IP. IMS terminals (such as mobile phones, personal digital assistants (PDAs) and computers) can register directly on IMS, even when they are roaming in another network or country (the visited network). The only requirement is that they can use IP and run SIP user agents. Fixed access (e.g., digital subscriber line (DSL), cable modems, Ethernet), mobile access (e.g. W-CDMA, CDMA2000, GSM, GPRS) and wireless access (e.g., WLAN, WiMAX) are all supported. Other phone systems like plain old telephone service (POTS—the old analogue telephones), H.323 and non IMS-compatible systems, are supported through gateways.\n\nHSS – Home subscriber server:\nThe \"home subscriber server\" (HSS), or \"user profile server function\" (UPSF), is a master user database that supports the IMS network entities that actually handle calls. It contains the subscription-related information (subscriber profiles), performs authentication and authorization of the user, and can provide information about the subscriber's location and IP information. It is similar to the GSM home location register (HLR) and Authentication centre (AuC).\n\nA \"subscriber location function\" (SLF) is needed to map user addresses when multiple HSSs are used.\n\nUser identities:\nVarious identities may be associated with IMS: IP multimedia private identity (IMPI), IP multimedia public identity (IMPU), globally routable user agent URI (GRUU), wildcarded public user identity. Both IMPI and IMPU are not phone numbers or other series of digits, but uniform resource identifier (URIs), that can be digits (a Tel URI, such as \"tel:+1-555-123-4567\") or alphanumeric identifiers (a SIP URI, such as \"sip:john.doe@example.com\" ).\n\nIP Multimedia Private Identity:\nThe \"IP Multimedia Private Identity\" (IMPI) is a unique permanently allocated global identity assigned by the home network operator, it has the form of an Network Access Identifier(NAI) i.e. user.name@domain, and is used, for example, for Registration, Authorization, Administration, and Accounting purposes. Every IMS user shall have one IMPI.\n\nIP Multimedia Public Identity:\nThe \"IP Multimedia Public Identity\" (IMPU) is used by any user for requesting communications to other users (e.g. this might be included on a business card). Also known as Address of Record (AOR). There can be multiple IMPU per IMPI. The IMPU can also be shared with another phone, so that both can be reached with the same identity (for example, a single phone-number for an entire family).\n\nGlobally Routable User Agent URI:\n\"Globally Routable User Agent URI\" (GRUU) is an identity that identifies a unique combination of IMPU and UE instance. \nThere are two types of GRUU: Public-GRUU (P-GRUU) and Temporary GRUU (T-GRUU). \n- P-GRUU reveal the IMPU and are very long lived.\n- T-GRUU do not reveal the IMPU and are valid until the contact is explicitly de-registered or the current registration expires\n\nWildcarded Public User Identity:\nA \"wildcarded Public User Identity\" expresses a set of IMPU grouped together.\nThe HSS subscriber database contains the IMPU, IMPI, IMSI, MSISDN, subscriber service profiles, service triggers, and other information.\n\nSeveral role of SIP servers or proxies, collectively called Call Session Control Function (CSCF), are used to process SIP signaling packets in the IMS.\n\n- A \"Proxy-CSCF\" (P-CSCF) is a SIP proxy that is the first point of contact for the IMS terminal. It can be located either in the visited network (in full IMS networks) or in the home network (when the visited network is not IMS compliant yet). Some networks may use a Session Border Controller (SBC) for this function. The P-CSCF is at its core a specialized SBC for the User–network interface which not only protects the network, but also the IMS terminal. The use of an additional SBC between the IMS terminal and the P-CSCF is unnecessary and infeasible due to the signaling being encrypted on this leg. The terminal discovers its P-CSCF with either DHCP, or it may be configured (e.g. during initial provisioning or via a 3GPP IMS Management Object (MO)) or in the ISIM or assigned in the PDP Context (in General Packet Radio Service (GPRS)).\n- It is assigned to an IMS terminal before registration, and does not change for the duration of the registration.\n- It sits on the path of all signaling, and can inspect every signal; the IMS terminal must ignore any other unencrypted signaling.\n- It provides subscriber authentication and may establish an IPsec or TLS security association with the IMS terminal. This prevents spoofing attacks and replay attacks and protects the privacy of the subscriber.\n- It inspects the signaling and ensures that the IMS terminals do not misbehave (e.g. change normal signaling routes, disobey home network's routing policy).\n- It can compress and decompress SIP messages using SigComp, which reduces the round-trip over slow radio links.\n- It may include a Policy Decision Function (PDF), which authorizes media plane resources e.g., quality of service (QoS) over the media plane. It is used for policy control, bandwidth management, etc. The PDF can also be a separate function.\n- It also generates charging records.\n- An \"Interrogating-CSCF\" (I-CSCF) is another SIP function located at the edge of an administrative domain. Its IP address is published in the Domain Name System (DNS) of the domain (using NAPTR and SRV type of DNS records), so that remote servers can find it, and use it as a forwarding point (e.g., registering) for SIP packets to this domain.\n- it queries the HSS to retrieve the address of the S-CSCF and assign it to a user performing SIP registration\n- it also forwards SIP request or response to the S-CSCF\n- Up to Release 6 it can also be used to hide the internal network from the outside world (encrypting parts of the SIP message), in which case it's called a \"Topology Hiding Inter-network Gateway\" (THIG). From Release 7 onwards this \"entry point\" function is removed from the I-CSCF and is now part of the \"Interconnection Border Control Function\" (IBCF). The IBCF is used as gateway to external networks, and provides NAT and firewall functions (pinholing). The IBCF is a session border controller specialized for the network-to-network interface (NNI).\n- A \"Serving-CSCF\" (S-CSCF) is the central node of the signaling plane. It is a SIP server, but performs session control too. It is always located in the home network. It uses Diameter Cx and Dx interfaces to the HSS to download user profiles and upload user-to-S-CSCF associations (the user profile is only cached locally for processing reasons and is not changed). All necessary subscriber profile information is loaded from the HSS.\n- it handles SIP registrations, which allows it to bind the user location (e.g., the IP address of the terminal) and the SIP address\n- it sits on the path of all signaling messages of the locally registered users, and can inspect every message\n- it decides to which application server(s) the SIP message will be forwarded, in order to provide their services\n- it provides routing services, typically using Electronic Numbering (ENUM) lookups\n- it enforces the policy of the network operator\n- there can be multiple S-CSCFs in the network for load distribution and high availability reasons. It's the HSS that assigns the S-CSCF to a user, when it's queried by the I-CSCF. There are multiple options for this purpose, including a mandatory/optional capabilities to be matched between subscribers and S-CSCFs.\n\nSIP Application servers (AS) host and execute services, and interface with the S-CSCF using SIP. An example of an application server that is being developed in 3GPP is the Voice call continuity Function (VCC Server). Depending on the actual service, the AS can operate in SIP proxy mode, SIP UA (user agent) mode or SIP B2BUA mode. An AS can be located in the home network or in an external third-party network. If located in the home network, it can query the HSS with the Diameter Sh or Si interfaces (for a SIP-AS).\n- SIP AS: Host and execute IMS specific services\n- \"IP Multimedia Service Switching Function\" (IM-SSF): Interfaces SIP to CAP to communicate with CAMEL Application Servers\n- OSA service capability server (OSA SCS) : Interfaces SIP to the OSA framework;\n\nThe AS-ILCM (Application Server - Incoming Leg Control Model) and AS-OLCM (Application Server - Outgoing Leg Control Model) store transaction state, and may optionally store session state depending on the specific service being executed. \nThe AS-ILCM interfaces to the S-CSCF (ILCM) for an incoming leg and the AS-OLCM interfaces to the S-CSCF (OLCM) for an outgoing leg.\nApplication Logic provides the service(s) and interacts between the AS-ILCM and AS-OLCM.\n\nPublic Service Identities (PSI) are identities that identify services, which are hosted by application servers. As user identities, PSI takes the form of either a SIP or Tel URI. PSIs are stored in the HSS either as a distinct PSI or as a wildcarded PSI:\n- a distinct PSI contains the PSI that is used in routing\n- a wildcarded PSI represents a collection of PSIs.\n\nThe \"Media Resource Function\" (MRF) provides media related functions such as media manipulation (e.g. voice stream mixing) and playing of tones and announcements.\n\nEach MRF is further divided into a \"media resource function controller\" (MRFC) and a \"media resource function processor\" (MRFP).\n\n- The MRFC is a signalling plane node that interprets information coming from an AS and S-CSCF to control the MRFP\n- The MRFP is a media plane node used to mix, source or process media streams. It can also manage access right to shared resources.\n\nThe \"Media Resource Broker\" (MRB) is a functional entity that is responsible for both collection of appropriate published MRF information and supplying of appropriate MRF information to consuming entities such as the AS. MRB can be used in two modes:\n- Query mode: AS queries the MRB for media and sets up the call using the response of MRB\n- In-Line Mode: AS sends a SIP INVITE to the MRB. The MRB sets up the call\n\nA \"Breakout Gateway Control Function\" (BGCF) is a SIP proxy which processes requests for routing from an S-CSCF when the S-CSCF has determined that the session cannot be routed using DNS or ENUM/DNS. It includes routing functionality based on telephone numbers.\n\nA PSTN/CS gateway interfaces with PSTN circuit switched (CS) networks. For signalling, CS networks use ISDN User Part (ISUP) (or BICC) over Message Transfer Part (MTP), while IMS uses SIP over IP. For media, CS networks use Pulse-code modulation (PCM), while IMS uses Real-time Transport Protocol (RTP).\n- A signalling gateway (SGW) interfaces with the signalling plane of the CS. It transforms lower layer protocols as Stream Control Transmission Protocol (SCTP, an IP protocol) into Message Transfer Part (MTP, a Signalling System 7 (SS7) protocol), to pass ISDN User Part (ISUP) from the MGCF to the CS network.\n- A \"media gateway controller function\" (MGCF) is a SIP endpoint that does call control protocol conversion between SIP and ISUP/BICC and interfaces with the SGW over SCTP. It also controls the resources in a \"Media Gateway\" (MGW) across an H.248 interface.\n- A \"media gateway\" (MGW) interfaces with the media plane of the CS network, by converting between RTP and PCM. It can also transcode when the codecs don't match (e.g., IMS might use AMR, PSTN might use G.711).\n\nMedia Resources are those components that operate on the media plane and are under the control of IMS core functions. Specifically, \"Media Server\" (MS) and \"Media gateway\" (MGW)\n\nThere are two types of next-generation networking interconnection:\n- \"Service-oriented interconnection\" (SoIx): The physical and logical linking of NGN domains that allows carriers and service providers to offer services over NGN (i.e., IMS and PES) platforms with control, signalling (i.e., session based), which provides defined levels of interoperability. For instance, this is the case of \"carrier grade\" voice and/or multimedia services over IP interconnection. \"Defined levels of interoperability\" are dependent upon the service or the QoS or the Security, etc.\n- \"Connectivity-oriented interconnection\" (CoIx): The physical and logical linking of carriers and service providers based on simple IP connectivity irrespective of the levels of interoperability. For example, an IP interconnection of this type is not aware of the specific end to end service and, as a consequence, service specific network performance, QoS and security requirements are not necessarily assured. This definition does not exclude that some services may provide a defined level of interoperability. However, only SoIx fully satisfies NGN interoperability requirements.\n\nAn NGN interconnection mode can be direct or indirect. Direct interconnection refers to the interconnection between two network domains without any intermediate network domain. Indirect interconnection at one layer refers to the interconnection between two network domains with one or more intermediate network domain(s) acting as transit networks. The intermediate network domain(s) provide(s) transit functionality to the two other network domains. Different interconnection modes may be used for carrying service layer signalling and media traffic.\n\nOffline charging is applied to users who pay for their services periodically (e.g., at the end of the month). Online charging, also known as credit-based charging, is used for prepaid services, or real-time credit control of postpaid services. Both may be applied to the same session.\n\n\"Charging function addresses\" are addresses distributed to each IMS entities and provide a common location for each entity to send charging information. \"charging data function\" (CDF) addresses are used for offline billing and \"Online Charging Function\" (OCF) for online billing.\n\n- Offline Charging : All the SIP network entities (P-CSCF, I-CSCF, S-CSCF, BGCF, MRFC, MGCF, AS) involved in the session use the Diameter Rf interface to send accounting information to a CDF located in the same domain. The CDF will collect all this information, and build a \"call detail record\" (CDR), which is sent to the billing system (BS) of the domain.Each session carries an \"IMS Charging Identifier\" (ICID) as a unique identifier generated by the first IMS entity involved in a SIP transaction and used for the correlation with CDRs. \"Inter Operator Identifier\" (IOI) is a globally unique identifier shared between sending and receiving networks. Each domain has its own charging network. Billing systems in different domains will also exchange information, so that roaming charges can be applied.\n- Online charging : The S-CSCF talks to a \"IMS gateway function\" (IMS-GWF) which looks like a regular SIP application server. The IMS-GWF can signal the S-CSCF to terminate the session when the user runs out of credits during a session. The AS and MRFC use the Diameter Ro interface towards an OCF.\n- When \"immediate event charging\" (IEC) is used, a number of credit units is immediately deducted from the user's account by the ECF and the MRFC or AS is then authorized to provide the service. The service is not authorized when not enough credit units are available.\n- When \"event charging with unit reservation\" (ECUR) is used, the ECF (event charging function) first reserves a number of credit units in the user's account and then authorizes the MRFC or the AS. After the service is over, the number of spent credit units is reported and deducted from the account; the reserved credit units are then cleared.\n\nIMS-based PES (PSTN Emulation System) provides IP networks services to analog devices. IMS-based PES allows non-IMS devices to appear to IMS as normal SIP users. Analog terminal using standard analog interfaces can connect to IMS-based PES in two ways:\n- Via A-MGW (Access Media Gateway) that is linked and controlled by AGCF. AGCF is placed within the Operators network and controls multiple A-MGW. A-MGW and AGCF communicate using H.248.1 (Megaco) over the P1 reference point. POTS phone connect to A-MGW over the z interface. The signalling is converted to H.248 in the A-MGW and passed to AGCF. AGCF interprets the H.248 signal and other inputs from the A-MGW to format H.248 messages into appropriate SIP messages. AGCF presents itself as P-CSCF to the S-CSCF and passes generated SIP messages to S-CSCF or to IP border via IBCF (Interconnection Border Control Function). Service presented to S-CSCF in SIP messages trigger PES AS. AGCF has also certain service independent logic, for example on receipt of off-hook event from A-MGW, the AGCF requests the A-MGW to play dial tone.\n- Via VGW (VoIP-Gateway) or SIP Gateway/Adapter on customer premises. POTS phones via VOIP Gateway connect to P-CSCF directly. Operators mostly use session border controllers between VoIP gateways and P-CSCFs for security and to hide network topology. VoIP gateway link to IMS using SIP over Gm reference point. The conversion from POTS service over the z interface to SIP occurs in the customer premises VoIP gateway. POTS signaling is converted to SIP and passed on to P-CSCF. VGW acts as SIP user agent and appears to P-CSCF as SIP terminal.\n\nBoth A-MGW and VGW are unaware of the services. They only relay call control signalling to and from the PSTN terminal. Session control and handling is done by IMS components.\n\nOne of the most important features of IMS, that of allowing for a SIP application to be dynamically and differentially (based on the user's profile) triggered, is implemented as a filter-and-redirect signalling mechanism in the S-CSCF.\n\nThe S-CSCF might apply filter criteria to determine the need to forward SIP requests to AS. It is important to note that services for the originating party will be applied in the originating network, while the services for the terminating party will be applied in the terminating network, all in the respective S-CSCFs.\n\nAn initial filter criteria (iFC) is an XML-based format used for describing control logic. iFCs represent a provisioned subscription of a user to an application. They are stored in the HSS as part of the IMS Subscription Profile and are downloaded to the S-CSCF upon user registration (for registered users) or on processing demand (for services, acting as unregistered users). iFCs are valid throughout the registration lifetime or until the User Profile is changed.\n\nThe iFC is composed of:\n- Priority - determines the order of checking the trigger.\n- Trigger point - logical condition(s) which is verified against initial dialog creating SIP requests or stand-alone SIP requests.\n- Application server URI - specifies the application server to be forwarded to when the trigger point matches.\n\nThere are two types of iFCs:\n- Shared - When provisioning, only a reference number (the shared iFC number) is assigned to the subscriber. During registration, only the number is sent to the CSCF, not the entire XML description. The complete XML will have previously been stored on the CSCF.\n- Non-shared - when provisioning, the entire XML description of the iFC is assigned to the subscriber. During registration, the entire XML description is sent to the CSCF.\n\nIt is envisaged that security defined in TS 33.203 may not be available for a while especially because of the lack of USIM/ISIM interfaces and prevalence of devices that support IPv4. For this situation, to provide some protection against the most significant threats, 3GPP defines some security mechanisms, which are informally known as \"early IMS security,\" in TR33.978. This mechanism relies on the authentication performed during the network attachment procedures, which binds between the user's profile and its IP address. This mechanism is also weak because the signaling is not protected on the user–network interface.\n\nCableLabs in PacketCable 2.0, which adopted also the IMS architecture but has no USIM/ISIM capabilities in their terminals, published deltas to the 3GPP specifications where the Digest-MD5 is a valid authentication option. Later on, TISPAN also did a similar effort given their fixed networks scopes, although the procedures are different. To compensate for the lack of IPsec capabilities, TLS has been added as an option for securing the Gm interface. Later 3GPP Releases have included the Digest-MD5 method, towards a Common-IMS platform, yet in its own and again different approach. Although all 3 variants of Digest-MD5 authentication have the same functionality and are the same from the IMS terminal's perspective, the implementations on the Cx interface between the S-CSCF and the HSS are different.\n\n", "related": "\n- 4G\n- Generic Access Network\n- Image share\n- OMA Instant Messaging and Presence Service\n- IP connectivity access network\n- Mobile broadband\n- Mobile VoIP\n- Peer-to-peer video sharing\n- Service capability interaction manager\n- System Architecture Evolution\n- SIMPLE\n- SIP extensions for the IP multimedia subsystem\n- Text over IP\n- Ultra Mobile Broadband\n- Video share\n- Voice call continuity\n- Voice over LTE\n\n\n- A decent IMS tutorial\n- IMS multi-page tutorial\n- IMS Call Flows\n"}
{"id": "40925", "url": "https://en.wikipedia.org/wiki?curid=40925", "title": "Communications system", "text": "Communications system\n\nIn telecommunication, a communications system or communication system is a collection of individual communications networks, transmission systems, relay stations, tributary stations, and data terminal equipment (DTE) usually capable of interconnection and interoperation to form an integrated whole. The components of a communications system serve a common purpose, are technically compatible, use common procedures, respond to controls, and operate in union. \n\nTelecommunications is a method of communication (e.g., for sports broadcasting, mass media, journalism, etc.). Communication is the act of conveying intended meanings from one entity or group to another through the use of mutually understood signs and semiotic rules\n\nAn optical communication system is any form of telecommunication that uses light as the transmission medium. Equipment consists of a transmitter, which encodes a \"message\" into an optical \"signal\", a \"communication channel\", which carries the signal to its destination, and a receiver, which reproduces the message from the received optical signal. Fiber-optic communication systems transmit information from one place to another by sending light through an optical fiber. The light forms a carrier signal that is modulated to carry information.\n\nA radio communication system is composed of several communications subsystems that give exterior communications capabilities. A radio communication system comprises a transmitting conductor in which electrical oscillations or currents are produced and which is arranged to cause such currents or oscillations to be propagated through the free space medium from one point to another remote therefrom and a receiving conductor at such distant point adapted to be excited by the oscillations or currents propagated from the transmitter.\n\nPower line communication systems operate by impressing a modulated carrier signal on power wires. Different types of powerline communications use different frequency bands, depending on the signal transmission characteristics of the power wiring used. Since the power wiring system was originally intended for transmission of AC power, the power wire circuits have only a limited ability to carry higher frequencies. The propagation problem is a limiting factor for each type of power line communications.\n\nA duplex communication system is a system composed of two connected parties or devices which can communicate with one another in both directions. The term \"duplex\" is used when describing communication between two parties or devices. Duplex systems are employed in nearly all communications networks, either to allow for a communication \"two-way street\" between two connected parties or to provide a \"reverse path\" for the monitoring and remote adjustment of equipment in the field.\nAn Antenna is basically a small length of a qwert conductor that is used to radiate or receive electromagnetic waves.\nIt acts as a conversion device. At the transmitting end it converts high frequency current into electromagnetic waves. At the receiving end it transforms electromagnetic waves into electrical signals that is fed into the input of the receiver. several types of antenna are used in communication.\n\nExamples of communications subsystems include the Defense Communications System (DCS).\n- Telephone\n- Mobile\n- Telegraph\n- Edison Telegraph\n- T.V. Cable\n- Computer\n\nA tactical communications system is a communications system that \n(a) is used within, or in direct support of tactical forces\n(b) is designed to meet the requirements of changing tactical situations and varying environmental conditions, \n(c) provides securable communications, such as voice, data, and video, among mobile users to facilitate command and control within, and in support of, tactical forces, and \n(d) usually requires extremely short installation times, usually on the order of hours, in order to meet the requirements of frequent relocation.\n\nAn Emergency communication system is any system (typically computer based) that is organized for the primary purpose of supporting the two way communication of emergency messages between both individuals and groups of individuals. These systems are commonly designed to integrate the cross-communication of messages between are variety of communication technologies.\n\nAn Automatic call distributor (ACD) is a communication system that automatically queues, assigns and connects callers to handlers. This is used often in customer service (such as for product or service complaints), ordering by telephone (such as in a ticket office), or coordination services (such as in air traffic control).\n\nA Voice Communication Control System (VCCS) is essentially an ACD with characteristics that make it more adapted to use in critical situations (no waiting for dialtone, or lengthy recorded announcements, radio and telephone lines equally easily connected to, individual lines immediately accessible etc..)\n\nSources can be classified as electric or non-electric; they are the origins of a message or input signal. Examples of sources include but are not limited to the following:\n- Audio Files (MP3, WAV, etc...)\n- Graphic Image Files (GIFs)\n- Email Messages\n- Human Voice\n- Television Picture\n- Electromagnetic Radiation\n\nSensors, like microphones and cameras, capture non-electric sources, like sound and light (respectively), and convert them into electrical signals. These types of sensors are called input transducers in modern analog and digital communication systems. Without input transducers there would not be an effective way to transport non-electric sources or signals over great distances, i.e. humans would have to rely solely on our eyes and ears to see and hear things despite the distances. \n\nOther examples of input transducers include:\n- Microphones\n- Cameras\n- Keyboards\n- Mouse (See Computer Peripherals)\n- Force Sensors\n- Accelerometers\n\nOnce the source signal has been converted into an electric signal, the transmitter will modify this signal for efficient transmission. In order to do this, the signal must pass through an electronic circuit containing the following components:\n1. Noise Filter\n2. Analog to digital converter (A/D converter)\n3. Encoder\n4. Modulator\n5. Signal Amplifier\nAfter the signal has been amplified, it is ready for transmission. At the end of the circuit is an antenna, the point at which the signal is released as electromagnetic waves (or electromagnetic radiation).\n\nA communication channel is simply referring to the medium by which a signal travels. There are two types of media by which electrical signals travel, i.e. guided and unguided. Guided media refers to any medium that can be directed from transmitter to receiver by means of connecting cables. In optical fiber communication, the medium is an optical (glass-like) fiber. Other guided media might include coaxial cables, telephone wire, twisted-pairs, etc... The other type of media, unguided media, refers to any communication channel that creates space between the transmitter and receiver. For radio or RF communication, the medium is air. Air is the only thing between the transmitter and receiver for RF communication while in other cases, like sonar, the medium is usually water because sound waves travel efficiently through certain liquid media. Both types of media are considered unguided because there are no connecting cables between the transmitter and receiver. Communication channels include almost everything from the vacuum of space to solid pieces of metal; however, some mediums are preferred more than others. That is because differing sources travel through subjective mediums with fluctuating efficiencies.\n\nOnce the signal has passed through the communication channel, it must be effectively captured by a receiver. The goal of the receiver is to capture and reconstruct the signal before it passed through the transmitter (i.e. the A/D converter, modulator and encoder). This is done by passing the \"received\" signal through another circuit containing the following components:\n1. Noise Filter\n2. Digital to analog converter (D/A converter)\n3. Decoder\n4. Demodulator\n5. Signal Amplifier\nMost likely the signal will have lost some of its energy after having passed through the communication channel or medium. The signal can be boosted by passing it through a signal amplifier.\nWhen the analog signal converted into digital signal.\n\nThe output transducer simply converts the electric signal (created by the input transducer) back into its original form. Examples of output transducers include but are not limited to the following:\n- Speakers (Audio)\n- Monitors (See Computer Peripherals)\n- Motors (Movement)\n- Lighting (Visual)\n\nSome common pairs of input and output transducers include:\n1. microphones and speakers (audio signals)\n2. keyboards and computer monitors\n3. cameras and liquid crystal displays (LCDs)\n4. force sensors (buttons) and lights or motors\n\nAgain, input transducers convert non-electric signals like voice into electric signals that can be transmitted over great distances very quickly. Output transducers convert the electric signal back into sound or picture, etc... There are many different types of transducers and the combinations are limitless.\n\n", "related": "\n- Automatic call distributor\n\n- Hansell, Clarence W., \", \"Communication system by pulses through the Earth\"\".\n"}
{"id": "19285762", "url": "https://en.wikipedia.org/wiki?curid=19285762", "title": "LTE Advanced", "text": "LTE Advanced\n\nLTE Advanced is a mobile communication standard and a major enhancement of the Long Term Evolution (LTE) standard. It was formally submitted as a candidate 4G to ITU-T in late 2009 as meeting the requirements of the IMT-Advanced standard, and was standardized by the 3rd Generation Partnership Project (3GPP) in March 2011 as 3GPP Release 10.\n\nThe LTE format was first proposed by NTT DoCoMo of Japan and has been adopted as the international standard. LTE standardization has matured to a state where changes in the specification are limited to corrections and bug fixes. The first commercial services were launched in Sweden and Norway in December 2009 followed by the United States and Japan in 2010. More LTE networks were deployed globally during 2010 as a natural evolution of several 2G and 3G systems, including Global system for mobile communications (GSM) and Universal Mobile Telecommunications System (UMTS) in the 3GPP family as well as CDMA2000 in the 3GPP2 family.\n\nThe work by 3GPP to define a 4G candidate radio interface technology started in Release 9 with the study phase for LTE-Advanced. Being described as a 3.9G (beyond 3G but pre-4G), the first release of LTE did not meet the requirements for 4G (also called IMT Advanced as defined by the International Telecommunication Union) such as peak data rates up to 1 Gb/s. The ITU has invited the submission of candidate Radio Interface Technologies (RITs) following their requirements in a circular letter, 3GPP Technical Report (TR) 36.913, \"Requirements for Further Advancements for E-UTRA (LTE-Advanced).\" These are based on ITU's requirements for 4G and on operators’ own requirements for advanced LTE.\nMajor technical considerations include the following:\n- Continual improvement to the LTE radio technology and architecture\n- Scenarios and performance requirements for working with legacy radio technologies\n- Backward compatibility of LTE-Advanced with LTE. An LTE terminal should be able to work in an LTE-Advanced network and vice versa. Any exceptions will be considered by 3GPP.\n- Consideration of recent World Radiocommunication Conference (WRC-07) decisions regarding frequency bands to ensure that LTE-Advanced accommodates the geographically available spectrum for channels above 20 MHz. Also, specifications must recognize those parts of the world in which wideband channels are not available.\n\nLikewise, 'WiMAX 2', 802.16m, has been approved by ITU as the IMT Advanced family. WiMAX 2 is designed to be backward compatible with WiMAX 1 devices. Most vendors now support conversion of 'pre-4G', pre-advanced versions and some support software upgrades of base station equipment from 3G.\n\nThe mobile communication industry and standards organizations have therefore started work on 4G access technologies, such as LTE Advanced. At a workshop in April 2008 in China, 3GPP agreed the plans for work on Long Term Evolution (LTE). A first set of specifications were approved in June 2008. Besides the peak data rate 1 Gb/s as defined by the ITU-R, it also targets faster switching between power states and improved performance at the cell edge. Detailed proposals are being studied within the working groups.\n\nThree technologies from the LTE-Advanced tool-kit – carrier aggregation, 4x4 MIMO and 256QAM modulation in the downlink\n– if used together and with sufficient aggregated bandwidth, can deliver maximum peak downlink speeds approaching, or even exceeding, 1 Gbit/s. Such networks are often described as ‘Gigabit LTE networks’ mirroring a term that is also used in the fixed broadband industry.\n\nThe target of 3GPP LTE Advanced is to reach and surpass the ITU requirements. LTE Advanced should be compatible with first release LTE equipment, and should share frequency bands with first release LTE. In the feasibility study for LTE Advanced, 3GPP determined that LTE Advanced would meet the ITU-R requirements for 4G. The results of the study are published in 3GPP Technical Report (TR) 36.912.\n\nOne of the important LTE Advanced benefits is the ability to take advantage of advanced topology networks; optimized heterogeneous networks with a mix of macrocells with low power nodes such as picocells, femtocells and new relay nodes. The next significant performance leap in wireless networks will come from making the most of topology, and brings the network closer to the user by adding many of these low power nodes — LTE Advanced further improves the capacity and coverage, and ensures user fairness. LTE Advanced also introduces multicarrier to be able to use ultra wide bandwidth, up to 100 MHz of spectrum supporting very high data rates.\n\nIn the research phase many proposals have been studied as candidates for LTE Advanced (LTE-A) technologies. The proposals could roughly be categorized into:\n- Support for relay node base stations\n- Coordinated multipoint (CoMP) transmission and reception\n- UE Dual TX antenna solutions for SU-MIMO and diversity MIMO, commonly referred to as 2x2 MIMO\n- Scalable system bandwidth exceeding 20 MHz, up to 100 MHz\n- Carrier aggregation of contiguous and non-contiguous spectrum allocations\n- Local area optimization of air interface\n- Nomadic / Local Area network and mobility solutions\n- Flexible spectrum usage\n- Cognitive radio\n- Automatic and autonomous network configuration and operation\n- Support of autonomous network and device test, measurement tied to network management and optimization\n- Enhanced precoding and forward error correction\n- Interference management and suppression\n- Asymmetric bandwidth assignment for FDD\n- Hybrid OFDMA and SC-FDMA in uplink\n- UL/DL inter eNB coordinated MIMO\n- SONs, Self Organizing Networks methodologies\n\nWithin the range of system development, LTE-Advanced and WiMAX 2 can use up to 8x8 MIMO and 128-QAM in downlink direction. Example performance: 100 MHz aggregated bandwidth, LTE-Advanced provides almost 3.3 Gbit peak download rates per sector of the base station under ideal conditions. Advanced network architectures combined with distributed and collaborative smart antenna technologies provide several years road map of commercial enhancements.\n\nThe 3GPP standards Release 12 added support for 256-QAM.\n\nA summary of a study carried out in 3GPP can be found in TR36.912.\n\nOriginal standardization work for LTE-Advanced was done as part of 3GPP Release 10, which was frozen in April 2011. Trials were based on pre-release equipment. Major vendors support software upgrades to later versions and ongoing improvements.\n\nIn order to improve the quality of service for users in hotspots and on cell edges, heterogenous networks (HetNet) are formed of a mixture of macro-, pico- and femto base stations serving corresponding-size areas. Frozen in December 2012, 3GPP Release 11 concentrates on better support of HetNet. Coordinated Multi-Point operation (CoMP) is a key feature of Release 11 in order to support such network structures. Whereas users located at a cell edge in homogenous networks suffer from decreasing signal strength compounded by neighbor cell interference, CoMP is designed to enable use of a neighboring cell to also transmit the same signal as the serving cell, enhancing quality of service on the perimeter of a serving cell. In-device Co-existence (IDC) is another topic addressed in Release 11. IDC features are designed to ameliorate disturbances within the user equipment caused between LTE/LTE-A and the various other radio subsystems such as WiFi, Bluetooth, and the GPS receiver. Further enhancements for MIMO such as 4x4 configuration for the uplink were standardized.\n\nThe higher number of cells in HetNet results in user equipment changing the serving cell more frequently when in motion.\nThe ongoing work on LTE-Advanced in Release 12, amongst other areas, concentrates on addressing issues that come about when users move through HetNet, such as frequent hand-overs between cells. It also included use of 256-QAM.\n\nThis list covers technology demonstrations and field trials up to the year 2014, paving the way for a wider commercial deployment of the VoLTE technology worldwide. From 2014 onwards various further operators trialled and demonstrated the technology for future deployment on their respective networks. These are not covered here. Instead a coverage of commercial deployments can be found in the section below.\n\nThe deployment of LTE-Advanced in progress in various LTE networks.\n\nIn August 2019, the Global mobile Suppliers Association (GSA) reported that there were 304 commercially launched LTE-Advanced networks in 134 countries. Overall, 335 operators are investing in LTE-Advanced (in the form of tests, trials, deployments or commercial service provision) in 141 countries.\n\n", "related": "\n- E-UTRA\n- LTE Advanced Pro\n- LTE User Equipment Category\n- Simulation of LTE Networks\n- 4G\n- 5G\n\n- Qualcomm\n- Harri Holma, Antti Toskala, \"LTE for UMTS - OFDMA and SC-FDMA Based Radio Access\", John Wiley & Sons 2009, Chapter 2.6: LTE Advanced for IMT-advanced, pp 19–21.\n- Moray Rumney (editor), \"LTE and the Evolution to 4G Wireless: Design and Measurement Challenges\", Agilent Technologies Publication 2009, , Chapter 8.7: Proving LTE Advanced, p 425\n- Preben E. Mogensen, Tommi Koivisto, Klaus I. Pedersen 1, et al.; Nokia Siemens Networks;LTE Advanced: The Path towards Gigabit/s in Wireless Mobile Communications, Wireless VITAE'09.\n- Sajal Kumar Das, \"Mobile Terminal Receiver Design: LTE and LTE-Advanced \", John Wiley & Sons 2016, .\n\n- LTE Advanced page on Qualcomm site\n- 3GPP Official 3GPP Standardisation Page on LTE Advanced\n- Future use of LTE A femtocells\n- LTE-3GPP online decoders - 3GPP LTE / LTE Advanced online L3 messages decoders (24.008, 44.018, 44.060, etc.) supporting Rel.14\n\n- LTE-Advanced Technology Introduction - this white paper summarizes improvements on LTE known as LTE-Advanced Rel.10\n- Introducing LTE-Advanced - Application Note\n- Introduction to LTE-Advanced Rel.11 - Summarization of improvements specified in LTE-Advanced Release 11.\n"}
{"id": "19752979", "url": "https://en.wikipedia.org/wiki?curid=19752979", "title": "LTE (telecommunication)", "text": "LTE (telecommunication)\n\nIn telecommunications, Long-Term Evolution (LTE) is a standard for wireless broadband communication for mobile devices and data terminals, based on the GSM/EDGE and UMTS/HSPA technologies. It increases the capacity and speed using a different radio interface together with core network improvements. The standard is developed by the 3GPP (3rd Generation Partnership Project) and is specified in its Release 8 document series, with minor enhancements described in Release 9. LTE is the upgrade path for carriers with both GSM/UMTS networks and CDMA2000 networks. The different LTE frequencies and bands used in different countries mean that only multi-band phones are able to use LTE in all countries where it is supported.\n\nLTE has been marketed both as \"4G LTE\" and as \"Advanced 4G\", but it does not meet the technical criteria of a 4G wireless service, as specified in the 3GPP Release 8 and 9 document series for LTE Advanced. LTE is also commonly known as 3.95G. The requirements were originally set forth by the ITU-R organisation in the IMT Advanced specification. However, due to marketing pressures and the significant advancements that WiMAX, Evolved High Speed Packet Access, and LTE bring to the original 3G technologies, ITU later decided that LTE together with the aforementioned technologies can be called 4G technologies. The LTE Advanced standard formally satisfies the ITU-R requirements to be considered IMT-Advanced. To differentiate LTE Advanced and WiMAX-Advanced from current 4G technologies, ITU has defined them as \"True 4G\".\n\nLTE stands for Long Term Evolution and is a registered trademark owned by ETSI (European Telecommunications Standards Institute) for the wireless data communications technology and a development of the GSM/UMTS standards. However, other nations and companies do play an active role in the LTE project. The goal of LTE was to increase the capacity and speed of wireless data networks using new DSP (digital signal processing) techniques and modulations that were developed around the turn of the millennium. A further goal was the redesign and simplification of the network architecture to an IP-based system with significantly reduced transfer latency compared with the 3G architecture. The LTE wireless interface is incompatible with 2G and 3G networks, so that it must be operated on a separate radio spectrum.\n\nLTE was first proposed in 2004 by Japan's NTT Docomo, with studies on the standard officially commenced in 2005. In May 2007, the LTE/SAE Trial Initiative (LSTI) alliance was founded as a global collaboration between vendors and operators with the goal of verifying and promoting the new standard in order to ensure the global introduction of the technology as quickly as possible. The LTE standard was finalized in December 2008, and the first publicly available LTE service was launched by TeliaSonera in Oslo and Stockholm on December 14, 2009, as a data connection with a USB modem. The LTE services were launched by major North American carriers as well, with the Samsung SCH-r900 being the world's first LTE Mobile phone starting on September 21, 2010, and Samsung Galaxy Indulge being the world's first LTE smartphone starting on February 10, 2011, both offered by MetroPCS, and the HTC ThunderBolt offered by Verizon starting on March 17 being the second LTE smartphone to be sold commercially. In Canada, Rogers Wireless was the first to launch LTE network on July 7, 2011, offering the Sierra Wireless AirCard 313U USB mobile broadband modem, known as the \"LTE Rocket stick\" then followed closely by mobile devices from both HTC and Samsung. Initially, CDMA operators planned to upgrade to rival standards called UMB and WiMAX, but major CDMA operators (such as Verizon, Sprint and MetroPCS in the United States, Bell and Telus in Canada, au by KDDI in Japan, SK Telecom in South Korea and China Telecom/China Unicom in China) have announced instead they intend to migrate to LTE. The next version of LTE is LTE Advanced, which was standardized in March 2011. Services are expected to commence in 2013. Additional evolution known as LTE Advanced Pro have been approved in year 2015.\n\nThe LTE specification provides downlink peak rates of 300 Mbit/s, uplink peak rates of 75 Mbit/s and QoS provisions permitting a transfer latency of less than 5 ms in the radio access network. LTE has the ability to manage fast-moving mobiles and supports multi-cast and broadcast streams. LTE supports scalable carrier bandwidths, from 1.4 MHz to 20 MHz and supports both frequency division duplexing (FDD) and time-division duplexing (TDD). The IP-based network architecture, called the Evolved Packet Core (EPC) designed to replace the GPRS Core Network, supports seamless handovers for both voice and data to cell towers with older network technology such as GSM, UMTS and CDMA2000. The simpler architecture results in lower operating costs (for example, each E-UTRA cell will support up to four times the data and voice capacity supported by HSPA).\n\n- In 2004, NTT Docomo of Japan proposes LTE as the international standard.\n- In September 2006, Siemens Networks (today Nokia Networks) showed in collaboration with Nomor Research the first live emulation of an LTE network to the media and investors. As live applications two users streaming an HDTV video in the downlink and playing an interactive game in the uplink have been demonstrated.\n- In February 2007, Ericsson demonstrated for the first time in the world, LTE with bit rates up to 144 Mbit/s\n- In September 2007, NTT Docomo demonstrated LTE data rates of 200 Mbit/s with power level below 100 mW during the test.\n- In November 2007, Infineon presented the world's first RF transceiver named SMARTi LTE supporting LTE functionality in a single-chip RF silicon processed in CMOS\n- In early 2008, LTE test equipment began shipping from several vendors and, at the Mobile World Congress 2008 in Barcelona, Ericsson demonstrated the world's first end-to-end mobile call enabled by LTE on a small handheld device. Motorola demonstrated an LTE RAN standard compliant eNodeB and LTE chipset at the same event.\n- At the February 2008 Mobile World Congress:\n- Motorola demonstrated how LTE can accelerate the delivery of personal media experience with HD video demo streaming, HD video blogging, Online gaming and VoIP over LTE running a RAN standard compliant LTE network & LTE chipset.\n- Ericsson EMP (now ST-Ericsson) demonstrated the world's first end-to-end LTE call on handheld Ericsson demonstrated LTE FDD and TDD mode on the same base station platform.\n- Freescale Semiconductor demonstrated streaming HD video with peak data rates of 96 Mbit/s downlink and 86 Mbit/s uplink.\n- NXP Semiconductors (now a part of ST-Ericsson) demonstrated a multi-mode LTE modem as the basis for a software-defined radio system for use in cellphones.\n- picoChip and Mimoon demonstrated a base station reference design. This runs on a common hardware platform (multi-mode / software defined radio) with their WiMAX architecture.\n- In April 2008, Motorola demonstrated the first EV-DO to LTE hand-off handing over a streaming video from LTE to a commercial EV-DO network and back to LTE.\n- In April 2008, LG Electronics and Nortel demonstrated LTE data rates of 50 Mbit/s while travelling at 110 km/h (68 mph).\n- In November 2008, Motorola demonstrated industry first over-the-air LTE session in 700 MHz spectrum.\n- Researchers at Nokia Siemens Networks and Heinrich Hertz Institut have demonstrated LTE with 100 Mbit/s Uplink transfer speeds.\n- At the February 2009 Mobile World Congress:\n- Infineon demonstrated a single-chip 65 nm CMOS RF transceiver providing 2G/3G/LTE functionality\n- Launch of ng Connect program, a multi-industry consortium founded by Alcatel-Lucent to identify and develop wireless broadband applications.\n- Motorola provided LTE drive tour on the streets of Barcelona to demonstrate LTE system performance in a real-life metropolitan RF environment\n- In July 2009, Nujira demonstrated efficiencies of more than 60% for an 880 MHz LTE Power Amplifier\n- In August 2009, Nortel and LG Electronics demonstrated the first successful handoff between CDMA and LTE networks in a standards-compliant manner\n- In August 2009, Alcatel-Lucent receives FCC certification for LTE base stations for the 700 MHz spectrum band.\n- In September 2009, Nokia Siemens Networks demonstrated world's first LTE call on standards-compliant commercial software.\n- In October 2009, Ericsson and Samsung demonstrated interoperability between the first ever commercial LTE device and the live network in Stockholm, Sweden.\n- In October 2009, Alcatel-Lucent's Bell Labs, Deutsche Telekom Innovation Laboratories, the Fraunhofer Heinrich-Hertz Institut and antenna supplier Kathrein conducted live field tests of a technology called Coordinated Multipoint Transmission (CoMP) aimed at increasing the data transmission speeds of LTE and 3G networks.\n- In November 2009, Alcatel-Lucent completed first live LTE call using 800 MHz spectrum band set aside as part of the European Digital Dividend (EDD).\n- In November 2009, Nokia Siemens Networks and LG completed first end-to-end interoperability testing of LTE.\n- On December 14, 2009, the first commercial LTE deployment was in the Scandinavian capitals Stockholm and Oslo by the Swedish-Finnish network operator TeliaSonera and its Norwegian brandname NetCom (Norway). TeliaSonera incorrectly branded the network \"4G\". The modem devices on offer were manufactured by Samsung (dongle GT-B3710), and the network infrastructure with SingleRAN technology created by Huawei (in Oslo) and Ericsson (in Stockholm). TeliaSonera plans to roll out nationwide LTE across Sweden, Norway and Finland. TeliaSonera used spectral bandwidth of 10 MHz (out of the maximum 20 MHz), and Single-Input and Single-Output transmission. The deployment should have provided a physical layer net bitrates of up to 50 Mbit/s downlink and 25 Mbit/s in the uplink. Introductory tests showed a TCP goodput of 42.8 Mbit/s downlink and 5.3 Mbit/s uplink in Stockholm.\n- In December 2009, ST-Ericsson and Ericsson first to achieve LTE and HSPA mobility with a multimode device.\n- In January 2010, Alcatel-Lucent and LG complete a live handoff of an end-to-end data call between LTE and CDMA networks.\n- In February 2010, Nokia Siemens Networks and Movistar test the LTE in Mobile World Congress 2010 in Barcelona, Spain, with both indoor and outdoor demonstrations.\n- In May 2010, Mobile TeleSystems (MTS) and Huawei showed an indoor LTE network at \"Sviaz-Expocomm 2010\" in Moscow, Russia. MTS expects to start a trial LTE service in Moscow by the beginning of 2011. Earlier, MTS has received a license to build an LTE network in Uzbekistan, and intends to commence a test LTE network in Ukraine in partnership with Alcatel-Lucent.\n- At the Shanghai Expo 2010 in May 2010, Motorola demonstrated a live LTE in conjunction with China Mobile. This included video streams and a drive test system using TD-LTE.\n- As of 12/10/2010, DirecTV has teamed up with Verizon Wireless for a test of high-speed LTE wireless technology in a few homes in Pennsylvania, designed to deliver an integrated Internet and TV bundle. Verizon Wireless said it launched LTE wireless services (for data, no voice) in 38 markets where more than 110 million Americans live on Sunday, Dec. 5.\n- On May 6, 2011, Sri Lanka Telecom Mobitel demonstrated 4G LTE for the first time in South Asia, achieving a data rate of 96 Mbit/s in Sri Lanka.\n\nMost carriers supporting GSM or HSUPA networks can be expected to upgrade their networks to LTE at some stage. A complete list of commercial contracts can be found at:\n\n- August 2009: Telefónica selected six countries to field-test LTE in the succeeding months: Spain, the United Kingdom, Germany and the Czech Republic in Europe, and Brazil and Argentina in Latin America.\n- On November 24, 2009: Telecom Italia announced the first outdoor pre-commercial experimentation in the world, deployed in Torino and totally integrated into the 2G/3G network currently in service.\n- On December 14, 2009, the world's first publicly available LTE service was opened by TeliaSonera in the two Scandinavian capitals Stockholm and Oslo.\n- On May 28, 2010, Russian operator Scartel announced the launch of an LTE network in Kazan by the end of 2010.\n- On October 6, 2010, Canadian provider Rogers Communications Inc announced that Ottawa, Canada's national capital, will be the site of LTE trials. Rogers said it will expand on this testing and move to a comprehensive technical trial of LTE on both low- and high-band frequencies across the Ottawa area.\n- On May 6, 2011, Sri Lanka Telecom Mobitel successfully demonstrated 4G LTE for the first time in South Asia, achieving a data rate of 96 Mbit/s in Sri Lanka.\n- On May 7, 2011, Sri Lankan Mobile Operator Dialog Axiata PLC switched on the first pilot 4G LTE Network in South Asia with vendor partner Huawei and demonstrated a download data speed up to 127 Mbit/s.\n- On February 9, 2012, Telus Mobility launched their LTE service initial in metropolitan areas include Vancouver, Calgary, Edmonton, Toronto and the Greater Toronto Area, Kitchener, Waterloo, Hamilton, Guelph, Belleville, Ottawa, Montreal, Québec City, Halifax and Yellowknife.\n- Telus Mobility has announced that it will adopt LTE as its 4G wireless standard.\n- Cox Communications has its first tower for wireless LTE network build-out. Wireless services launched in late 2009.\n- In March 2019, the Global Mobile Suppliers Association reported that there were now 717 operators with commercially launched LTE networks (broadband fixed wireless access and or mobile).\n\nThe following is a list of top 10 countries/territories by 4G LTE coverage as measured by OpenSignal.com in February/March 2019.\n\nFor the complete list of all the countries/territories, see list of countries by 4G LTE penetration.\n\nLong-Term Evolution Time-Division Duplex (LTE-TDD), also referred to as TDD LTE, is a 4G telecommunications technology and standard co-developed by an international coalition of companies, including China Mobile, Datang Telecom, Huawei, ZTE, Nokia Solutions and Networks, Qualcomm, Samsung, and ST-Ericsson. It is one of the two mobile data transmission technologies of the Long-Term Evolution (LTE) technology standard, the other being Long-Term Evolution Frequency-Division Duplex (LTE-FDD). While some companies refer to LTE-TDD as \"TD-LTE\" for familiarity with TD-SCDMA, there is no reference to that acronym anywhere in the 3GPP specifications.\n\nThere are two major differences between LTE-TDD and LTE-FDD: how data is uploaded and downloaded, and what frequency spectra the networks are deployed in. While LTE-FDD uses paired frequencies to upload and download data, LTE-TDD uses a single frequency, alternating between uploading and downloading data through time. The ratio between uploads and downloads on a LTE-TDD network can be changed dynamically, depending on whether more data needs to be sent or received. LTE-TDD and LTE-FDD also operate on different frequency bands, with LTE-TDD working better at higher frequencies, and LTE-FDD working better at lower frequencies. Frequencies used for LTE-TDD range from 1850 MHz to 3800 MHz, with several different bands being used. The LTE-TDD spectrum is generally cheaper to access, and has less traffic. Further, the bands for LTE-TDD overlap with those used for WiMAX, which can easily be upgraded to support LTE-TDD.\n\nDespite the differences in how the two types of LTE handle data transmission, LTE-TDD and LTE-FDD share 90 percent of their core technology, making it possible for the same chipsets and networks to use both versions of LTE. A number of companies produce dual-mode chips or mobile devices, including Samsung and Qualcomm, while operators CMHK and Hi3G Access have developed dual-mode networks in Hong Kong and Sweden, respectively.\n\nThe creation of LTE-TDD involved a coalition of international companies that worked to develop and test the technology. China Mobile was an early proponent of LTE-TDD, along with other companies like Datang Telecom and Huawei, which worked to deploy LTE-TDD networks, and later developed technology allowing LTE-TDD equipment to operate in white spaces—frequency spectra between broadcast TV stations. Intel also participated in the development, setting up a LTE-TDD interoperability lab with Huawei in China, as well as ST-Ericsson, Nokia, and Nokia Siemens (now Nokia Solutions and Networks), which developed LTE-TDD base stations that increased capacity by 80 percent and coverage by 40 percent. Qualcomm also participated, developing the world's first multi-mode chip, combining both LTE-TDD and LTE-FDD, along with HSPA and EV-DO. Accelleran, a Belgian company, has also worked to build small cells for LTE-TDD networks.\n\nTrials of LTE-TDD technology began as early as 2010, with Reliance Industries and Ericsson India conducting field tests of LTE-TDD in India, achieving 80 megabit-per second download speeds and 20 megabit-per-second upload speeds. By 2011, China Mobile began trials of the technology in six cities.\n\nAlthough initially seen as a technology utilized by only a few countries, including China and India, by 2011 international interest in LTE-TDD had expanded, especially in Asia, in part due to LTE-TDD 's lower cost of deployment compared to LTE-FDD. By the middle of that year, 26 networks around the world were conducting trials of the technology. The Global LTE-TDD Initiative (GTI) was also started in 2011, with founding partners China Mobile, Bharti Airtel, SoftBank Mobile, Vodafone, Clearwire, Aero2 and E-Plus. In September 2011, Huawei announced it would partner with Polish mobile provider Aero2 to develop a combined LTE-TDD and LTE-FDD network in Poland, and by April 2012, ZTE Corporation had worked to deploy trial or commercial LTE-TDD networks for 33 operators in 19 countries. In late 2012, Qualcomm worked extensively to deploy a commercial LTE-TDD network in India, and partnered with Bharti Airtel and Huawei to develop the first multi-mode LTE-TDD smartphone for India.\n\nIn Japan, SoftBank Mobile launched LTE-TDD services in February 2012 under the name Advanced eXtended Global Platform (AXGP), and marketed as SoftBank 4G (). The AXGP band was previously used for Willcom's PHS service, and after PHS was discontinued in 2010 the PHS band was re-purposed for AXGP service.\n\nIn the U.S., Clearwire planned to implement LTE-TDD, with chip-maker Qualcomm agreeing to support Clearwire's frequencies on its multi-mode LTE chipsets. With Sprint's acquisition of Clearwire in 2013, the carrier began using these frequencies for LTE service on networks built by Samsung, Alcatel-Lucent, and Nokia.\n\nAs of March 2013, 156 commercial 4G LTE networks existed, including 142 LTE-FDD networks and 14 LTE-TDD networks.\nAs of November 2013, the South Korean government planned to allow a fourth wireless carrier in 2014, which would provide LTE-TDD services, and in December 2013, LTE-TDD licenses were granted to China's three mobile operators, allowing commercial deployment of 4G LTE services.\n\nIn January 2014, Nokia Solutions and Networks indicated that it had completed a series of tests of voice over LTE (VoLTE) calls on China Mobile's TD-LTE network. The next month, Nokia Solutions and Networks and Sprint announced that they had demonstrated throughput speeds of 2.6 gigabits per second using a LTE-TDD network, surpassing the previous record of 1.6 gigabits per second.\n\nMuch of the LTE standard addresses the upgrading of 3G UMTS to what will eventually be 4G mobile communications technology. A large amount of the work is aimed at simplifying the architecture of the system, as it transitions from the existing UMTS circuit + packet switching combined network, to an all-IP flat architecture system. E-UTRA is the air interface of LTE. Its main features are:\n- Peak download rates up to 299.6 Mbit/s and upload rates up to 75.4 Mbit/s depending on the user equipment category (with 4×4 antennas using 20 MHz of spectrum). Five different terminal classes have been defined from a voice-centric class up to a high-end terminal that supports the peak data rates. All terminals will be able to process 20 MHz bandwidth.\n- Low data transfer latencies (sub-5 ms latency for small IP packets in optimal conditions), lower latencies for handover and connection setup time than with previous radio access technologies.\n- Improved support for mobility, exemplified by support for terminals moving at up to or depending on the frequency band.\n- Orthogonal frequency-division multiple access for the downlink, Single-carrier FDMA for the uplink to conserve power.\n- Support for both FDD and TDD communication systems as well as half-duplex FDD with the same radio access technology.\n- Support for all frequency bands currently used by IMT systems by ITU-R.\n- Increased spectrum flexibility: 1.4 MHz, 3 MHz, 5 MHz, 10 MHz, 15 MHz and 20 MHz wide cells are standardized. (W-CDMA has no option for other than 5 MHz slices, leading to some problems rolling-out in countries where 5 MHz is a commonly allocated width of spectrum so would frequently already be in use with legacy standards such as 2G GSM and cdmaOne.)\n- Support for cell sizes from tens of metres radius (femto and picocells) up to radius macrocells. In the lower frequency bands to be used in rural areas, is the optimal cell size, having reasonable performance, and up to 100 km cell sizes supported with acceptable performance. In the city and urban areas, higher frequency bands (such as 2.6 GHz in EU) are used to support high-speed mobile broadband. In this case, cell sizes may be or even less.\n- Support of at least 200 active data clients in every 5 MHz cell.\n- Simplified architecture: The network side of E-UTRAN is composed only of eNode Bs.\n- Support for inter-operation and co-existence with legacy standards (e.g., GSM/EDGE, UMTS and CDMA2000). Users can start a call or transfer of data in an area using an LTE standard, and, should coverage be unavailable, continue the operation without any action on their part using GSM/GPRS or W-CDMA-based UMTS or even 3GPP2 networks such as cdmaOne or CDMA2000.\n- Uplink and downlink Carrier aggregation.\n- Packet-switched radio interface.\n- Support for MBSFN (multicast-broadcast single-frequency network). This feature can deliver services such as Mobile TV using the LTE infrastructure, and is a competitor for DVB-H-based TV broadcast only LTE compatible devices receives LTE signal.\n\nThe LTE standard supports only packet switching with its all-IP network. Voice calls in GSM, UMTS and CDMA2000 are circuit switched, so with the adoption of LTE, carriers will have to re-engineer their voice call network. Three different approaches sprang up:\n\n- Voice over LTE (VoLTE):\n\n- Circuit-switched fallback (CSFB): In this approach, LTE just provides data services, and when a voice call is to be initiated or received, it will fall back to the circuit-switched domain. When using this solution, operators just need to upgrade the MSC instead of deploying the IMS, and therefore, can provide services quickly. However, the disadvantage is longer call setup delay.\n\n- Simultaneous voice and LTE (SVLTE): In this approach, the handset works simultaneously in the LTE and circuit switched modes, with the LTE mode providing data services and the circuit switched mode providing the voice service. This is a solution solely based on the handset, which does not have special requirements on the network and does not require the deployment of IMS either. The disadvantage of this solution is that the phone can become expensive with high power consumption.\n\n- Single Radio Voice Call Continuity (SRVCC):\n\nOne additional approach which is not initiated by operators is the usage of over-the-top content (OTT) services, using applications like Skype and Google Talk to provide LTE voice service.\n\nMost major backers of LTE preferred and promoted VoLTE from the beginning. The lack of software support in initial LTE devices, as well as core network devices, however led to a number of carriers promoting VoLGA (Voice over LTE Generic Access) as an interim solution. The idea was to use the same principles as GAN (Generic Access Network, also known as UMA or Unlicensed Mobile Access), which defines the protocols through which a mobile handset can perform voice calls over a customer's private Internet connection, usually over wireless LAN. VoLGA however never gained much support, because VoLTE (IMS) promises much more flexible services, albeit at the cost of having to upgrade the entire voice call infrastructure. VoLTE will also require Single Radio Voice Call Continuity (SRVCC) in order to be able to smoothly perform a handover to a 3G network in case of poor LTE signal quality.\n\nWhile the industry has seemingly standardized on VoLTE for the future, the demand for voice calls today has led LTE carriers to introduce circuit-switched fallback as a stopgap measure. When placing or receiving a voice call, LTE handsets will fall back to old 2G or 3G networks for the duration of the call.\n\nTo ensure compatibility, 3GPP demands at least AMR-NB codec (narrow band), but the recommended speech codec for VoLTE is Adaptive Multi-Rate Wideband, also known as HD Voice. This codec is mandated in 3GPP networks that support 16 kHz sampling.\n\nFraunhofer IIS has proposed and demonstrated \"Full-HD Voice\", an implementation of the AAC-ELD (Advanced Audio CodingEnhanced Low Delay) codec for LTE handsets. Where previous cell phone voice codecs only supported frequencies up to 3.5 kHz and upcoming wideband audio services branded as \"HD Voice\" up to 7 kHz, Full-HD Voice supports the entire bandwidth range from 20 Hz to 20 kHz. For end-to-end Full-HD Voice calls to succeed, however, both the caller and recipient's handsets, as well as networks, have to support the feature.\n\nThe LTE standard covers a range of many different bands, each of which is designated by both a frequency and a band number:\n- North America 600, 700, 750, 800 850, 1900, 2100(AWS), 2300 (WCS), 2500, 2600 MHz (bands 2, 4, 5, 7, 12, 13, 17, 25, 26, 29, 30, 41, 66, 71)\n- Latin America and Caribbean 700, 850, 900, 1700, 1800, 1900, 2100, 2500, 2600 MHz (bands 1, 2, 3, 4, 5, 7, 8, 12, 13, 17, 28, 41)\n- Europe 450, 700, 800, 900, 1500, 1800, 2100, 2300, 2600, 3500, 3700 MHz (bands 1, 3, 7, 8, 20, 22, 28, 31, 32, 38, 40, 42, 43)\n- Asia 450, 700, 800, 850, 900, 1500, 1800, 1900, 2100, 2300, 2500, 2600, 3500 MHz (bands 1, 3, 5, 7, 8, 11, 18, 19, 21, 26, 21, 28, 31, 38, 39, 40, 41, 42)\n- Africa 700, 800, 850, 900, 1800, 2100, 2500, 2600 MHz (bands 1, 3, 5, 7, 8, 20, 28, 41)\n- Oceania (incl. Australia and New Zealand) 700, 800, 850, 1800, 2100, 2300, 2600 MHz (bands 1, 3, 7, 12, 20, 28, 40)\n\nAs a result, phones from one country may not work in other countries. Users will need a multi-band capable phone for roaming internationally.\n\nAccording to the European Telecommunications Standards Institute's (ETSI) intellectual property rights (IPR) database, about 50 companies have declared, as of March 2012, holding essential patents covering the LTE standard. The ETSI has made no investigation on the correctness of the declarations however, so that \"any analysis of essential LTE patents should take into account more than ETSI declarations.\" Independent studies have found that about 3.3 to 5 percent of all revenues from handset manufacturers are spent on standard-essential patents. This is less than the combined published rates, due to reduced-rate licensing agreements, such as cross-licensing.\n\n", "related": "\n- 4G-LTE filter\n- Comparison of wireless data standards\n- E-UTRAthe radio access network used in LTE\n- HSPA+an enhancement of the 3GPP HSPA standard\n- Flat IPflat IP architectures in mobile networks\n- LTE-A Pro\n- LTE-A\n- LTE-U\n- NarrowBand IoT (NB-IoT)\n- Simulation of LTE Networks\n- QoS Class Identifier (QCI) the mechanism used in LTE networks to allocate proper Quality of Service to bearer traffic\n- System architecture evolutionthe re-architecturing of core networks in LTE\n- WiMAXa competitor to LTE\n\n- Agilent Technologies, \"LTE and the Evolution to 4G Wireless: Design and Measurement Challenges\", John Wiley & Sons, 2009\n- Beaver, Paul, \"What is TD-LTE?\", RF&Microwave Designline, September 2011.\n- E. Dahlman, H. Ekström, A. Furuskär, Y. Jading, J. Karlsson, M. Lundevall, and S. Parkvall, \"The 3G Long-Term EvolutionRadio Interface Concepts and Performance Evaluation\", IEEE Vehicular Technology Conference (VTC) 2006 Spring, Melbourne, Australia, May 2006\n- Erik Dahlman, Stefan Parkvall, Johan Sköld, Per Beming, \"3G EvolutionHSPA and LTE for Mobile Broadband\", 2nd edition, Academic Press, 2008,\n- Erik Dahlman, Stefan Parkvall, Johan Sköld, \"4GLTE/LTE-Advanced for Mobile Broadban\", Academic Press, 2011,\n- Sajal K. Das, John Wiley & Sons (April 2010): \"Mobile Handset Design\", .\n- Sajal K. Das, John Wiley & Sons (April 2016): \"Mobile Terminal Receiver Design: LTE and LTE-Advanced\", .\n- H. Ekström, A. Furuskär, J. Karlsson, M. Meyer, S. Parkvall, J. Torsner, and M. Wahlqvist, \"Technical Solutions for the 3G Long-Term Evolution\", \"IEEE Commun. Mag.\", vol. 44, no. 3, March 2006, pp. 38–45\n- Mustafa Ergen, \"Mobile Broadband: Including WiMAX and LTE\", Springer, NY, 2009\n- K. Fazel and S. Kaiser, \"Multi-Carrier and Spread Spectrum Systems: From OFDM and MC-CDMA to LTE and WiMAX\", 2nd Edition, John Wiley & Sons, 2008,\n- Dan Forsberg, Günther Horn, Wolf-Dietrich Moeller, Valtteri Niemi, \"LTE Security\", Second Edition, John Wiley & Sons Ltd, Chichester 2013,\n- Borko Furht, Syed A. Ahson, \"Long Term Evolution: 3GPP LTE Radio and Cellular Technology\", CRC Press, 2009,\n- Chris Johnson, \"LTE in BULLETS\", CreateSpace, 2010,\n- F. Khan, \"LTE for 4G Mobile BroadbandAir Interface Technologies and Performance\", Cambridge University Press, 2009\n- Guowang Miao, Jens Zander, Ki Won Sung, and Ben Slimane, \"Fundamentals of Mobile Data Networks\", Cambridge University Press, 2016,\n- Stefania Sesia, Issam Toufik, and Matthew Baker, \"LTEThe UMTS Long Term Evolution: From Theory to Practice\", Second Edition including Release 10 for LTE-Advanced, John Wiley & Sons, 2011,\n- Gautam Siwach, Dr Amir Esmailpour, \"LTE Security Potential Vulnerability and Algorithm Enhancements\", IEEE Canadian Conference on Electrical and Computer Engineering (IEEE CCECE), Toronto, Canada, May 2014\n- SeungJune Yi, SungDuck Chun, YoungDae lee, SungJun Park, SungHoon Jung, \"Radio Protocols for LTE and LTE-Advanced\", Wiley, 2012,\n- Y. Zhou, Z. Lei and S. H. Wong, Evaluation of Mobility Performance in 3GPP Heterogeneous Networks 2014 IEEE 79th Vehicular Technology Conference (VTC Spring), Seoul, 2014, pp. 1–5.\n\n- LTE homepage from the 3GPP website\n- LTE Frequently Asked Questions\n- LTE Deployment Map\n- A Simple Introduction to the LTE Downlink\n- LTE-3GPP.info: online LTE messages decoder fully supporting Rel.14\n"}
{"id": "50957870", "url": "https://en.wikipedia.org/wiki?curid=50957870", "title": "SD-WAN", "text": "SD-WAN\n\nSD-WAN is an acronym for software-defined networking in a wide area network (WAN). SD-WAN simplifies the management and operation of a WAN by decoupling the networking hardware from its control mechanism. This concept is similar to how software-defined networking implements virtualization technology to improve data center management and operation.\n\nA key application of SD-WAN is to allow companies to build higher-performance WANs using lower-cost and commercially available Internet access, enabling businesses to partially or wholly replace more expensive private WAN connection technologies such as MPLS.\n\nAmerican marketing research firm Gartner predicted in 2018 that by 2023 more than 90 percent of WAN edge infrastructure refresh initiatives will be based on virtualized customer premises equipment (vCPE) platforms or SD-WAN software/appliances.\n\nWANs allow companies to extend their computer networks over large distances, connecting remote branch offices to data centers and each other, and delivering applications and services required to perform business functions. Due to the physical constraints imposed by the propagation time over large distances, and the need to integrate multiple service providers to cover global geographies (often crossing nation boundaries), WANs face important operational challenges, including network congestion, packet delay variation, packet loss, and even service outages. Modern applications such as VoIP calling, videoconferencing, streaming media, and virtualized applications and desktops require low latency. Bandwidth requirements are also increasing, especially for applications featuring high-definition video. It can be expensive and difficult to expand WAN capability, with corresponding difficulties related to network management and troubleshooting.\n\nSD-WAN products are designed to address these network problems. By enhancing or even replacing traditional branch routers with virtualization appliances that can control application-level policies and offer a network overlay, less expensive consumer-grade Internet links can act more like a dedicated circuit. This simplifies the setup process for branch personnel. MEF Forum has defined an SD-WAN architecture consisting of an SD-WAN Edge, SD-WAN Controller and SD-WAN Orchestrator. The SD-WAN Edge is a physical or virtual network function that is placed at an organization's branch/regional/central office site, data center, and in public or private clouds cloud platforms. MEF Forum has published the first SD-WAN service standard, MEF 70 which defines the fundamental characteristics of an SD-WAN service plus service requirements and attributes.\n\nThe SD-WAN Orchestrator, which typically also includes the SD-WAN Controller functionality, is used to set centralized policies which are used to make forwarding decisions for Application Flows. Application flows are IP packets that have been classified to determine their user application or grouping of applications to which they are associated. The grouping of Application Flows based on a common type, e.g., conferencing applications, is referred to as an Application Flow Group in MEF 70. Per MEF 70, the SD-WAN Edge classifies incoming IP packets at the SD-WAN UNI, determines, via OSI Layer 2 through Layer 7 classification, which Application Flow the IP packets belong to, and then applies the policies to block the Application Flows or allow the Application Flows to be forwarded based on the availability of a route to the destination SD-WAN UNI on a remote SD-WAN Edge. This helps ensure that application performance meets service level agreements (SLAs).\n\nWANs were very important for the development of networking technologies in general and were for a long time the most important application of networks both for military and enterprise applications. The ability to communicate data over large distances was one of the main driving factors for the development of data communications technologies, as it made it possible to overcome the distance limitations, as well as shortening the time necessary to exchange messages with other parties.\n\nLegacy WANs technologies allowed communication over circuits connecting two or more endpoints. Earlier technologies supported point-to-point communication over a slow speed circuit, usually between two fixed locations. As technology evolved, WAN circuits became faster and more flexible. Innovations like circuit and packet switching (in the form of X.25, ATM and later Internet Protocol or Multiprotocol Label Switching communications) allowed communication to become more dynamic, supporting ever-growing networks.\n\nThe need for strict control, security and quality of service meant that multinational corporations were very conservative in leasing and operating their WANs. National regulations restricted the companies that could provide local service in each country, and complex arrangements were necessary to establish truly global networks. All that changed with the growth of the Internet, which allowed entities around the world to connect to each other. However, over the first years, the uncontrolled nature of the Internet was not considered adequate or safe for private corporate use.\n\nIndependent of safety concerns, connectivity to the Internet became a mandatory necessity to the point where every branch required Internet access. At first, due to the safety concerns, private communication were still done via WAN, and communication with other entities (including customers and partners) moved to the Internet.\n\nAs the Internet grew in reach and maturity, companies started to evaluate how to leverage it for private corporate communications. During the early 2000s, application delivery over the WAN became an important topic of research and commercial innovation . Over the next decade, the increasing computing power made it possible to create software-based appliances that were able to analyze traffic and make informed decisions in real time, making it possible to create large-scale overlay networks over the public Internet that could replicate all the functionality of legacy WANs, at a fraction of the cost.\n\nSD-WAN combines several technologies to create full-fledged private networks, with the ability to dynamically share network bandwidth across the connection points.. Additional enhancements include central controllers, zero-touch provisioning, integrated analytics and on-demand circuit provisioning, with some network intelligence based in the cloud, allowing centralized policy management and security.\n\nNetworking publications started using the term SD-WAN to describe this new networking trend as early as 2014.\n\nResearch firm Gartner has defined an SD-WAN as having four required characteristics:\n\n- The ability to support multiple connection types, such as MPLS, Last Mile Fiber Optic Network or through high speed cellular networks e.g. 4G LTE and 5G wireless technologies\n- The ability to do dynamic path selection, for load sharing and resiliency purposes\n- A simple interface that is easy to configure and manage\n- The ability to support VPNs, and third party services such as WAN optimization controllers, firewalls and web gateways\n\nSD-WAN products can be physical appliances or software based only.\n\nFeatures of SD-WANs include resilience, quality of service (QoS), security, and performance, with flexible deployment options; simplified administration and troubleshooting; and online traffic engineering.\n\nA resilient SD-WAN reduces network downtime. To be resilient, the technology must feature real time detection of outages and automatic switch over (fail over) to working links.\n\nSD-WAN technology supports quality of service by having application level awareness, giving bandwidth priority to the most critical applications. This may include dynamic path selection, sending an application on a faster link, or even splitting an application between two paths to improve performance by delivering it faster.\n\nSD-WAN communication is usually secured using IPsec, a staple of WAN security.\n\nSD-WANs can improve application delivery using caching, storing recently accessed information in memory to speed future access.\n\nMost SD-WAN products are available as pre-configured appliances, placed at the network edge in data centers, branch offices and other remote locations. There are also virtual appliances that can work on existing network hardware, or the appliance can be deployed as a virtual appliance on the cloud in environments such as Amazon Web Services (AWS), Unified Communications as a service (UCaaS) or as Software as a Service (SaaS). This allows enterprises to benefit from SD-WAN services as they migrate application delivery from corporate servers to cloud based services such as Salesforce.com and Google apps.\n\nManagement simplicity is a key requirement for SD-WANs, per Gartner. As with network equipment in general, GUIs may be preferred to command line interface (CLI) methods of configuration and control. Other beneficial administrative features include automatic path selection, the ability to centrally configure each end appliance by pushing configuration changes out, and even a true software defined networking approach that lets all appliances and virtual appliances be configured centrally based on application needs rather than underlying hardware.\n\nWith a global view of network status, a controller that manages SD-WAN can perform careful and adaptive traffic engineering by assigning new transfer requests according to current usage of resources (links). For example, this can be achieved by performing central calculation of transmission rates at the controller and rate-limiting at the senders (end-points) according to such rates.\n\nThere are some similarities between SD-WAN and WAN optimization, the name given to the collection of techniques used to increase data-transfer efficiencies across WANs. The goal of each is to accelerate application delivery between branch offices and data centers, but SD-WAN technology focuses additionally on cost savings and efficiency, specifically by allowing lower cost network links to perform the work of more expensive leased lines, whereas WAN Optimization focuses squarely on improving packet delivery. An SD-WAN utilizing virtualization techniques assisted with WAN Optimization traffic control allows network bandwidth to dynamically grow or shrink as needed. SD-WAN technology and WAN optimization can be used separately or together, and some SD-WAN vendors are adding WAN optimization features to their products.\n\nA WAN edge router is a device that routes data packets between different WAN locations, giving an enterprise access to a carrier network. Also called a boundary router, it is unlike a core router, which only sends packets within a single network. SD-WANs can work as an overlay to simplify the management of existing WAN edge routers, by lowering dependence on routing protocols. SD-WAN can also potentially be an alternative to WAN Edge routers.\n\nSD-WANs are similar to hybrid WANs, and sometimes the terms are used interchangeably, but they are not identical. A hybrid WAN consists of different connection types, and may have a software defined network (SDN) component, but doesn't have to.\n\nCloud-based SD-WAN offers advanced features, such as enhanced security, seamless cloud and support for mobile users, that result naturally from the use of cloud infrastructure. As a result, cloud-based SD-WAN can replace MPLS, enabling organizations to release resources once tied to WAN investments and create new capabilities.\n\nSD-WAN appliances alone do not solve the middle-mile performance issues of the Internet core. SD-CORE architectures are more consistent than the Internet, routing traffic optimally through the core. SD-CORE is available as Independent MPLS backbones or Software-defined backbones. \n\nAs there is no standard algorithm for SD-WAN controllers, device manufacturers each use their own proprietary algorithm in the transmission of data. These algorithms determine which traffic to direct over which link and when to switch traffic from one link to another. Given the breadth of options available in relation to both software and hardware SD-WAN control solutions, it's imperative they be tested and validated under real-world conditions within a lab setting prior to deployment.\n\nThere are multiple solutions available for testing purposes, ranging from purpose-built network emulation appliances which can apply specified network impairments to the network being tested in order to reliably validate performance, to software-based solutions.\n\nIT website Network World divides the SD-WAN vendor market into three groups: established networking vendors who are adding SD-WAN products to their offerings, WAN specialists who are starting to integrate SD-WAN functionality into their products, and startups focused specifically on the SD-WAN market.\n\nAlternatively, a market overview by Nemertes Research groups SD-WAN vendors into categories based on their original technology space, and which are \"Pure-play SD-WAN providers\", \"WAN optimization vendors\", \"Link-aggregation vendors\", and \"General network vendors\" While Network World's second category (startups focused specifically on the SD-WAN market), is generally equivalent to Nemertes' \"Pure-play SD-WAN providers\" category, Nemertes offers a more detailed view of the preexisting WAN and overall networking providers.\n\nAdditionally, Nemertes Research also describes the in-net side of the SD-WAN market, describing the go-to-market strategy of connectivity providers entering the SD-WAN market. These providers include \"Network-as-a-service vendors\", \"Carriers or telcos\", \"Content delivery networks\" and \"Secure WAN providers\".\n\nSeveral online resources, including the networking technology podcast \"Packet Pushers\", keep an updated list of existing SD-WAN vendors. In June 2018, Network World named 10 hot SD-WAN startups.\n\nMEF 70 standardizes SD-WAN service attributes and uses standard IPv4 and IPv6 routing protocols. SD-WAN services also use standard IPsec encryption protocols. Additional standardization for other SD-WAN functions and related security functionality not covered in MEF 70 are under development at the MEF Forum. There are several opensource SD-WAN solutions and opensource SD-WAN implementations available. For example, the Linux Foundation has three projects that intersect with and help the SD-WAN market: ONAP, OpenDaylight Project, and the Tungsten Fabric (formerly Juniper Networks' OpenContrail).\n", "related": "NONE"}
{"id": "51257673", "url": "https://en.wikipedia.org/wiki?curid=51257673", "title": "False Answer Supervision", "text": "False Answer Supervision\n\nFalse Answer Supervision (FAS) refers to VoIP fraud, when A-party is incorrectly billed: billed duration is more than duration of actual telephone conversation. The FAS is usually performed by VoIP wholesalers in their softswitches for randomly selected calls. Adding a small amount of extra billed seconds for many calls means a big revenue for the VoIP wholesaler. Actually it means stealing of money from caller (A-party).\n\nThe FAS fraud can be implemented in a softswitch in many different ways. Here are few of them:\n1. False billing of A-party without calling B-party. Usually a fake ringback tone, loopback audio or voicemail message is played\n2. Start of billing before actual answer of B-party\n3. Extra billing after disconnection of B-party\n\nThe FAS can be detected and blocked in a softswitch. Common methods are:\n1. Manual verification of Call Detail Records, listening to voice recordings\n2. Identification of FAS types and using algorithms to automatically detect the FAS\n- RTP audio signal processing: detection of voice\n- RTP audio signal processing: detection of silence\n- RTP audio signal processing: detection of ringback tone\n\n", "related": "\n- Phone fraud\n- Voice over IP\n- Telecommunications billing\n- Softswitch\n- FAS described on voip-info.org\n"}
{"id": "2512475", "url": "https://en.wikipedia.org/wiki?curid=2512475", "title": "Application-oriented networking", "text": "Application-oriented networking\n\nApplication-oriented networking (AON) involves network devices designed to aid in computer-to-computer application integration. Application-oriented networks are sometimes called \"intelligent networks\" or \"content-based routing networks\" and they are generally network technology that can use the content of a network packet or message to take some sort of action. \n\nApplication-oriented networking was popularized by Cisco Systems in response to increasing use of XML messaging (combined with related standards such as XSLT, XPath and XQuery) to link miscellaneous applications, data sources and other computing assets. Most Application-Orientated Networks manipulate structured data based in a human-readable format like XML.\n\nMany of the operations required to mediate between applications, or to monitor their transactions, can be built into network devices that are optimized for the purpose.\n\nThe rules and policies for performing these operations, also expressed in XML, are specified separately and downloaded as required. Cisco has adopted the AON acronym as the name of a family of products that function in this way.\n\nDuring the rise of the internet many routing decisions were made at layer 4 i.e. based on the TCP/IP address and/or the port number. Application-oriented networks work at layer 7 of the OSI stack and because they can examine the content of the message they can make routing decisions based on many different criteria including such things as the value of the purchase order or the ship date.\n\n", "related": "\n- Enterprise Application Integration\n\n- XML Security in Netscaler\n- Definition\n"}
{"id": "52458933", "url": "https://en.wikipedia.org/wiki?curid=52458933", "title": "Computer Aided Transceiver", "text": "Computer Aided Transceiver\n\nA computer aided transceiver (CAT) is a device used by radio amateurs for controlling a transceiver radio receiver using a computer.\n\nConventional transmitters are manually controlled and used to transmit voice using buttons, dials, etc. However, advances in electronics have come to market devices that can be controlled by a computer and allowing digital modes such as packet radio and also the use of satellite tracking, because it can continuously change the device's frequency according to the Doppler effect. This is done by connecting Radio receiver and a PC using a CAT interface and a CAT Program \n\nA CAT interface is a piece of hardware that connects between the PC and a radio that provides a connection to allows the radio and the PC to communicate with each other. The CAT interface provides the signals to and fro via correct voltage levels and in the case of a Universal Serial Bus (USB) CAT interface it requires a \"protocol\" for communication but communication itself is down to the radio and the software on the PC.\nA Software that may be called a CAT program allows a radio to be controlled through the PC. Changes made on the radio through user interactions on the CAT Program is (generally) shown on the PC's screen. Functionality of CAT equipment (software & interface) is down the radio and what features the software writers included in the CAT software. Modern radio systems do have more CAT functionality\nIf you run a logging program that supports CAT, then that software may take advantage of the CAT system by retrieving information from the radio to help fill in log details, such as the frequency that the contact was made on. \nCAT is also useful on many radios were there are many sub-menus in the radios menu system, many of the sub-menu items can be easily changed via the PC. On many HF radios the CAT system is also used to program the memories on the radio, but you would need to use appropriate programming software.\n\nA CAT interface do not revive or transmit any DATA mode, that is the purpose of a DATA interface. Although, both may be used at the same time with correct CAT Equipment.\n\nDATA modes, and getting audio to and from the PC is the function of a DATA interface. A completely different thing but it is easier and more useful when CAT and DATA are used at the same time. Wouldn't it be nice to have an interface that could operate Frequency-shift keying (FSK), Audio FSK (AFSK), (real) Morse Code (CW), with a CAT interface and its own sound card... (eg. The DigiMaster Pro3).\n\n", "related": "\n- : A library that allows to exploit the CAT interfaces of many radio transceivers.\n- Socialhams : A blog explaining the use of CAT and it's interfaces using RS232.\n"}
{"id": "3411777", "url": "https://en.wikipedia.org/wiki?curid=3411777", "title": "Quality of experience", "text": "Quality of experience\n\nQuality of Experience (QoE) is a measure of the delight or annoyance of a customer's experiences with a service (e.g., web browsing, phone call, TV broadcast). QoE focuses on the entire service experience; it is a holistic concept, similar to the field of user experience, but with its roots in telecommunication. QoE is an emerging multidisciplinary field based on social psychology, cognitive science, economics, and engineering science, focused on understanding overall human quality requirements.\n\nIn 2013, within the context of the COST Action \"QUALINET\", QoE has been defined as:The degree of delight or annoyance of the user of an application or service. It results from the fulfillment of his or her expectations with respect to the utility and / or enjoyment of the application or service in the light of the user’s personality and current state.This definition has been adopted in 2016 by the International Telecommunication Union in Recommendation ITU-T P.10. Before, various definitions of QoE had existed in the domain, with the above-mentioned definition now finding wide acceptance in the community.\n\nQoE has historically emerged from Quality of Service (QoS), which attempts to objectively measure service parameters (such as packet loss rates or average throughput). QoS measurement is most of the time not related to a customer, but to the media or network itself. QoE however is a purely subjective measure from the user’s perspective of the overall quality of the service provided, by capturing people’s aesthetic and hedonic needs.\n\nQoE looks at a vendor's or purveyor's offering from the standpoint of the customer or end user, and asks, \"What mix of goods, services, and support, do you think will provide you with the perception that the total product is providing you with the experience you desired and/or expected?\" It then asks, \"Is this what the vendor/purveyor has actually provided?\" If not, \"What changes need to be made to enhance your total experience?\" In short, QoE provides an assessment of human expectations, feelings, perceptions, cognition and satisfaction with respect to a particular product, service or application.\n\nQoE is a blueprint of all human subjective and objective quality needs and experiences arising from the interaction of a person with technology and with business entities in a particular context. Although QoE is perceived as subjective, it is an important measure that counts for customers of a service. Being able to measure it in a controlled manner helps operators understand what may be wrong with their services and how to improve them.\n\nQoE aims at taking into consideration every factor that contributes to a user's perceived quality of a system or service. This includes system, human and contextual factors. The following so-called \"influence factors\" have been identified and classified by Reiter et al.:\n- Human Influence Factors\n- Low-level processing (visual and auditory acuity, gender, age, mood, …)\n- Higher-level processing (cognitive processes, socio-cultural and economic background, expectations, needs and goals, other personality traits…)\n- System Influence Factors\n- Content-related\n- Media-related (encoding, resolution, sample rate, …)\n- Network-related (bandwidth, delay, jitter, …)\n- Device-related (screen resolution, display size, …)\n- Context Influence Factors\n- Physical context (location and space)\n- Temporal context (time of day, frequency of use, …)\n- Social context (inter-personal relations during experience)\n- Economic context\n- Task context (multitasking, interruptions, task type)\n- Technical and information context (relationship between systems)\nStudies in the field of QoE have typically focused on system factors, primarily due to its origin in the QoS and network engineering domains. Through the use of dedicated test laboratories, the context is often sought to be kept constant.\n\nQoE is strongly related to but different from the field of User Experience (UX), which also focuses on users' experiences with services. Historically, QoE has emerged from telecommunication research, while UX has its roots in Human–Computer Interaction. Both fields can be considered multi-disciplinary. In contrast to UX, the goal of improving QoE for users was more strongly motivated by economic needs.\n\nWechsung and De Moor identify the following key differences between the fields:\nAs a measure of the end-to-end performance at the service level from the user's perspective, QoE is an important metric for the design of systems and engineering processes. This is particularly relevant for video services because – due to their high traffic demands –, bad network performance may highly affect the user's experience. So, when designing systems, the expected output, i.e. the expected QoE, is often taken into account – also as a system output metric and optimization goal.\n\nTo measure this level of QoE, human ratings can be used. The mean opinion score (MOS) is a widely used measure for assessing the quality of media signals. It is a limited form of QoE measurement, relating to a specific media type, in a controlled environment and without explicitly taking into account user expectations. The MOS as an indicator of experienced quality has been used for audio and speech communication, as well as for the assessment of quality of Internet video, television and other multimedia signals, and web browsing. Due to inherent limitations in measuring QoE in a single scalar value, the usefulness of the MOS is often debated.\n\nSubjective quality evaluation requires a lot of human resources, establishing it as a time-consuming process. Objective evaluation methods can provide quality results faster, but require dedicated computing resources. Since such instrumental video quality algorithms are often developed based on a limited set of subjective data, their QoE prediction accuracy may be low when compared to human ratings.\n\nQoE metrics are often measured at the end devices and can conceptually be seen as the remaining quality after the distortion introduced during the preparation of the content and the delivery through the network, until it reaches the decoder at the end device. There are several elements in the media preparation and delivery chain, and some of them may introduce distortion. This causes degradation of the content, and several elements in this chain can be considered as ”QoE-relevant“ for the offered services. The causes of degradation are applicable for any multimedia service, that is, not exclusive to video or speech. Typical degradations occur at the encoding system (compression degradation), transport network, access network (e.g., packet loss or packet delay), home network (e.g. WiFi performance) and end device (e.g. decoding performance).\n\nSeveral QoE-centric network management and bandwidth management solutions have been proposed, which aim to improve the QoE delivered to the end-users.\n\nWhen managing a network, QoE fairness may be taken into account in order to keep the users sufficiently satisfied (i.e., high QoE) in a fair manner. From a QoE perspective, network resources and multimedia services should be managed in order to guarantee specific QoE levels instead of classical QoS parameters, which are unable to reflect the actual delivered QoE. A pure QoE-centric management is challenged by the nature of the Internet itself, as the Internet protocols and architecture were not originally designed to support today's complex and high demanding multimedia services.\n\nAs an example for an implementation of QoE management, network nodes can become QoE-aware by estimating the status of the multimedia service as perceived by the end-users. This information can then be used to improve the delivery of the multimedia service over the network and proactively improve the users' QoE. This can be achieved, for example, via traffic shaping. QoE management gives the service provider and network operator the capability to minimize storage and network resources by allocating only the resources that are sufficient to maintain a specific level of user satisfaction.\n\nAs it may involve limiting resources for some users or services in order to increase the overall network performance and QoE, the practice of QoE management requires that net neutrality regulations are considered.\n", "related": "NONE"}
{"id": "22612797", "url": "https://en.wikipedia.org/wiki?curid=22612797", "title": "PEGASUS", "text": "PEGASUS\n\nPEGASIS is an encryption algorithm used for satellite telemetry, command link and mission data transfers.\n\nAccording to budget item justification document for FY 2004–2005, this cryptographic algorithm is used for Global Positioning Systems (GPS), Space-Based Infrared Systems (SBIRS), MILSATCOM, and other Special Project Systems.\n\n- PEGASUS products\n", "related": "NONE"}
{"id": "1645752", "url": "https://en.wikipedia.org/wiki?curid=1645752", "title": "Mean opinion score", "text": "Mean opinion score\n\nMean opinion score (MOS) is a measure used in the domain of Quality of Experience and telecommunications engineering, representing overall quality of a stimulus or system. It is the arithmetic mean over all individual \"values on a predefined scale that a subject assigns to his opinion of the performance of a system quality\". Such ratings are usually gathered in a subjective quality evaluation test, but they can also be algorithmically estimated.\n\nMOS is a commonly used measure for video, audio, and audiovisual quality evaluation, but not restricted to those modalities. ITU-T has defined several ways of referring to a MOS in Recommendation P.800.1, depending on whether the score was obtained from audiovisual, conversational, listening, talking, or video quality tests.\n\nThe MOS is expressed as a single rational number, typically in the range 1–5, where 1 is lowest perceived quality, and 5 is the highest perceived quality. Other MOS ranges are also possible, depending on the rating scale that has been used in the underlying test. The Absolute Category Rating scale is very commonly used, which maps ratings between \"Bad\" and \"Excellent\" to numbers between 1 and 5, as seen in below table.\n\nOther standardized quality rating scales exist in ITU-T recommendations (such as P.800 or P.910). For example, one could use a continuous scale ranging between 1–100. Which scale is used depends on the purpose of the test. In certain contexts there are no statistically significant differences between ratings for the same stimuli when they are obtained using different scales.\n\nThe MOS is calculated as the arithmetic mean over single ratings performed by human subjects for a given stimulus in a subjective quality evaluation test. Thus:\n\nWhere are the individual ratings for a given stimulus by subjects.\n\nThe MOS is subject to certain mathematical properties and biases. In general, there is an ongoing debate on the usefulness of the MOS to quantify Quality of Experience in a single scalar value.\n\nWhen the MOS is acquired using a categorical rating scales, it is based on – similar to Likert scales – an ordinal scale. In this case, the ranking of the scale items is known, but their interval is not. Therefore, it is mathematically incorrect to calculate a mean over individual ratings in order to obtain the central tendency; the median should be used instead. However, in practice and in the definition of MOS, it is considered acceptable to calculate the arithmetic mean.\n\nIt has been shown that for categorical rating scales (such as ACR), the individual items are not perceived equidistant by subjects. For example, there may be a larger \"gap\" between \"Good\" and \"Fair\" than there is between \"Good\" and \"Excellent\". The perceived distance may also depend on the language into which the scale is translated. However, there exist studies that could not prove a significant impact of scale translation on the obtained results.\n\nSeveral other biases are present in the way MOS ratings are typically acquired. In addition to the above-mentioned issues with scales that are perceived non-linearly, there is a so-called \"range-equalization bias\": subjects, over the course of a subjective experiment, tend to give scores that span the entire rating scale. This makes it impossible to compare two different subjective tests if the range of presented quality differs. In other words, the MOS is never an absolute measure of quality, but only relative to the test in which it has been acquired.\n\nFor the above reasons – and due to several other contextual factors influencing the perceived quality in a subjective test – a MOS value should only be reported if the context in which the values have been collected in is known and reported as well. MOS values gathered from different contexts and test designs therefore should not be directly compared. ITU-T Recommendation P.800.2 prescribes how MOS values should be reported. Specifically, P.800.2 says:it is not meaningful to directly compare MOS values produced from separate experiments, unless those experiments were explicitly designed to be compared, and even then the data should be statistically analysed to ensure that such a comparison is valid.\n\nMOS historically originates from subjective measurements where listeners would sit in a \"quiet room\" and score a telephone call quality as they perceived it. This kind of test methodology had been in use in the telephony industry for decades and was standardized in ITU-T recommendation P.800. It specifies that \"the talker should be seated in a quiet room with volume between 30 and 120 dB and a reverberation time less than 500 ms (preferably in the range 200–300 ms). The room noise level must be below 30 dBA with no dominant peaks in the spectrum.\" Requirements for other modalities were similarly specified in ITU recommendations later.\n\nObtaining MOS ratings may be time-consuming and expensive as it requires the recruitment of human assessors. For various use cases such as codec development or service quality monitoring purposes – where quality should be estimated repeatedly and automatically – MOS scores can also be predicted by objective quality models, which typically have been developed and trained using human MOS ratings. A question that arises from using such models is whether the MOS differences produced are noticeable to the users. For example, when rating images on a five point MOS scale, an image with a MOS equal to 5 is expected to be noticeably better in quality than one with a MOS equal to 1. Contrary to that, it is not evident whether an image with a MOS equal to 3.8 is noticeably better in quality than one with a MOS equal to 3.6. Research conducted on determining the smallest MOS difference that is perceptible to users for digital photographs showed that a MOS difference of approximately 0.46 is required in order for 75% of the users to be able to detect the higher quality image. Nevertheless, image quality expectation, and hence MOS, changes over time with the change of user expectations. As a result, minimum noticeable MOS differences determined using analytical methods such as in may change over time.\n\n", "related": "\n- Absolute Category Rating\n- Likert scale\n- MUSHRA (ITU-R Recommendation BS.1534)\n- Objective video quality\n- Subjective video quality\n"}
{"id": "1065362", "url": "https://en.wikipedia.org/wiki?curid=1065362", "title": "End-to-end encryption", "text": "End-to-end encryption\n\nEnd-to-end encryption (E2EE) is a system of communication where only the communicating users can read the messages. In principle, it prevents potential eavesdroppers – including telecom providers, Internet providers, and even the provider of the communication service – from being able to access the cryptographic keys needed to decrypt the conversation. \n\nIn many messaging systems, including email and many chat networks, messages pass through intermediaries and are stored by a third party, from which they are retrieved by the recipient. Even if the messages are encrypted, they are typically only encrypted 'in transit', and are stored in \"decrypted\" form by the third party. This allows the third party to provide search and other features, or to scan for illegal and unacceptable content, but also means they can be read and misused by anyone who has access to the stored messages on the third party system, whether this is by design or via a backdoor. This can be seen as a concern in many cases where privacy is very important, such as persons living under repressive governments, whistleblowing, mass surveillance, businesses whose reputation depends on its ability to protect third party data, negotiations and communications that are important enough to have a risk of targeted 'hacking', and where sensitive subjects such as health, and information about minors are involved.\n\nEnd-to-end encryption is intended to prevent data being read or secretly modified, other than by the true sender and recipient(s). The messages are encrypted by the sender but the third party does not have a means to decrypt them, and stores them encrypted. The recipient retrieves the encrypted data and decrypts it themselves. \n\nBecause no third parties can decipher the data being communicated or stored, for example, companies that use end-to-end encryption are unable to hand over texts of their customers' messages to the authorities.\n\nIn an E2EE system, encryption keys must only be known to the communicating parties. To achieve this goal, E2EE systems can encrypt data using a pre-arranged string of symbols, called a pre-shared secret (PGP), or a one-time secret derived from such a pre-shared secret (DUKPT). They can also negotiate a secret key on the spot using Diffie-Hellman key exchange (OTR).\n\nAs of 2016, typical server-based communications systems do not include end-to-end encryption. These systems can only guarantee the protection of communications between clients and servers, meaning that users have to trust the third parties who are running the servers with the original texts. End-to-end encryption is regarded as safer because it reduces the number of parties who might be able to interfere or break the encryption. In the case of instant messaging, users may use a third-party client to implement an end-to-end encryption scheme over an otherwise non-E2EE protocol.\n\nSome non-E2EE systems, such as Lavabit and Hushmail, have described themselves as offering \"end-to-end\" encryption when they did not. Other systems, such as Telegram and Google Allo, have been criticized for not having end-to-end encryption, which they offer, enabled by default. Telegram did not enable end-to-end encryption by default on VoIP calls while users were using desktop software version, but that problem was fixed quickly.\n\nSome encrypted backup and file sharing services provide client-side encryption. The encryption they offer is here not referred to as end-to-end encryption, because the services are not meant for sharing messages between users. However, the term \"end-to-end encryption\" is often used as a synonym for client-side encryption.\n\nEnd-to-end encryption ensures that data is transferred securely between endpoints. But, rather than try to break the encryption, an eavesdropper may impersonate a message recipient (during key exchange or by substituting his public key for the recipient's), so that messages are encrypted with a key known to the attacker. After decrypting the message, the snoop can then encrypt it with a key that they share with the actual recipient, or their public key in case of asymmetric systems, and send the message on again to avoid detection. This is known as a man-in-the-middle attack (MITM).\n\nMost end-to-end encryption protocols include some form of endpoint authentication specifically to prevent MITM attacks. For example, one could rely on certification authorities or a web of trust. An alternative technique is to generate cryptographic hashes (fingerprints) based on the communicating users’ public keys or shared secret keys. The parties compare their fingerprints using an outside (out-of-band) communication channel that guarantees integrity and authenticity of communication (but not necessarily secrecy), before starting their conversation. If the fingerprints match, there is in theory, no man in the middle. \n\nWhen displayed for human inspection, fingerprints are usually encoded into hexadecimal strings. These strings are then formatted into groups of characters for readability. For example, a 128-bit MD5 fingerprint would be displayed as follows:\n\nSome protocols display natural language representations of the hexadecimal blocks. As the approach consists of a one-to-one mapping between fingerprint blocks and words, there is no loss in entropy. The protocol may choose to display words in the user's native (system) language. This can, however, make cross-language comparisons prone to errors. In order to improve localization, some protocols have chosen to display fingerprints as base 10 strings instead of hexadecimal or natural language strings. Modern messaging applications can also display fingerprints as QR codes that users can scan off each other's devices.\n\nThe end-to-end encryption paradigm does not directly address risks at the communications endpoints themselves. Each user's computer can still be hacked to steal his or her cryptographic key (to create a MITM attack) or simply read the recipients’ decrypted messages both in real time and from log files. Even the most perfectly encrypted communication pipe is only as secure as the mailbox on the other end. Major attempts to increase endpoint security have been to isolate key generation, storage and cryptographic operations to a smart card such as Google's Project Vault. However, since plaintext input and output are still visible to the host system, malware can monitor conversations in real time. A more robust approach is to isolate all sensitive data to a fully air gapped computer. PGP has been recommended by experts for this purpose: However, as Bruce Schneier points out, Stuxnet developed by US and Israel successfully jumped air gap and reached Natanz nuclear plant's network in Iran. To deal with key exfiltration with malware, one approach is to split the Trusted Computing Base behind two unidirectionally connected computers that prevent either insertion of malware, or exfiltration of sensitive data with inserted malware.\n\nA backdoor is usually a secret method of bypassing normal authentication or encryption in a computer system, a product, or an embedded device, etc. Companies may also willingly or unwillingly introduce backdoors to their software that help subvert key negotiation or bypass encryption altogether. In 2013, information leaked by Edward Snowden showed that Skype had a backdoor which allowed Microsoft to hand over their users' messages to the NSA despite the fact that those messages were officially end-to-end encrypted.\n\n", "related": "\n- Comparison of instant messaging clients#Secure messengers – a table overview of instant messaging clients that offer end-to-end encryption\n- Comparison of instant messaging protocols\n- Comparison of VoIP software#Secure VoIP software – a table overview of VoIP clients that offer end-to-end encryption\n- Client-side encryption – the encryption of data before it is transmitted to a server\n- Point to Point Encryption\n"}
{"id": "53365013", "url": "https://en.wikipedia.org/wiki?curid=53365013", "title": "Mosaik Solutions", "text": "Mosaik Solutions\n\nMosaik Solutions (formerly American Roamer) is a company that specializes in wireless coverage data and wireless coverage maps, based in Memphis, Tennessee.\n\nThe company collects and crowdsources carrier signal quality from major telecommunications providers or users who have its consumer or enterprise mobile application installed. The data is used to provide insights into places around the world without access to cellular coverage and the development of new coverage patterns, as well as to provide maps showing what provider offers the best service in an area.\n\nIn 2011, the Federal Communications Commission (FCC), recognized Mosaik Solutions as the \"industry standard\" for the presence of wireless service at the census-block level.\n\nIn 2016, Mosaik purchased Sensorly, a free app developed to crowdsource cellular network performance service and provide coverage mapping for wireless networks worldwide.\n\nMapELEMENTS software is a visualization tool that allows users to analyze data from the largest cellular coverage database in the world.\n\nCellMaps is an interactive mapping solution that allows companies to show their network coverage directly on their website through an iframe or API. In 2013 Mosaik launched an android app for CellMaps that provides data directly from carriers so that users can determine what carrier meets their needs in a given area. On the map you can overlay multiple carriers, zoom to street-view level, and drop a pin onto any given spot to get a breakdown of carrier service in that area.\n\nSignal Insights is an SaaS platform service available for android users that measures and analyzes the customer's experience in cellular or Wi-Fi networks. Indoor mode allows a user to upload a building floor plan and then map and test specific points in the building for cellular or Wi-Fi connectivity. \n\nSensorly is a free app that crowdsources cellular network performance to provide coverage mapping worldwide and mobile speed data to help consumers make informed decisions when choosing a cellular carrier. In February 2017, Sensorly launched Map Trip, a feature that allows users to map their routes and share with others their signal data at a particular point in real time.\n\nTowerSource is a resource for locating cell towers and identifying ownership, availability, fiber routes, type and height. It was acquired by Mosaik Solutions in September 2014.\n\nNetwork Validator is a SaaS solution designed for users to quickly determine whether global cellular networks exist - by country, operator and wireless technology.\n\nCoverageRight is composed of licensed GIS file datasets that identify the marketed coverage of wireless operators in the United States and worldwide. It enables users to perform spatial analyses, monitor competitive build-outs, analyze coverage trends and assemble roaming footprints. This data has been utilized by the FCC to analyze wireless coverage nationwide.\n\nNetwork QoE is an enterprise platform that uses crowdsourced data from cellular devices to detect wireless network issues including 3G, 4G and wifi accessibility, network coverage holes and data performance issues.\n\nIn March 2017, Mosaik Solutions launched the Wireless Spectrum Report, a tabular dataset detailing facts about spectrum ownership and availability in the United States.\n\n- Official Website\n", "related": "NONE"}
{"id": "53624053", "url": "https://en.wikipedia.org/wiki?curid=53624053", "title": "Information element", "text": "Information element\n\nAn information element, sometimes informally referred to as a field, is an item in Q.931 and Q.2931 messages, IEEE 802.11 management frames, and cellular network messages sent between a base transceiver station and a mobile phone or similar piece of user equipment. An information element is often a type-length-value item, containing 1) a type (which corresponds to the label of a field), a length indicator, and a value, although any combination of one or more of those parts is possible. A single message may contain multiple information elements.\n\nThe abbreviation IE is found in many technical specification documents from 3GPP. It is not uncommon for a single specification document to contain thousands of references to IEs.\n\n", "related": "\n- Mobile telephony\n"}
{"id": "41232", "url": "https://en.wikipedia.org/wiki?curid=41232", "title": "Harmonic", "text": "Harmonic\n\nA harmonic is any member of the harmonic series. The term is employed in various disciplines, including music, physics, acoustics, electronic power transmission, radio technology, and other fields. It is typically applied to repeating signals, such as sinusoidal waves. A harmonic of such a wave is a wave with a frequency that is a positive integer multiple of the frequency of the original wave, known as the fundamental frequency. The original wave is also called the 1st harmonic, the following harmonics are known as higher harmonics. As all harmonics are periodic at the fundamental frequency, the sum of harmonics is also periodic at that frequency. For example, if the fundamental frequency is 50 Hz, a common AC power supply frequency, the frequencies of the first three higher harmonics are 100 Hz (2nd harmonic), 150 Hz (3rd harmonic), 200 Hz (4th harmonic) and any addition of waves with these frequencies is periodic at 50 Hz.\n\nIn music, harmonics are used on string instruments and wind instruments as a way of producing sound on the instrument, particularly to play higher notes and, with strings, obtain notes that have a unique sound quality or \"tone colour\". On strings, harmonics that are bowed have a \"glassy\", pure tone. On stringed instruments, harmonics are played by touching (but not fully pressing down the string) at an exact point on the string while sounding the string (plucking, bowing, etc.); this allows the harmonic to sound, a pitch which is always higher than the fundamental frequency of the string.\n\nHarmonics may also be called \"overtones\", \"partials\" or \"upper partials\". The difference between \"harmonic\" and \"overtone\" is that the term \"harmonic\" includes all of the notes in a series, including the fundamental frequency (e.g., the open string of a guitar). The term \"overtone\" only includes the pitches above the fundamental. In some music contexts, the terms \"harmonic\", \"overtone\" and \"partial\" are used fairly interchangeably.\n\nMost acoustic instruments emit complex tones containing many individual partials (component simple tones or sinusoidal waves), but the untrained human ear typically does not perceive those partials as separate phenomena. Rather, a musical note is perceived as one sound, the quality or timbre of that sound being a result of the relative strengths of the individual partials. Many acoustic oscillators, such as the human voice or a bowed violin string, produce complex tones that are more or less periodic, and thus are composed of partials that are near matches to integer multiples of the fundamental frequency and therefore resemble the ideal harmonics and are called \"harmonic partials\" or simply \"harmonics\" for convenience (although it's not strictly accurate to call a partial a harmonic, the first being real and the second being ideal).\n\nOscillators that produce harmonic partials behave somewhat like one-dimensional resonators, and are often long and thin, such as a guitar string or a column of air open at both ends (as with the modern orchestral transverse flute). Wind instruments whose air column is open at only one end, such as trumpets and clarinets, also produce partials resembling harmonics. However they only produce partials matching the odd harmonics, at least in theory. The reality of acoustic instruments is such that none of them behaves as perfectly as the somewhat simplified theoretical models would predict.\n\nPartials whose frequencies are not integer multiples of the fundamental are referred to as \"inharmonic partials\". Some acoustic instruments emit a mix of harmonic and inharmonic partials but still produce an effect on the ear of having a definite fundamental pitch, such as pianos, strings plucked pizzicato, vibraphones, marimbas, and certain pure-sounding bells or chimes. Antique singing bowls are known for producing multiple harmonic partials or multiphonics.\n\nAn overtone is any partial higher than the lowest partial in a compound tone. The relative strengths and frequency relationships of the component partials determine the timbre of an instrument. The similarity between the terms overtone and partial sometimes leads to their being loosely used interchangeably in a musical context, but they are counted differently, leading to some possible confusion. In the special case of instrumental timbres whose component partials closely match a harmonic series (such as with most strings and winds) rather than being inharmonic partials (such as with most pitched percussion instruments), it is also convenient to call the component partials \"harmonics\" but not strictly correct (because harmonics are numbered the same even when missing, while partials and overtones are only counted when present). This chart demonstrates how the three types of names (partial, overtone, and harmonic) are counted (assuming that the harmonics are present):\n\nIn many musical instruments, it is possible to play the upper harmonics without the fundamental note being present. In a simple case (e.g., recorder) this has the effect of making the note go up in pitch by an octave, but in more complex cases many other pitch variations are obtained. In some cases it also changes the timbre of the note. This is part of the normal method of obtaining higher notes in wind instruments, where it is called \"overblowing\". The extended technique of playing multiphonics also produces harmonics. On string instruments it is possible to produce very pure sounding notes, called harmonics or \"flageolets\" by string players, which have an eerie quality, as well as being high in pitch. Harmonics may be used to check at a unison the tuning of strings that are not tuned to the unison. For example, lightly fingering the node found halfway down the highest string of a cello produces the same pitch as lightly fingering the node of the way down the second highest string. For the human voice see Overtone singing, which uses harmonics.\n\nWhile it is true that electronically produced periodic tones (e.g. square waves or other non-sinusoidal waves) have \"harmonics\" that are whole number multiples of the fundamental frequency, practical instruments do not all have this characteristic. For example, higher \"harmonics\"' of piano notes are not true harmonics but are \"overtones\" and can be very sharp, i.e. a higher frequency than given by a pure harmonic series. This is especially true of instruments other than stringed or brass/woodwind ones, e.g., xylophone, drums, bells etc., where not all the overtones have a simple whole number ratio with the fundamental frequency. The fundamental frequency is the reciprocal of the period of the periodic phenomenon.\n\nThe following table displays the stop points on a stringed instrument, such as the guitar (guitar harmonics), at which gentle touching of a string will force it into a harmonic mode when vibrated. String harmonics (flageolet tones) are described as having a \"flutelike, silvery quality\" that can be highly effective as a special color or tone color (timbre) when used and heard in orchestration. It is unusual to encounter natural harmonics higher than the fifth partial on any stringed instrument except the double bass, on account of its much longer strings. Harmonics are widely used in plucked string instruments, such as acoustic guitar, electric guitar and electric bass. On an electric guitar played loudly through a guitar amplifier with distortion, harmonics are more sustained and can be used in guitar solos. In the heavy metal music lead guitar style known as shred guitar, harmonics, both natural and artificial, are widely used.\n\nAlthough harmonics are most often used on open strings (natural harmonics), occasionally a score will call for an artificial harmonic, produced by playing an overtone on an already stopped string. As a performance technique, it is accomplished by using two fingers on the fingerboard, the first to shorten the string to the desired fundamental, with the second touching the node corresponding to the appropriate harmonic. On fretted instruments, such as an electric guitar, the performer can look at the frets to determine where to stop the string and where to touch the node. On unfretted instruments, such as the violin and related instruments, playing artificial harmonics is an advanced technique, as it requires the performer to find two precise locations on the same string.\n\nHarmonics may be either used or considered as the basis of just intonation systems. Composer Arnold Dreyblatt is able to bring out different harmonics on the single string of his modified double bass by slightly altering his unique bowing technique halfway between hitting and bowing the strings. Composer Lawrence Ball uses harmonics to generate music electronically.\n\n", "related": "\n- Aristoxenus\n- Electronic tuner\n- Formant\n- Fourier series\n- Guitar harmonic\n- Harmonics (electrical power)\n- Harmonic oscillator\n- Harmonic series (music)\n- Harmony\n- Pure tone\n- Pythagorean tuning\n- Scale of harmonics\n- Spherical harmonics\n- Stretched octave\n- Subharmonic\n- Xenharmonic music\n\n- Harmonics, partials and overtones from fundamental frequency\n- Discussion of Sciarrino's violin etudes and notation issues\n- Harmonics\n- Hear and see harmonics on a Piano\n"}
{"id": "53946597", "url": "https://en.wikipedia.org/wiki?curid=53946597", "title": "Virgin Mobile Saudi Arabia", "text": "Virgin Mobile Saudi Arabia\n\nVirgin Mobile KSA is a telecommunication company operating in the Kingdom of Saudi Arabia.\n\nThe company behind Virgin Mobile Saudi Arabia was formally called the Virgin Mobile Saudi Consortium — a Saudi Arabian company that brings together local, regional and global shareholders and experts in mobile telecommunications.\n\nThe company is headquartered in Riyadh and has outlets across the kingdom and a member care center in Jeddah.\n\nVirgin Mobile Saudi Arabia was awarded a licence by the Communications and Information Technology Commission to operate as a Mobile Virtual Network Operator in April 2014.\n\nVirgin Mobile Saudi Consortium LLC was formally incorporated in June 2013, shortly after the award of Virgin Mobile’s licence by CITC.\n\nThe company is part of Virgin Mobile Middle East & Africa and has local Saudi Arabian companies as shareholders.\n\nVirgin Mobile uses the STC network for all its Saudi based services. This network operates on the following frequencies: \n- 3G 2100 MHz\n- 4G LTE 1800/2300 MHz\n\nVirgin Mobile Saudi Arabia says it focuses mainly on “fairness and simplicity” in its offerings. \n\nVirgin Mobile’s telecommunications products include:\n- Number booking service\n- Prepaid plans\n- Postpaid plans\n- Prepaid mobile broadband services\nVirgin Mobile sells their products across Saudi Arabia.\n\n- Official website\n", "related": "NONE"}
{"id": "4671299", "url": "https://en.wikipedia.org/wiki?curid=4671299", "title": "Quindar tones", "text": "Quindar tones\n\nQuindar tones, most often referred to as the \"beeps\" that were heard during the American Apollo space missions, were a means by which remote transmitters on Earth were turned on and off so that the capsule communicator (CapCom) could communicate with the crews of the spacecraft. It was a means of in-band signaling to simulate the action of the push-to-talk and release-to-listen (often referred to as PTT) button commonly found on two-way radio systems and walkie-talkies.\n\nWhen Mission Control (in Houston, Texas) wanted to talk to astronauts, the capsule communicator (CapCom) pushed a button (push-to-talk, or PTT) that turned on the transmitter, then spoke, then released the button. When the transmitter is local, this is easy to arrange - the transmitter is connected directly to the PTT button. But to stay in continuous contact with the astronauts as they orbit the Earth, or travel to the Moon, NASA had to use tracking stations all around the world, switching from one station to the next as needed. To get the voice signal to the remote transmitter, dedicated telephone lines connected these stations to Houston. NASA could either build a parallel system for operating the transmitters - one line to carry the audio and another to carry the control signal for the PTT button (out-of-band signalling), or combine these two systems together, using audio tones to turn the transmitter on and off. Since dedicated phone lines were a very expensive measure at the time, NASA chose the use of tones to reduce the operating cost of the network. The same system was used in Project Gemini and was still in use with half duplex UHF Space Shuttle communications for transmitter RF keying.\n\nWith modern digital communication systems, Quindar tones are no longer necessary because a single communication line (such as a fiber optic cable) can simultaneously carry multiple communication channels in the form of data comprising both speech and signaling (the PTT signal), as well as video and telemetry.\n\nThe Quindar system, named after its manufacturer, used two tones, both being pure sine waves that were 250ms long. The \"intro tone\" was generated at 2,525 Hz and signaled the \"key down\" key-press of the PTT button and unmuted the audio. The \"outro tone\" was slightly lower at 2,475 Hz and signalled the release of the PTT button and muted the audio. The two tones were generated by special equipment located at Mission Control, and they were decoded by detectors located at the various tracking stations.\n\nThe selection of the tones allowed them to travel in the same passband as a human voice, which has a range from roughly 300 Hz to 3,000 Hz.\n\nTwo common misconceptions surround Quindar tones. The first is that one tone came from Earth and the other from the transmitters used by the astronauts while in space. This confusion exists because many ground-to-space transmissions were initiated by Mission Control and responded to by the astronauts. In this sequence, the CapCom would press the PTT, which would send the intro tone, and then speak. When finished speaking, the CapCom would release the PTT, which would send the outro tone, and the astronauts would respond to Mission Control. Therefore, those transmissions would consist of a \"beep\" (PTT press) followed by Houston talking, then another \"beep\" (PTT release) and finally the voice of the astronauts.\n\nAnother misconception about Quindar tones is that they were designed to signal the end of a transmission, similar to a courtesy tone used on many half-duplex radio repeaters. Although the astronauts may have secondarily used the Quindar outro tone to know when the CAPCOM had started/stopped speaking, no equivalent existed for Mission Control because the astronauts keyed their transmissions locally (inside the spacecraft) using either a PTT or VOX, neither of which required Quindar tones. Additionally, separate radio frequencies allowed both Houston and the astronauts to talk simultaneously if they wished and thereby made a courtesy tone as a way to minimize the possibility of both of them speaking at the same time unnecessary.\n\nQuindar tones were named for the manufacturer Quindar Electronics, Inc. Glen Swanson, historian at NASA's Johnson Space Center who edited the \"Mission Transcript Collection\", and Steve Schindler, an engineer with voice systems engineering at NASA's Kennedy Space Center, confirmed the origin of the name. \"Quindar tones, named after the manufacturer of the tone generation and detection equipment, are actually used to turn on and off, or 'key', the remote transmitters at the various tracking stations.\"\n\n- Apollo Lunar Surface Journal: Quindar Tones\n- The Mission Transcript Collection\n- Apollo 17 Onboard Voice Recorder Transcripts Link no longer active.\n- Communications Transcripts: Mercury Through Apollo\n- QEI, Inc. (formerly, Quindar Electronics Incorporated)\n- Science Friday podcast\n", "related": "NONE"}
{"id": "31686333", "url": "https://en.wikipedia.org/wiki?curid=31686333", "title": "Willis Graham Act", "text": "Willis Graham Act\n\nThe Willis Graham Act of 1921 effectively established telephone companies as natural monopolies, citing that \"there is nothing to be gained by local competition in the telephone industry.\" This repealed the Kingsbury Commitment, allowing AT&T to merge with or acquire competing telephone companies if the ICC approved.\n\nAT&T was incorporated in 1885 as a wholly owned subsidiary of American Bell. On December 30, 1899, AT&T acquired the assets of American Bell and became the parent company of the Bell System. In order to extend service nationwide, some inventions had to be developed to propagate the telephone signal, since the signals weaken as they travel through the telephone wires. Until Bell's second patent expired in 1894, Bell Telephone was the only company that could legally operate telephone systems in the USA. Between 1894 and 1904, after Bell's patents expired, over six thousand independent telephone companies arose in the US. \n\nThe rise of these new companies brought new problems. Telephone customers on different carriers had no way of contacting each other—there was no inter-connectivity between carriers. In order to connect all of the telephone customers, AT&T began acquiring independent telephone providers, much to the dismay of remaining independents. These independents complained to the attorney general that AT&T was eliminating the competition. In response to this, the attorney general referred the case to the Interstate Commerce Commission (ICC), which began an investigation. AT&T then agreed to a settlement, now known as the Kingsbury Commitment. This consisted of a letter from AT&T stating that \"Bell agreed to provide interconnection to the independents and to refrain from further acquisitions.\"\n\nHowever, AT&T continued to acquire more noncompeting companies. The Willis-Graham Act, which was passed in 1921, shifted merger oversight to the ICC, lessening AT&T's constraints on the acquisition of competitors. This essentially repealed the Kingsbury Commitment. Because of this, by 1924 AT&T had acquired 223 of the 234 independent telephone companies with approval of the ICC.\n", "related": "NONE"}
{"id": "3565119", "url": "https://en.wikipedia.org/wiki?curid=3565119", "title": "Infone", "text": "Infone\n\nInfone was a service launched by Metro One Telecommunications in 2003. The service was discontinued effective December 14, 2005.\n\nInfone included directory assistance and other services via a toll-free phone number. A user could call 888-411-1111 to request directory assistance, directions, traffic information, movie times, call completion, dinner reservation assistance and other services. \n\nInfone provided a number of innovative 411 'concierge'-like services, including movie listings from a live operator, and offered a feature where they could provide information from a linked Microsoft Outlook calendar when set up in advance. For a period of time they advertised heavily on U.S. television, featuring ads with then Governor of Minnesota Jesse Ventura, emphasizing their use of all U.S. based operators. The price offered was $0.89 per call up to 15 minutes (for use when the operator connects you to the requested number, as well as for additional information requests afterwards), with $0.05 for each additional minute, making Infone also a competitively priced long-distance service. New users received 5–10 free calls.\n\nInfone identified a registered user (along with billing information; the service was only payable by credit card) by caller ID (numbers were registered on signing up) and by an advanced voiceprint recognition system from SpeechWorks that identified the user when the user called from an unregistered telephone number (or no caller ID) through the use of a personal phrase spoken by the user (e.g., \"Hello Infone!\") after the welcome tone.\n", "related": "NONE"}
{"id": "1197962", "url": "https://en.wikipedia.org/wiki?curid=1197962", "title": "Information and communications technology", "text": "Information and communications technology\n\nInformation and communications technology (ICT) is an extensional term for information technology (IT) that stresses the role of unified communications and the integration of telecommunications (telephone lines and wireless signals) and computers, as well as necessary enterprise software, middleware, storage, and audiovisual systems, that enable users to access, store, transmit, and manipulate information.\n\nThe term \"ICT\" is also used to refer to the convergence of audiovisual and telephone networks with computer networks through a single cabling or link system. There are large economic incentives to merge the telephone network with the computer network system using a single unified system of cabling, signal distribution, and management. ICT is an umbrella term that includes any communication device, encompassing radio, television, cell phones, computer and network hardware, satellite systems and so on, as well as the various services and appliance with them such as video conferencing and distance learning.\n\nICT is a broad subject and the concepts are evolving. It covers any product that will store, retrieve, manipulate, transmit, or receive information electronically in a digital form (e.g., personal computers, digital television, email, or robots). Theoretical differences between interpersonal-communication technologies and mass-communication technologies have been identified by the philosopher Piyush Mathur. Skills Framework for the Information Age is one of many models for describing and managing competencies for ICT professionals for the 21st century.\n\nThe phrase \"information and communication technologies\" has been used by academic researchers since the 1980s. The abbreviation \"ICT\" became popular after it was used in a report to the UK government by Dennis Stevenson in 1997, and then in the revised National Curriculum for England, Wales and Northern Ireland in 2000. However, in 2012, the Royal Society recommended that the use of the term \"ICT\" should be discontinued in British schools \"as it has attracted too many negative connotations\". From 2014 the National Curriculum has used the word \"computing,\" which reflects the addition of computer programming into the curriculum.\n\nVariations of the phrase have spread worldwide. The United Nations has created a \"United Nations Information and Communication Technologies Task Force\" and an internal \"Office of Information and Communications Technology\".\n\nThe money spent on IT worldwide has been estimated as US$3.8 trillion in 2017 and has been growing at less than 5% per year since 2009. The estimate 2018 growth of the entire ICT is 5%. The biggest growth of 16% is expected in the area of new technologies (IoT, Robotics, AR/VR, and AI).\n\nThe 2014 IT budget of US federal government was nearly $82 billion. IT costs, as a percentage of corporate revenue, have grown 50% since 2002, putting a strain on IT budgets. When looking at current companies' IT budgets, 75% are recurrent costs, used to \"keep the lights on\" in the IT department, and 25% are cost of new initiatives for technology development.\n\nThe average IT budget has the following breakdown:\n- 31% personnel costs (internal)\n- 29% software costs (external/purchasing category)\n- 26% hardware costs (external/purchasing category)\n- 14% costs of external service providers (external/services).\n\nThe estimate of money to be spent in 2022 is just over US$6 trillion.\n\nThe world's technological capacity to store information grew from 2.6 (optimally compressed) exabytes in 1986 to 15.8 in 1993, over 54.5 in 2000, and to 295 (optimally compressed) exabytes in 2007, and some 5 zetta bytes in 2014. This is the informational equivalent to 1.25 stacks of CD-ROM from the earth to the moon in 2007, and the equivalent of 4,500 stacks of printed books from the earth to the sun in 2014.\nThe world's technological capacity to receive information through one-way broadcast networks was 432 exabytes of (optimally compressed) information in 1986, 715 (optimally compressed) exabytes in 1993, 1.2 (optimally compressed) zettabytes in 2000, and 1.9 zettabytes in 2007.\nThe world's effective capacity to exchange information through two-way telecommunication networks was 281 petabytes of (optimally compressed) information in 1986, 471 petabytes in 1993, 2.2 (optimally compressed) exabytes in 2000, 65 (optimally compressed) exabytes in 2007, and some 100 exabytes in 2014.\nThe world's technological capacity to compute information with humanly guided general-purpose computers grew from 3.0 × 10^8 MIPS in 1986, to 6.4 x 10^12 MIPS in 2007.\n\nThe following is a list of OECD countries by share of ICT sector in total value added in 2013.\nThe ICT Development Index ranks and compares the level of ICT use and access across the various countries around the world. In 2014 ITU (International Telecommunications Union) released the latest rankings of the IDI, with Denmark attaining the top spot, followed by South Korea. The top 30 countries in the rankings include most high-income countries where quality of life is higher than average, which includes countries from Europe and other regions such as \"Australia, Bahrain, Canada, Japan, Macao (China), New Zealand, Singapore and the United States; almost all countries surveyed improved their IDI ranking this year.\"\n\nOn 21 December 2001, the United Nations General Assembly approved Resolution 56/183, endorsing the holding of the World Summit on the Information Society (WSIS) to discuss the opportunities and challenges facing today's information society. According to this resolution, the General Assembly related the Summit to the United Nations Millennium Declaration's goal of implementing ICT to achieve Millennium Development Goals. It also emphasized a multi-stakeholder approach to achieve these goals, using all stakeholders including civil society and the private sector, in addition to governments.\n\nTo help anchor and expand ICT to every habitable part of the world, \"2015 is the deadline for achievements of the UN Millennium Development Goals (MDGs), which global leaders agreed upon in the year 2000.\">\n\nThe United Nations Educational, Scientific and Cultural Organisation (UNESCO), a division of the United Nations, has made integrating ICT into education part of its efforts to ensure equity and access to education. The following, taken directly from a UNESCO publication on educational ICT, explains the organization's position on the initiative.Information and Communication Technology can contribute to universal access to education, equity in education, the delivery of quality learning and teaching, teachers' professional development and more efficient education management, governance and administration. UNESCO takes a holistic and comprehensive approach to promoting ICT in education. Access, inclusion and quality are among the main challenges they can address. The Organization's Intersectral Platform for ICT in education focuses on these issues through the joint work of three of its sectors: Communication & Information, Education and Science.\n\nDespite the power of computers to enhance and reform teaching and learning practices, improper implementation is a widespread issue beyond the reach of increased funding and technological advances with little evidence that teachers and tutors are properly integrating ICT into everyday learning. Intrinsic barriers such as a belief in more traditional teaching practices and individual attitudes towards computers in education as well as the teachers own comfort with computers and their ability to use them all as result in varying effectiveness in the integration of ICT in the classroom.\nThere is some evidence that, to be effective in education, ICT must be fully integrated into the pedagogy. Specifically, when teaching literacy and math, using ICT in combination with Writing to Learn produces better results than traditional methods alone or ICT alone.\n\n\"Main article Mobile learning for refugees\"\n\nSchool environments play an important role in facilitating language learning. However, language and literacy barriers are obstacles preventing refugees from accessing and attending school, especially outside camp settings.\n\nMobile-assisted language learning apps are key tools for language learning. Mobile solutions can provide support for refugees’ language and literacy challenges in three main areas: literacy development, foreign language learning and translations. Mobile technology is relevant because communicative practice is a key asset for refugees and immigrants as they immerse themselves in a new language and a new society. Well-designed mobile language learning activities connect refugees with mainstream cultures, helping them learn in authentic contexts.\n\nICT has been employed as an educational enhancement in Sub-Saharan Africa since the 1960s. Beginning with television and radio, it extended the reach of education from the classroom to the living room, and to geographical areas that had been beyond the reach of the traditional classroom. As technology evolved and became more widely used, efforts in Sub-Saharan Africa were also expanded. In the 1990s a massive effort to push computer hardware and software into schools was undertaken, with the goal of familiarizing both students and teachers with computers in the classroom. Since then, multiple projects have endeavored to continue the expansion of ICT's reach in the region, including the One Laptop Per Child (OLPC) project, which by 2015 had distributed over 2.4 million laptops to nearly 2 million students and teachers.\n\nThe inclusion of ICT in the classroom, often referred to as M-Learning, has expanded the reach of educators and improved their ability to track student progress in Sub-Saharan Africa. In particular, the mobile phone has been most important in this effort. Mobile phone use is widespread, and mobile networks cover a wider area than internet networks in the region. The devices are familiar to student, teacher, and parent, and allow increased communication and access to educational materials. In addition to benefits for students, M-learning also offers the opportunity for better teacher training, which leads to a more consistent curriculum across the educational service area. In 2011, UNESCO started a yearly symposium called Mobile Learning Week with the purpose of gathering stakeholders to discuss the M-learning initiative.\n\nImplementation is not without its challenges. While mobile phone and internet use are increasing much more rapidly in Sub-Saharan Africa than in other developing countries, the progress is still slow compared to the rest of the developed world, with smartphone penetration only expected to reach 20% by 2017. Additionally, there are gender, social, and geo-political barriers to educational access, and the severity of these barriers vary greatly by country. Overall, 29.6 million children in Sub-Saharan Africa were not in school in the year 2012, owing not just to the geographical divide, but also to political instability, the importance of social origins, social structure, and gender inequality. Once in school, students also face barriers to quality education, such as teacher competency, training and preparedness, access to educational materials, and lack of information management.\n\nModern ICT\nIn modern society ICT is ever-present, with over three billion people having access to the Internet. With approximately 8 out of 10 Internet users owning a smartphone, information and data are increasing by leaps and bounds. This rapid growth, especially in developing countries, has led ICT to become a keystone of everyday life, in which life without some facet of technology renders most of clerical, work and routine tasks dysfunctional. The most recent authoritative data, released in 2014, shows \"that Internet use continues to grow steadily, at 6.6% globally in 2014 (3.3% in developed countries, 8.7% in the developing world); the number of Internet users in developing countries has doubled in five years (2009-2014), with two thirds of all people online now living in the developing world.\"\n\nHowever, hurdles are still large. \"Of the 4.3 billion people not yet using the Internet, 90% live in developing countries. In the world's 42 Least Connected Countries (LCCs), which are home to 2.5 billion people, access to ICTs remains largely out of reach, particularly for these countries' large rural populations.\" ICT has yet to penetrate the remote areas of some countries, with many developing countries dearth of any type of Internet. This also includes the availability of telephone lines, particularly the availability of cellular coverage, and other forms of electronic transmission of data. The latest \"Measuring the Information Society Report\" cautiously stated that the increase in the aforementioned cellular data coverage is ostensible, as \"many users have multiple subscriptions, with global growth figures sometimes translating into little real improvement in the level of connectivity of those at the very bottom of the pyramid; an estimated 450 million people worldwide live in places which are still out of reach of mobile cellular service.\"\n\nFavorably, the gap between the access to the Internet and mobile coverage has decreased substantially in the last fifteen years, in which \"2015 <nowiki>[was]</nowiki> the deadline for achievements of the UN Millennium Development Goals (MDGs), which global leaders agreed upon in the year 2000, and the new data show ICT progress and highlight remaining gaps.\" ICT continues to take on new form, with nanotechnology set to usher in a new wave of ICT electronics and gadgets. ICT newest editions into the modern electronic world include smart watches, such as the Apple Watch, smart wristbands such as the Nike+ FuelBand, and smart TVs such as Google TV. With desktops soon becoming part of a bygone era, and laptops becoming the preferred method of computing, ICT continues to insinuate and alter itself in the ever-changing globe.\n\nInformation communication technologies play a role in facilitating accelerated pluralism in new social movements today. The internet according to Bruce Bimber is \"accelerating the process of issue group formation and action\" and coined the term accelerated pluralism to explain this new phenomena. ICTs are tools for \"enabling social movement leaders and empowering dictators\" in effect promoting societal change. ICTs can be used to garner grassroots support for a cause due to the internet allowing for political discourse and direct interventions with state policy as well as change the way complaints from the populace are handled by governments. Furthermore, ICTs in a household are associated with women rejecting justifications for intimate partner violence. According to a study published in 2017, this is likely because “[a]ccess to ICTs exposes women to different ways of life and different notions about women’s role in society and the household, especially in culturally conservative regions where traditional gender expectations contrast observed alternatives.\"\n\nScholar Mark Warschauer defines a “models of access” framework for analyzing ICT accessibility. In the second chapter of his book, \"Technology and Social Inclusion: Rethinking the Digital Divide\", he describes three models of access to ICTs: devices, conduits, and literacy. Devices and conduits are the most common descriptors for access to ICTs, but they are insufficient for meaningful access to ICTs without third model of access, literacy. Combined, these three models roughly incorporate all twelve of the criteria of “Real Access” to ICT use, conceptualized by a non-profit organization called Bridges.org in 2005:\n\n1. Physical access to technology\n2. Appropriateness of technology\n3. Affordability of technology and technology use\n4. Human capacity and training\n5. Locally relevant content, applications, and services\n6. Integration into daily routines\n7. Socio-cultural factors\n8. Trust in technology\n9. Local economic environment\n10. Macro-economic environment\n11. Legal and regulatory framework\n12. Political will and public support\n\nThe most straightforward model of access for ICT in Warschauer’s theory is devices. In this model, access is defined most simply as the ownership of a device such as a phone or computer. Warschauer identifies many flaws with this model, including its inability to account for additional costs of ownership such as software, access to telecommunications, knowledge gaps surrounding computer use, and the role of government regulation in some countries. Therefore, Warschauer argues that considering only devices understates the magnitude of digital inequality. For example, the Pew Research Center notes that 96% of Americans own a smartphone, although most scholars in this field would contend that comprehensive access to ICT in the United States is likely much lower than that. \n\nA conduit requires a connection to a supply line, which for ICT could be a telephone line or Internet line. Accessing the supply requires investment in the proper infrastructure from a commercial company or local government and recurring payments from the user once the line is set up. For this reason, conduits usually divide people based on their geographic locations. As a Pew Research Center poll reports, rural Americans are 12% less likely to have broadband access than other Americans, thereby making them less likely to own the devices. Additionally, these costs can be prohibitive to lower-income families accessing ICTs. These difficulties have led to a shift toward mobile technology; fewer people are purchasing broadband connection and are instead relying on their smartphones for Internet access, which can be found for free at public places such as libraries. Indeed, smartphones are on the rise, with 37% of Americans using smartphones as their primary medium for internet access and 96% of Americans owning a smartphone.\n\nIn 1981, Sylvia Scribner and Michael Cole studied a tribe in Liberia, the Vai people, that has its own local language. Since about half of those literate in Vai have never had formal schooling, Scribner and Cole were able to test more than 1,000 subjects to measure the mental capabilities of literates over non-literates. This research, which they laid out in their book \"The Psychology of Literacy\", allowed them to study whether the literacy divide exists at the individual level. Warschauer applied their literacy research to ICT literacy as part of his model of ICT access.\n\nScribner and Cole found no generalizable cognitive benefits from Vai literacy; instead, individual differences on cognitive tasks were due to other factors, like schooling or living environment. The results suggested that there is “no single construct of literacy that divides people into two cognitive camps; [...] rather, there are gradations and types of literacies, with a range of benefits closely related to the specific functions of literacy practices.” Furthermore, literacy and social development are intertwined, and the literacy divide does not exist on the individual level.\n\nWarschauer draws on Scribner and Cole’s research to argue that ICT literacy functions similarly to literacy acquisition, as they both require resources rather than a narrow cognitive skill. Conclusions about literacy serve as the basis for a theory of the digital divide and ICT access, as detailed below:There is not just one type of ICT access, but many types. The meaning and value of access varies in particular social contexts. Access exists in gradations rather than in a bipolar opposition. Computer and Internet use brings no automatic benefit outside of its particular functions. ICT use is a social practice, involving access to physical artifacts, content, skills, and social support. And acquisition of ICT access is a matter not only of education but also of power.Therefore, Warschauer concludes that access to ICT cannot rest on devices or conduits alone; it must also engage physical, digital, human, and social resources. Each of these categories of resources have iterative relations with ICT use. If ICT is used well, it can promote these resources, but if it is used poorly, it can contribute to a cycle of underdevelopment and exclusion.\n\n", "related": "\n- Cloud computing\n- Cognitive infocommunications\n- DICOM\n- Digital divide\n- Example of Information and communication technologies for education\n- Gender digital divide\n- Global e-Schools and Communities Initiative\n- Hospital information system\n- Infocommunications\n- Information Age\n- Information and communication technologies for environmental sustainability\n- Market information systems\n- Mobile Web\n- Picture archiving and communication system\n- 21st century skills\n- World Information Technology and Services Alliance\n- Cantoni, L., & Danowski, J. A. (Eds.). (2015). Communication and Technology. Berlin: De Gruyter Mouton.\n- Caperna A., \"Integrating ICT into Sustainable Local Policies\".\n- Carnoy, Martin. \"ICT in Education: Possibilities and Challenges.\" Universitat Oberta de Catalunya, 2005.\n- \"Good Practice in Information and Communication Technology for Education.\" Asian Development Bank, 2009.\n- Oliver, Ron. \"The Role of ICT in Higher Education for the 21st Century: ICT as a Change Agent for Education.\" University, Perth, Western Australia, 2002.\n- Walter Ong, Orality and Literacy: The Technologizing of the Word (London, UK: Routledge, 1988), in particular Chapter 4\n- Measuring the Information Society Report: 2014. International Telecommunication Union.\n\n- ICT Facts and Figures\n- ICT Industry Statistics\n- Growth Impact of IT and communication advantage and disadvantage\n"}
{"id": "33094374", "url": "https://en.wikipedia.org/wiki?curid=33094374", "title": "Telecommunication", "text": "Telecommunication\n\nTelecommunication is the exchange of signs, signals, messages, words, writings, images and sounds or information of any nature by wire, radio, optical or other electromagnetic systems.\nTelecommunication occurs when the exchange of information between communication participants includes the use of technology. It is transmitted through a transmission medium, such as over physical media, for example, over electrical cable, or via electromagnetic radiation through space such as radio or light. Such transmission paths are often divided into communication channels which afford the advantages of multiplexing. Since the Latin term \"communicatio\" is considered the social process of information exchange, the term telecommunications is often used in its plural form because it involves many different technologies.\n\nEarly means of communicating over a distance included visual signals, such as beacons, smoke signals, semaphore telegraphs, signal flags and optical heliographs. Other examples of pre-modern long-distance communication included audio messages such as coded drumbeats, lung-blown horns, and loud whistles. 20th- and 21st-century technologies for long-distance communication usually involve electrical and electromagnetic technologies, such as telegraph, telephone, and teleprinter, networks, radio, microwave transmission, optical fiber, and communications satellites.\n\nA revolution in wireless communication began in the first decade of the 20th century with the pioneering developments in radio communications by Guglielmo Marconi, who won the Nobel Prize in Physics in 1909, and other notable pioneering inventors and developers in the field of electrical and electronic telecommunications. These included Charles Wheatstone and Samuel Morse (inventors of the telegraph), Alexander Graham Bell (inventor of the telephone), Edwin Armstrong and Lee de Forest (inventors of radio), as well as Vladimir K. Zworykin, John Logie Baird and Philo Farnsworth (some of the inventors of television).\n\nThe word \"telecommunication\" is a compound of the Greek prefix \"tele\" (τηλε), meaning \"distant\", \"far off\", or \"afar\", and the Latin \"communicare\", meaning \"to share\". Its modern use is adapted from the French, because its written use was recorded in 1904 by the French engineer and novelist Édouard Estaunié. \"Communication\" was first used as an English word in the late 14th century. It comes from Old French comunicacion (14c., Modern French communication), from Latin communicationem (nominative communicatio), noun of action from past participle stem of communicare \"to share, divide out; communicate, impart, inform; join, unite, participate in\", literally \"to make common\", from communis\".\n\nHoming pigeons have occasionally been used throughout history by different cultures. Pigeon post had Persian roots, and was later used by the Romans to aid their military. Frontinus said that Julius Caesar used pigeons as messengers in his conquest of Gaul.\nThe Greeks also conveyed the names of the victors at the Olympic Games to various cities using homing pigeons. In the early 19th century, the Dutch government used the system in Java and Sumatra. And in 1849, Paul Julius Reuter started a pigeon service to fly stock prices between Aachen and Brussels, a service that operated for a year until the gap in the telegraph link was closed.\n\nIn the Middle Ages, chains of beacons were commonly used on hilltops as a means of relaying a signal. Beacon chains suffered the drawback that they could only pass a single bit of information, so the meaning of the message such as \"the enemy has been sighted\" had to be agreed upon in advance. One notable instance of their use was during the Spanish Armada, when a beacon chain relayed a signal from Plymouth to London.\n\nIn 1792, Claude Chappe, a French engineer, built the first fixed visual telegraphy system (or semaphore line) between Lille and Paris. However semaphore suffered from the need for skilled operators and expensive towers at intervals of ten to thirty kilometres (six to nineteen miles). As a result of competition from the electrical telegraph, the last commercial line was abandoned in 1880.\n\nOn 25 July 1837 the first commercial electrical telegraph was demonstrated by English inventor Sir William Fothergill Cooke, and English scientist Sir Charles Wheatstone. Both inventors viewed their device as \"an improvement to the [existing] electromagnetic telegraph\" not as a new device.\n\nSamuel Morse independently developed a version of the electrical telegraph that he unsuccessfully demonstrated on 2 September 1837. His code was an important advance over Wheatstone's signaling method. The first transatlantic telegraph cable was successfully completed on 27 July 1866, allowing transatlantic telecommunication for the first time.\n\nThe conventional telephone was patented by Alexander Bell in 1876. Elisha Gray also filed a caveat for it in 1876. Gray abandoned his caveat and because he did not contest Bell's priority, the examiner approved Bell's patent on March 3, 1876. Gray had filed his caveat for the variable resistance telephone, but Bell was the first to write down the idea and the first to test it in a telephone.[88] Antonio Meucci invented a device that allowed the electrical transmission of voice over a line nearly thirty years before in 1849, but his device was of little practical value because it relied on the electrophonic effect requiring users to place the receiver in their mouths to \"hear\". The first commercial telephone services were set-up by the Bell Telephone Company in 1878 and 1879 on both sides of the Atlantic in the cities of New Haven and London.\n\nStarting in 1894, Italian inventor Guglielmo Marconi began developing a wireless communication using the then newly discovered phenomenon of radio waves, showing by 1901 that they could be transmitted across the Atlantic Ocean. This was the start of wireless telegraphy by radio. Voice and music were demonstrated in 1900 and 1906, but had little early success.\n\nMillimetre wave communication was first investigated by Bengali physicist Jagadish Chandra Bose during 18941896, when he reached an extremely high frequency of up to 60GHz in his experiments. He also introduced the use of semiconductor junctions to detect radio waves, when he patented the radio crystal detector in 1901.\n\nWorld War I accelerated the development of radio for military communications. After the war, commercial radio AM broadcasting began in the 1920s and became an important mass medium for entertainment and news. World War II again accelerated development of radio for the wartime purposes of aircraft and land communication, radio navigation and radar. Development of stereo FM broadcasting of radio took place from the 1930s on-wards in the United States and displaced AM as the dominant commercial standard by the 1960s, and by the 1970s in the United Kingdom.\n\nOn 25 March 1925, John Logie Baird was able to demonstrate the transmission of moving pictures at the London department store Selfridges. Baird's device relied upon the Nipkow disk and thus became known as the mechanical television. It formed the basis of experimental broadcasts done by the British Broadcasting Corporation beginning 30 September 1929. However, for most of the twentieth century televisions depended upon the cathode ray tube invented by Karl Braun. The first version of such a television to show promise was produced by Philo Farnsworth and demonstrated to his family on 7 September 1927. After World War II, the experiments in television that had been interrupted were resumed, and it also became an important home entertainment broadcast medium.\n\nThe type of device known as a \"thermionic tube\" or \"thermionic valve\" uses the phenomenon of thermionic emission of electrons from a heated cathode and is used for a number of fundamental electronic functions such as signal amplification and current rectification.\nNon-thermionic types, such as a vacuum phototube however, achieve electron emission through the photoelectric effect, and are used for such as the detection of light levels. In both types, the electrons are accelerated from the cathode to the anode by the electric field in the tube.\n\nThe simplest vacuum tube, the diode invented in 1904 by John Ambrose Fleming, contains only a heated electron-emitting cathode and an anode. Electrons can only flow in one direction through the device—from the cathode to the anode. Adding one or more control grids within the tube allows the current between the cathode and anode to be controlled by the voltage on the grid or grids. These devices became a key component of electronic circuits for the first half of the twentieth century. They were crucial to the development of radio, television, radar, sound recording and reproduction, long-distance telephone networks, and analogue and early digital computers. Although some applications had used earlier technologies such as the spark gap transmitter for radio or mechanical computers for computing, it was the invention of the thermionic vacuum tube that made these technologies widespread and practical, and created the discipline of electronics.\n\nIn the 1940s the invention of semiconductor devices made it possible to produce solid-state devices, which are smaller, more efficient, reliable and durable, and cheaper than thermionic tubes. From the mid-1960s, thermionic tubes were then being replaced with the transistor. Thermionic tubes still have some applications for certain high-frequency amplifiers.\n\nThe modern period of telecommunication history from 1950 onwards is referred to as the semiconductor era, due to the wide adoption of semiconductor devices in telecommunication technology. The development of transistor technology and the semiconductor industry enabled significant advances in telecommunication technology, and led to a transition away from state-owned narrowband circuit-switched networks to private broadband packet-switched networks. Metal–oxide–semiconductor (MOS) technologies such as large-scale integration (LSI) and RF CMOS (radio-frequency complementary MOS), along with information theory (such as data compression), led to a transition from analog to digital signal processing, with the introduction of digital telecommunications (such as digital telephony and digital media) and wireless communications (such as cellular networks and mobile telephony), leading to rapid growth of the telecommunications industry towards the end of the 20th century.\n\nThe development of transistor technology has been fundamental to modern electronic telecommunication. The first transistor, a point-contact transistor, was invented by John Bardeen and Walter Houser Brattain at Bell Labs in 1947. The MOSFET (metal-oxide-silicon field-effect transistor), also known as the MOS transistor, was later invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959. The MOSFET is the building block or \"workhorse\" of the information revolution and the information age, and the most widely manufactured device in history. MOS technology, including MOS integrated circuits and power MOSFETs, drives the communications infrastructure of modern telecommunication. Along with computers, other essential elements of modern telecommunication that are built from MOSFETs include mobile devices, transceivers, base station modules, routers, RF power amplifiers, microprocessors, memory chips, and telecommunication circuits. \n\nAccording Edholm's law, the bandwidth of telecommunication networks has been doubling every 18 months. Advances in MOS technology, including MOSFET scaling (increasing transistor counts at an exponential pace, as predicted by Moore's law), has been the most important contributing factor in the rapid rise of bandwidth in telecommunications networks.\n\nOn 11 September 1940, George Stibitz transmitted problems for his Complex Number Calculator in New York using a teletype, and received the computed results back at Dartmouth College in New Hampshire. This configuration of a centralized computer (mainframe) with remote dumb terminals remained popular well into the 1970s. However, already in the 1960s, researchers started to investigate packet switching, a technology that sends a message in portions to its destination asynchronously without passing it through a centralized mainframe. A four-node network emerged on 5 December 1969, constituting the beginnings of the ARPANET, which by 1981 had grown to 213 nodes. ARPANET eventually merged with other networks to form the Internet. While Internet development was a focus of the Internet Engineering Task Force (IETF) who published a series of Request for Comment documents, other networking advancements occurred in industrial laboratories, such as the local area network (LAN) developments of Ethernet (1983) and the token ring protocol (1984).\n\nThe wireless revolution began in the 1990s, with the advent of digital wireless networks leading to a social revolution, and a paradigm shift from wired to wireless technology, including the proliferation of commercial wireless technologies such as cell phones, mobile telephony, pagers, wireless computer networks, cellular networks, the wireless Internet, and laptop and handheld computers with wireless connections. The wireless revolution has been driven by advances in radio frequency (RF) and microwave engineering, and the transition from analog to digital RF technology. Advances in metal-oxide-semiconductor field-effect transistor (MOSFET, or MOS transistor) technology, the key component of the RF technology that enables digital wireless networks, has been central to this revolution, including MOS devices such as the power MOSFET, LDMOS, and RF CMOS.\n\nPractical digital media distribution and streaming was made possible by advances in data compression, due to the impractically high memory, storage and bandwidth requirements of uncompressed media. The most important compression technique is the discrete cosine transform (DCT), a lossy compression algorithm that was first proposed as an image compression technique in 1972. Realization and demonstration, on 29 October 2001, of the first digital cinema transmission by satellite in Europe of a feature film by Bernard Pauchon, Alain Lorentz, Raymond Melwig and Philippe Binant.\n\nModern telecommunication is founded on a series of key concepts that experienced progressive development and refinement in a period of well over a century.\n\nTelecommunication technologies may primarily be divided into wired and wireless methods. Overall though, a basic telecommunication system consists of three main parts that are always present in some form or another:\n- A transmitter that takes information and converts it to a signal.\n- A transmission medium, also called the \"physical channel\" that carries the signal. An example of this is the \"free space channel\".\n- A receiver that takes the signal from the channel and converts it back into usable information for the recipient.\n\nFor example, in a radio broadcasting station the station's large power amplifier is the transmitter; and the broadcasting antenna is the interface between the power amplifier and the \"free space channel\". The free space channel is the transmission medium; and the receiver's antenna is the interface between the free space channel and the receiver. Next, the radio receiver is the destination of the radio signal, and this is where it is converted from electricity to sound for people to listen to.\n\nSometimes, telecommunication systems are \"duplex\" (two-way systems) with a single box of electronics working as both the transmitter and a receiver, or a \"transceiver\". For example, a cellular telephone is a transceiver. The transmission electronics and the receiver electronics within a transceiver are actually quite independent of each other. This can be readily explained by the fact that radio transmitters contain power amplifiers that operate with electrical powers measured in watts or kilowatts, but radio receivers deal with radio powers that are measured in the microwatts or nanowatts. Hence, transceivers have to be carefully designed and built to isolate their high-power circuitry and their low-power circuitry from each other, as to not cause interference.\n\nTelecommunication over fixed lines is called point-to-point communication because it is between one transmitter and one receiver. Telecommunication through radio broadcasts is called broadcast communication because it is between one powerful transmitter and numerous low-power but sensitive radio receivers.\n\nTelecommunications in which multiple transmitters and multiple receivers have been designed to cooperate and to share the same physical channel are called multiplex systems. The sharing of physical channels using multiplexing often gives very large reductions in costs. Multiplexed systems are laid out in telecommunication networks, and the multiplexed signals are switched at nodes through to the correct destination terminal receiver.\n\nCommunications signals can be sent either by analog signals or digital signals. There are analog communication systems and digital communication systems. For an analog signal, the signal is varied continuously with respect to the information. In a digital signal, the information is encoded as a set of discrete values (for example, a set of ones and zeros). During the propagation and reception, the information contained in analog signals will inevitably be degraded by undesirable physical noise. (The output of a transmitter is noise-free for all practical purposes.) Commonly, the noise in a communication system can be expressed as adding or subtracting from the desirable signal in a completely random way. This form of noise is called additive noise, with the understanding that the noise can be negative or positive at different instants of time. Noise that is not additive noise is a much more difficult situation to describe or analyze, and these other kinds of noise will be omitted here.\n\nOn the other hand, unless the additive noise disturbance exceeds a certain threshold, the information contained in digital signals will remain intact. Their resistance to noise represents a key advantage of digital signals over analog signals.\n\nA telecommunications network is a collection of transmitters, receivers, and communications channels that send messages to one another. Some digital communications networks contain one or more routers that work together to transmit information to the correct user. An analog communications network consists of one or more switches that establish a connection between two or more users. For both types of network, repeaters may be necessary to amplify or recreate the signal when it is being transmitted over long distances. This is to combat attenuation that can render the signal indistinguishable from the noise.\nAnother advantage of digital systems over analog is that their output is easier to store in memory, i.e. two voltage states (high and low) are easier to store than a continuous range of states.\n\nThe term \"channel\" has two different meanings. In one meaning, a channel is the physical medium that carries a signal between the transmitter and the receiver. Examples of this include the atmosphere for sound communications, glass optical fibers for some kinds of optical communications, coaxial cables for communications by way of the voltages and electric currents in them, and free space for communications using visible light, infrared waves, ultraviolet light, and radio waves. Coaxial cable types are classified by RG type or \"radio guide\", terminology derived from World War II. The various RG designations are used to classify the specific signal transmission applications. This last channel is called the \"free space channel\". The sending of radio waves from one place to another has nothing to do with the presence or absence of an atmosphere between the two. Radio waves travel through a perfect vacuum just as easily as they travel through air, fog, clouds, or any other kind of gas.\n\nThe other meaning of the term \"channel\" in telecommunications is seen in the phrase communications channel, which is a subdivision of a transmission medium so that it can be used to send multiple streams of information simultaneously. For example, one radio station can broadcast radio waves into free space at frequencies in the neighborhood of 94.5 MHz (megahertz) while another radio station can simultaneously broadcast radio waves at frequencies in the neighborhood of 96.1 MHz. Each radio station would transmit radio waves over a frequency bandwidth of about 180 kHz (kilohertz), centered at frequencies such as the above, which are called the \"carrier frequencies\". Each station in this example is separated from its adjacent stations by 200 kHz, and the difference between 200 kHz and 180 kHz (20 kHz) is an engineering allowance for the imperfections in the communication system.\n\nIn the example above, the \"free space channel\" has been divided into communications channels according to frequencies, and each channel is assigned a separate frequency bandwidth in which to broadcast radio waves. This system of dividing the medium into channels according to frequency is called \"frequency-division multiplexing\". Another term for the same concept is \"wavelength-division multiplexing\", which is more commonly used in optical communications when multiple transmitters share the same physical medium.\n\nAnother way of dividing a communications medium into channels is to allocate each sender a recurring segment of time (a \"time slot\", for example, 20 milliseconds out of each second), and to allow each sender to send messages only within its own time slot. This method of dividing the medium into communication channels is called \"time-division multiplexing\" (TDM), and is used in optical fiber communication. Some radio communication systems use TDM within an allocated FDM channel. Hence, these systems use a hybrid of TDM and FDM.\n\nThe shaping of a signal to convey information is known as modulation. Modulation can be used to represent a digital message as an analog waveform. This is commonly called \"keying\"—a term derived from the older use of Morse Code in telecommunications—and several keying techniques exist (these include phase-shift keying, frequency-shift keying, and amplitude-shift keying). The \"Bluetooth\" system, for example, uses phase-shift keying to exchange information between various devices. In addition, there are combinations of phase-shift keying and amplitude-shift keying which is called (in the jargon of the field) \"quadrature amplitude modulation\" (QAM) that are used in high-capacity digital radio communication systems.\n\nModulation can also be used to transmit the information of low-frequency analog signals at higher frequencies. This is helpful because low-frequency analog signals cannot be effectively transmitted over free space. Hence the information from a low-frequency analog signal must be impressed into a higher-frequency signal (known as the \"carrier wave\") before transmission. There are several different modulation schemes available to achieve this [two of the most basic being amplitude modulation (AM) and frequency modulation (FM)]. An example of this process is a disc jockey's voice being impressed into a 96 MHz carrier wave using frequency modulation (the voice would then be received on a radio as the channel \"96 FM\"). In addition, modulation has the advantage that it may use frequency division multiplexing (FDM).\n\nTelecommunication has a significant social, cultural and economic impact on modern society. In 2008, estimates placed the telecommunication industry's revenue at $4.7 trillion or just under 3 percent of the gross world product (official exchange rate). Several following sections discuss the impact of telecommunication on society.\n\nOn the microeconomic scale, companies have used telecommunications to help build global business empires. This is self-evident in the case of online retailer Amazon.com but, according to academic Edward Lenert, even the conventional retailer Walmart has benefited from better telecommunication infrastructure compared to its competitors. In cities throughout the world, home owners use their telephones to order and arrange a variety of home services ranging from pizza deliveries to electricians. Even relatively poor communities have been noted to use telecommunication to their advantage. In Bangladesh's Narshingdi district, isolated villagers use cellular phones to speak directly to wholesalers and arrange a better price for their goods. In Côte d'Ivoire, coffee growers share mobile phones to follow hourly variations in coffee prices and sell at the best price.\n\nOn the macroeconomic scale, Lars-Hendrik Röller and Leonard Waverman suggested a causal link between good telecommunication infrastructure and economic growth. Few dispute the existence of a correlation although some argue it is wrong to view the relationship as causal.\n\nBecause of the economic benefits of good telecommunication infrastructure, there is increasing worry about the inequitable access to telecommunication services amongst various countries of the world—this is known as the digital divide. A 2003 survey by the International Telecommunication Union (ITU) revealed that roughly a third of countries have fewer than one mobile subscription for every 20 people and one-third of countries have fewer than one land-line telephone subscription for every 20 people. In terms of Internet access, roughly half of all countries have fewer than one out of 20 people with Internet access. From this information, as well as educational data, the ITU was able to compile an index that measures the overall ability of citizens to access and use information and communication technologies. Using this measure, Sweden, Denmark and Iceland received the highest ranking while the African countries Nigeria, Burkina Faso and Mali received the lowest.\n\nTelecommunication has played a significant role in social relationships. Nevertheless, devices like the telephone system were originally advertised with an emphasis on the practical dimensions of the device (such as the ability to conduct business or order home services) as opposed to the social dimensions. It was not until the late 1920s and 1930s that the social dimensions of the device became a prominent theme in telephone advertisements. New promotions started appealing to consumers' emotions, stressing the importance of social conversations and staying connected to family and friends.\n\nSince then the role that telecommunications has played in social relations has become increasingly important. In recent years, the popularity of social networking sites has increased dramatically. These sites allow users to communicate with each other as well as post photographs, events and profiles for others to see. The profiles can list a person's age, interests, sexual preference and relationship status. In this way, these sites can play important role in everything from organising social engagements to courtship.\n\nPrior to social networking sites, technologies like short message service (SMS) and the telephone also had a significant impact on social interactions. In 2000, market research group Ipsos MORI reported that 81% of 15- to 24-year-old SMS users in the United Kingdom had used the service to coordinate social arrangements and 42% to flirt.\n\nIn cultural terms, telecommunication has increased the public's ability to access music and film. With television, people can watch films they have not seen before in their own home without having to travel to the video store or cinema. With radio and the Internet, people can listen to music they have not heard before without having to travel to the music store.\n\nTelecommunication has also transformed the way people receive their news. A 2006 survey (right table) of slightly more than 3,000 Americans by the non-profit Pew Internet and American Life Project in the United States the majority specified television or radio over newspapers.\n\nTelecommunication has had an equally significant impact on advertising. TNS Media Intelligence reported that in 2007, 58% of advertising expenditure in the United States was spent on media that depend upon telecommunication.\n\nMany countries have enacted legislation which conforms to the \"International Telecommunication Regulations\" established by the International Telecommunication Union (ITU), which is the \"leading UN agency for information and communication technology issues\". In 1947, at the Atlantic City Conference, the ITU decided to \"afford international protection to all frequencies registered in a new international frequency list and used in conformity with the Radio Regulation\". According to the ITU's \"Radio Regulations\" adopted in Atlantic City, all frequencies referenced in the \"International Frequency Registration Board\", examined by the board and registered on the \"International Frequency List\" \"shall have the right to international protection from harmful interference\".\n\nFrom a global perspective, there have been political debates and legislation regarding the management of telecommunication and broadcasting. The history of broadcasting discusses some debates in relation to balancing conventional communication such as printing and telecommunication such as radio broadcasting. The onset of World War II brought on the first explosion of international broadcasting propaganda. Countries, their governments, insurgents, terrorists, and militiamen have all used telecommunication and broadcasting techniques to promote propaganda. Patriotic propaganda for political movements and colonization started the mid-1930s. In 1936, the BBC broadcast propaganda to the Arab World to partly counter similar broadcasts from Italy, which also had colonial interests in North Africa.\n\nModern insurgents, such as those in the latest Iraq War, often use intimidating telephone calls, SMSs and the distribution of sophisticated videos of an attack on coalition troops within hours of the operation. \"The Sunni insurgents even have their own television station, Al-Zawraa, which while banned by the Iraqi government, still broadcasts from Erbil, Iraqi Kurdistan, even as coalition pressure has forced it to switch satellite hosts several times.\"\n\nOn 10 November 2014, President Obama recommended the Federal Communications Commission reclassify broadband Internet service as a telecommunications service to preserve net neutrality.\n\nAccording to data collected by Gartner and Ars Technica sales of main consumer's telecommunication equipment worldwide in millions of units was:\nIn a telephone network, the caller is connected to the person to whom they wish to talk by switches at various telephone exchanges. The switches form an electrical connection between the two users and the setting of these switches is determined electronically when the caller dials the number. Once the connection is made, the caller's voice is transformed to an electrical signal using a small microphone in the caller's handset. This electrical signal is then sent through the network to the user at the other end where it is transformed back into sound by a small speaker in that person's handset.\n\nAs of 2015, the landline telephones in most residential homes are analog—that is, the speaker's voice directly determines the signal's voltage. Although short-distance calls may be handled from end-to-end as analog signals, increasingly telephone service providers are transparently converting the signals to digital signals for transmission. The advantage of this is that digitized voice data can travel side-by-side with data from the Internet and can be perfectly reproduced in long distance communication (as opposed to analog signals that are inevitably impacted by noise).\n\nMobile phones have had a significant impact on telephone networks. Mobile phone subscriptions now outnumber fixed-line subscriptions in many markets. Sales of mobile phones in 2005 totalled 816.6 million with that figure being almost equally shared amongst the markets of Asia/Pacific (204 m), Western Europe (164 m), CEMEA (Central Europe, the Middle East and Africa) (153.5 m), North America (148 m) and Latin America (102 m). In terms of new subscriptions over the five years from 1999, Africa has outpaced other markets with 58.2% growth. Increasingly these phones are being serviced by systems where the voice content is transmitted digitally such as GSM or W-CDMA with many markets choosing to deprecate analog systems such as AMPS.\n\nThere have also been dramatic changes in telephone communication behind the scenes. Starting with the operation of TAT-8 in 1988, the 1990s saw the widespread adoption of systems based on optical fibers. The benefit of communicating with optical fibers is that they offer a drastic increase in data capacity. TAT-8 itself was able to carry 10 times as many telephone calls as the last copper cable laid at that time and today's optical fibre cables are able to carry 25 times as many telephone calls as TAT-8. This increase in data capacity is due to several factors: First, optical fibres are physically much smaller than competing technologies. Second, they do not suffer from crosstalk which means several hundred of them can be easily bundled together in a single cable. Lastly, improvements in multiplexing have led to an exponential growth in the data capacity of a single fibre.\n\nAssisting communication across many modern optical fibre networks is a protocol known as Asynchronous Transfer Mode (ATM). The ATM protocol allows for the side-by-side data transmission mentioned in the second paragraph. It is suitable for public telephone networks because it establishes a pathway for data through the network and associates a traffic contract with that pathway. The traffic contract is essentially an agreement between the client and the network about how the network is to handle the data; if the network cannot meet the conditions of the traffic contract it does not accept the connection. This is important because telephone calls can negotiate a contract so as to guarantee themselves a constant bit rate, something that will ensure a caller's voice is not delayed in parts or cut off completely. There are competitors to ATM, such as Multiprotocol Label Switching (MPLS), that perform a similar task and are expected to supplant ATM in the future.\n\nIn a broadcast system, the central high-powered broadcast tower transmits a high-frequency electromagnetic wave to numerous low-powered receivers. The high-frequency wave sent by the tower is modulated with a signal containing visual or audio information. The receiver is then tuned so as to pick up the high-frequency wave and a demodulator is used to retrieve the signal containing the visual or audio information. The broadcast signal can be either analog (signal is varied continuously with respect to the information) or digital (information is encoded as a set of discrete values).\n\nThe broadcast media industry is at a critical turning point in its development, with many countries moving from analog to digital broadcasts. This move is made possible by the production of cheaper, faster and more capable integrated circuits. The chief advantage of digital broadcasts is that they prevent a number of complaints common to traditional analog broadcasts. For television, this includes the elimination of problems such as snowy pictures, ghosting and other distortion. These occur because of the nature of analog transmission, which means that perturbations due to noise will be evident in the final output. Digital transmission overcomes this problem because digital signals are reduced to discrete values upon reception and hence small perturbations do not affect the final output. In a simplified example, if a binary message 1011 was transmitted with signal amplitudes [1.0 0.0 1.0 1.0] and received with signal amplitudes [0.9 0.2 1.1 0.9] it would still decode to the binary message 1011— a perfect reproduction of what was sent. From this example, a problem with digital transmissions can also be seen in that if the noise is great enough it can significantly alter the decoded message. Using forward error correction a receiver can correct a handful of bit errors in the resulting message but too much noise will lead to incomprehensible output and hence a breakdown of the transmission.\n\nIn digital television broadcasting, there are three competing standards that are likely to be adopted worldwide. These are the ATSC, DVB and ISDB standards; the adoption of these standards thus far is presented in the captioned map. All three standards use MPEG-2 for video compression. ATSC uses Dolby Digital AC-3 for audio compression, ISDB uses Advanced Audio Coding (MPEG-2 Part 7) and DVB has no standard for audio compression but typically uses MPEG-1 Part 3 Layer 2. The choice of modulation also varies between the schemes. In digital audio broadcasting, standards are much more unified with practically all countries choosing to adopt the Digital Audio Broadcasting standard (also known as the Eureka 147 standard). The exception is the United States which has chosen to adopt HD Radio. HD Radio, unlike Eureka 147, is based upon a transmission method known as in-band on-channel transmission that allows digital information to \"piggyback\" on normal AM or FM analog transmissions. \n\nHowever, despite the pending switch to digital, analog television remains being transmitted in most countries. An exception is the United States that ended analog television transmission (by all but the very low-power TV stations) on 12 June 2009 after twice delaying the switchover deadline. Kenya also ended analog television transmission in December 2014 after multiple delays. For analog television, there were three standards in use for broadcasting color TV (see a map on adoption ). These are known as PAL (German designed), NTSC (American designed), and SECAM (French designed). For analog radio, the switch to digital radio is made more difficult by the higher cost of digital receivers. The choice of modulation for analog radio is typically between amplitude (AM) or frequency modulation (FM). To achieve stereo playback, an amplitude modulated subcarrier is used for stereo FM, and quadrature amplitude modulation is used for stereo AM or C-QUAM.\n\nThe Internet is a worldwide network of computers and computer networks that communicate with each other using the Internet Protocol (IP). Any computer on the Internet has a unique IP address that can be used by other computers to route information to it. Hence, any computer on the Internet can send a message to any other computer using its IP address. These messages carry with them the originating computer's IP address allowing for two-way communication. The Internet is thus an exchange of messages between computers.\n\nIt is estimated that 51% of the information flowing through two-way telecommunications networks in the year 2000 were flowing through the Internet (most of the rest (42%) through the landline telephone). By the year 2007 the Internet clearly dominated and captured 97% of all the information in telecommunication networks (most of the rest (2%) through mobile phones). , an estimated 21.9% of the world population has access to the Internet with the highest access rates (measured as a percentage of the population) in North America (73.6%), Oceania/Australia (59.5%) and Europe (48.1%). In terms of broadband access, Iceland (26.7%), South Korea (25.4%) and the Netherlands (25.3%) led the world.\n\nThe Internet works in part because of protocols that govern how the computers and routers communicate with each other. The nature of computer network communication lends itself to a layered approach where individual protocols in the protocol stack run more-or-less independently of other protocols. This allows lower-level protocols to be customized for the network situation while not changing the way higher-level protocols operate. A practical example of why this is important is because it allows an Internet browser to run the same code regardless of whether the computer it is running on is connected to the Internet through an Ethernet or Wi-Fi connection. Protocols are often talked about in terms of their place in the OSI reference model (pictured on the right), which emerged in 1983 as the first step in an unsuccessful attempt to build a universally adopted networking protocol suite.\n\nFor the Internet, the physical medium and data link protocol can vary several times as packets traverse the globe. This is because the Internet places no constraints on what physical medium or data link protocol is used. This leads to the adoption of media and protocols that best suit the local network situation. In practice, most intercontinental communication will use the Asynchronous Transfer Mode (ATM) protocol (or a modern equivalent) on top of optic fiber. This is because for most intercontinental communication the Internet shares the same infrastructure as the public switched telephone network.\n\nAt the network layer, things become standardized with the Internet Protocol (IP) being adopted for logical addressing. For the World Wide Web, these \"IP addresses\" are derived from the human readable form using the Domain Name System (e.g. 72.14.207.99 is derived from www.google.com). At the moment, the most widely used version of the Internet Protocol is version four but a move to version six is imminent. \n\nAt the transport layer, most communication adopts either the Transmission Control Protocol (TCP) or the User Datagram Protocol (UDP). TCP is used when it is essential every message sent is received by the other computer whereas UDP is used when it is merely desirable. With TCP, packets are retransmitted if they are lost and placed in order before they are presented to higher layers. With UDP, packets are not ordered nor retransmitted if lost. Both TCP and UDP packets carry port numbers with them to specify what application or process the packet should be handled by. Because certain application-level protocols use certain ports, network administrators can manipulate traffic to suit particular requirements. Examples are to restrict Internet access by blocking the traffic destined for a particular port or to affect the performance of certain applications by assigning priority.\n\nAbove the transport layer, there are certain protocols that are sometimes used and loosely fit in the session and presentation layers, most notably the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols. These protocols ensure that data transferred between two parties remains completely confidential. Finally, at the application layer, are many of the protocols Internet users would be familiar with such as HTTP (web browsing), POP3 (e-mail), FTP (file transfer), IRC (Internet chat), BitTorrent (file sharing) and XMPP (instant messaging).\n\nVoice over Internet Protocol (VoIP) allows data packets to be used for synchronous voice communications. The data packets are marked as voice type packets and can be prioritized by the network administrators so that the real-time, synchronous conversation is less subject to contention with other types of data traffic which can be delayed (i.e. file transfer or email) or buffered in advance (i.e. audio and video) without detriment. That prioritization is fine when the network has sufficient capacity for all the VoIP calls taking place at the same time and the network is enabled for prioritization i.e. a private corporate style network, but the Internet is not generally managed in this way and so there can be a big difference in the quality of VoIP calls over a private network and over the public Internet.\n\nDespite the growth of the Internet, the characteristics of local area networks (LANs)—computer networks that do not extend beyond a few kilometers—remain distinct. This is because networks on this scale do not require all the features associated with larger networks and are often more cost-effective and efficient without them. When they are not connected with the Internet, they also have the advantages of privacy and security. However, purposefully lacking a direct connection to the Internet does not provide assured protection from hackers, military forces, or economic powers. These threats exist if there are any methods for connecting remotely to the LAN.\n\nWide area networks (WANs) are private computer networks that may extend for thousands of kilometers. Once again, some of their advantages include privacy and security. Prime users of private LANs and WANs include armed forces and intelligence agencies that must keep their information secure and secret.\n\nIn the mid-1980s, several sets of communication protocols emerged to fill the gaps between the data-link layer and the application layer of the OSI reference model. These included Appletalk, IPX, and NetBIOS with the dominant protocol set during the early 1990s being IPX due to its popularity with MS-DOS users. TCP/IP existed at this point, but it was typically only used by large government and research facilities.\n\nAs the Internet grew in popularity and its traffic was required to be routed into private networks, the TCP/IP protocols replaced existing local area network technologies. Additional technologies, such as DHCP, allowed TCP/IP-based computers to self-configure in the network. Such functions also existed in the AppleTalk/ IPX/ NetBIOS protocol sets.\n\nWhereas Asynchronous Transfer Mode (ATM) or Multiprotocol Label Switching (MPLS) are typical data-link protocols for larger networks such as WANs; Ethernet and Token Ring are typical data-link protocols for LANs. These protocols differ from the former protocols in that they are simpler, e.g., they omit features such as quality of service guarantees, and offer collision prevention. Both of these differences allow for more economical systems.\n\nDespite the modest popularity of IBM Token Ring in the 1980s and 1990s, virtually all LANs now use either wired or wireless Ethernet facilities. At the physical layer, most wired Ethernet implementations use copper twisted-pair cables (including the common 10BASE-T networks). However, some early implementations used heavier coaxial cables and some recent implementations (especially high-speed ones) use optical fibers. When optic fibers are used, the distinction must be made between multimode fibers and single-mode fibers. Multimode fibers can be thought of as thicker optical fibers that are cheaper to manufacture devices for, but that suffers from less usable bandwidth and worse attenuation—implying poorer long-distance performance.\n\nThe effective capacity to exchange information worldwide through two-way telecommunication networks grew from 281 petabytes of (optimally compressed) information in 1986, to 471 petabytes in 1993, to 2.2 (optimally compressed) exabytes in 2000, and to 65 (optimally compressed) exabytes in 2007. This is the informational equivalent of two newspaper pages per person per day in 1986, and six entire newspapers per person per day by 2007. Given this growth, telecommunications play an increasingly important role in the world economy and the global telecommunications industry was about a $4.7 trillion sector in 2012. The service revenue of the global telecommunications industry was estimated to be $1.5 trillion in 2010, corresponding to 2.4% of the world's gross domestic product (GDP).\n\n- Goggin, Gerard, \"Global Mobile Media\" (New York: Routledge, 2011), p. 176. .\n- OECD, \"Universal Service and Rate Restructuring in Telecommunications\", Organisation for Economic Co-operation and Development (OECD) Publishing, 1991. .\n- Wheen, Andrew. \"Dot-Dash to Dot.Com: How Modern Telecommunications Evolved from the Telegraph to the Internet\" (Springer, 2011).\n\n- International Teletraffic Congress\n- International Telecommunication Union (ITU)\n- ATIS Telecom Glossary\n- Federal Communications Commission\n- IEEE Communications Society\n- International Telecommunication Union\n- (Ericsson removed the book from their site in September 2005)\n", "related": "NONE"}
{"id": "30889569", "url": "https://en.wikipedia.org/wiki?curid=30889569", "title": "Digital signal", "text": "Digital signal\n\nA digital signal is a signal that is being used to represent data as a sequence of discrete values; at any given time it can only take on one of a finite number of values. This contrasts with an analog signal, which represents continuous values; at any given time it represents a real number within a continuous range of values. \n\nSimple digital signals represent information in discrete bands of analog levels. All levels within a band of values represent the same information state. In most digital circuits, the signal can have two possible values; this is called a binary signal or logic signal. They are represented by two voltage bands: one near a reference value (typically termed as \"ground\" or zero volts), and the other a value near the supply voltage. These correspond to the two values \"zero\" and \"one\" (or \"false\" and \"true\") of the Boolean domain, so at any given time a binary signal represents one binary digit (bit). Because of this discretization, relatively small changes to the analog signal levels do not leave the discrete envelope, and as a result are ignored by signal state sensing circuitry. As a result, digital signals have noise immunity; electronic noise, provided it is not too great, will not affect digital circuits, whereas noise always degrades the operation of analog signals to some degree.\n\nDigital signals having more than two states are occasionally used; circuitry using such signals is called multivalued logic. For example, signals that can assume three possible states are called three-valued logic. \n\nIn a digital signal, the physical quantity representing the information may be a variable electric current or voltage, the intensity, phase or polarization of an optical or other electromagnetic field, acoustic pressure, the magnetization of a magnetic storage media, etcetera. Digital signals are used in all digital electronics, notably computing equipment and data transmission.\n\nThe term \"digital signal\" has related definitions in different contexts.\n\nIn digital electronics, a digital signal is a pulse train (a pulse amplitude modulated signal), i.e. a sequence of fixed-width square wave electrical pulses or light pulses, each occupying one of a discrete number of levels of amplitude. A special case is a \"logic signal\" or a \"binary signal\", which varies between a low and a high signal level.\n\nThe pulse trains in digital circuits are typically generated by metal–oxide–semiconductor field-effect transistor (MOSFET) devices, due to their rapid on–off electronic switching speed and large-scale integration (LSI) capability. In contrast, BJT transistors more slowly generate analog signals resembling sine waves.\nIn digital signal processing, a digital signal is a representation of a physical signal that is a sampled and quantized. A digital signal is an abstraction which is discrete in time and amplitude. The signal's value only exists at regular time intervals, since only the values of the corresponding physical signal at those sampled moments are significant for further digital processing. The digital signal is a sequence of codes drawn from a finite set of values. The digital signal may be stored, processed or transmitted physically as a pulse-code modulation (PCM) signal.\nIn digital communications, a digital signal is a continuous-time physical signal, alternating between a discrete number of waveforms, representing a bitstream. The shape of the waveform depends the transmission scheme, which may be either a line coding scheme allowing baseband transmission; or a digital modulation scheme, allowing passband transmission over long wires or over a limited radio frequency band. Such a carrier-modulated sine wave is considered a digital signal in literature on digital communications and data transmission, but considered as a bitstream converted to an analog signal in electronics and computer networking.\n\nIn communications, sources of interference are usually present, and noise is frequently a significant problem. The effects of interference are typically minimized by filtering off interfering signals as much as possible and by using data redundancy. The main advantages of digital signals for communications are often considered to be the noise immunity to noise capability, and the ability, in many cases such as with audio and video data, to use data compression to greatly decrease the bandwidth that is required on the communication media.\nA waveform that switches representing the two states of a Boolean value (0 and 1, or low and high, or false and true) is referred to as a \"digital signal\" or \"logic signal\" or \"binary signal\" when it is interpreted in terms of only two possible digits.\n\nThe two states are usually represented by some measurement of an electrical property: Voltage is the most common, but current is used in some logic families. A threshold is designed for each logic family. When below that threshold, the signal is \"low\", when above \"high\".\n\nThe clock signal is a special digital signal that is used to synchronize many digital circuits. The image shown can be considered the waveform of a clock signal. Logic changes are triggered either by the rising edge or the falling edge. The rising edge is the transition from a low voltage (level 1 in the diagram) to a high voltage (level 2). The falling edge is the transition from a high voltage to a low one.\n\nAlthough in a highly simplified and idealized model of a digital circuit, we may wish for these transitions to occur instantaneously, no real world circuit is purely resistive and therefore no circuit can instantly change voltage levels. This means that during a short, finite transition time the output may not properly reflect the input, and will not correspond to either a logically high or low voltage.\n\nTo create a digital signal, an analog signal must be modulated with a control signal to produce it. The simplest modulation, a type of unipolar encoding, is simply to switch on and off a DC signal, so that high voltages represent a '1' and low voltages are '0'.\n\nIn digital radio schemes one or more carrier waves are amplitude, frequency or phase modulated by the control signal to produce a digital signal suitable for transmission.\n\nAsymmetric Digital Subscriber Line (ADSL) over telephone wires, does not primarily use binary logic; the digital signals for individual carriers are modulated with different valued logics, depending on the Shannon capacity of the individual channel.\n\nDigital signals may be \"sampled\" by a clock signal at regular intervals by passing the signal through a flip-flop. When this is done, the input is measured at the clock edge, and the signal from that time. The signal is then held steady until the next clock. This process is the basis of synchronous logic.\n\nAsynchronous logic also exists, which uses no single clock, and generally operates more quickly, and may use less power, but is significantly harder to design.\n", "related": "\n- Intersymbol interference\n"}
{"id": "7531293", "url": "https://en.wikipedia.org/wiki?curid=7531293", "title": "Outline of telecommunication", "text": "Outline of telecommunication\n\nThe following outline is provided as an overview of and topical guide to telecommunication:\n\nTelecommunication – the transmission of signals over a distance for the purpose of communication. In modern times, this process almost always involves the use of electromagnetic waves by transmitters and receivers, but in earlier years it also involved the use of drums and visual signals such as smoke, fire, beacons, semaphore lines and other optical communications.\n\n- E-mail\n- Fax\n- Instant messaging\n- Radio\n- Satellite\n- Telegraphy\n- Telephony\n- Television broadcasting\n- Videoconferencing\n- VoIP\n\nTelecommunications network\n- Computer networks\n- ARPANET\n- Ethernet\n- Internet\n- Wireless networks\n- Public switched telephone networks (PSTN)\n- Packet switched networks\n- Radio networks\n- Television networks\n\nTelecommunication\n- Analog\n- Digital\n- Functional profile\n- Optics\n\n- Modulation\n- Amplitude modulation\n- Frequency modulation\n- Quadrature amplitude modulation\n- Nyquist rate\n- Nyquist ISI criterion\n- Pulse shaping\n- Intersymbol interference\n\n- Physical media for Telecommunication\n- Twisted pair\n- Coaxial cable\n- Optical fiber\n- Telecommunication through Free Space\n- Broadcast radio frequency including television and radio\n- Line-of-sight\n-  Communications satellite\n-  Terrestrial Microwave\n-  Wireless LAN\n\n- Physical access to media\n- Simplex\n- Duplex (telecommunications)\n- Logical relationships\n- Return channel\n- Two-way alternating\n- Two-way simultaneous\n\n- Multiplexing\n- Analog\n-  Frequency division multiplexing\n-  Space division multiplexing\n- Digital\n-  Time-division multiplexing\n-  Statistical multiplexing and Packet switching\n- Media Access Control\n-  Contention\n-  Token-based\n-   Centralized token control\n-   Distributed token control\n\nHistory of telecommunication\n- History of telegraphy\n- History of the telephone\n- History of radio\n- History of television\n- History of videophones\n- History of mobile phones\n- History of computing hardware\n- History of the Internet\n\n- Alcatel-Lucent\n- Aricent\n- AT&T\n- Avaya\n- Ciena\n- Cisco Systems\n- Ericsson\n- Fujitsu\n- HCL Technologies\n- Huawei\n- NEC\n- Nokia\n- ShoreTel\n- Verizon\n- Wildix\n- ZTE\n\n- List of mobile network operators\n- List of telephone operating companies\n\n- Alliance for Telecommunications Industry Solutions\n- Telecommunications Industry Association\n\nMagazines\n- Billing and OSS World\n- Cabling Installation & Maintenance\n- Call Center\n- Communications News\n- Communications System Design\n- Lightwave\n- Mobile Radio Technology (MRT)\n- New Telephony\n- Phone+\n- RCR Wireless News\n- Telecom Asia\n- Telecommunications Magazine\n- Telephony\n- WhatSatphone Magazine\n- Wireless Systems Design\n- Wireless Week\n- Xchange\n\n- Edwin Howard Armstrong\n- John Logie Baird\n- Paul Baran\n- Alexander Graham Bell\n- Tim Berners-Lee\n- Jagadish Chandra Bose\n- Vint Cerf\n- Claude Chappe\n- Donald Davies\n- Louis Pouzin\n- Lee de Forest\n- Philo Farnsworth\n- Reginald Fessenden\n- Elisha Gray\n- Innocenzo Manzetti\n- Guglielmo Marconi\n- Antonio Meucci\n- Alexander Stepanovich Popov\n- Johann Philipp Reis\n- Almon Brown Strowger\n- Nikola Tesla\n- Camille Tissot\n- Alfred Vail\n- Charles Wheatstone\n- Vladimir K. Zworykin\n\n- International Telecommunication Union (ITU)\n- ATIS Telecom Glossary\n- Communications Engineering Tutorials\n- Federal Communications Commission\n- IEEE Communications Society\n- International Telecommunication Union\n- (Ericsson removed the book from their site in September 2005)\n- VoIP, Voice over Internet Protocol and Internet telephone calls\n- Free Telco Dictionary\n", "related": "NONE"}
{"id": "30010", "url": "https://en.wikipedia.org/wiki?curid=30010", "title": "Telegraphy", "text": "Telegraphy\n\nTelegraphy is the long-distance transmission of textual messages where the sender uses symbolic codes, known to the recipient, rather than a physical exchange of an object bearing the message. Thus flag semaphore is a method of telegraphy, whereas pigeon post is not. Ancient signalling systems, although sometimes quite extensive and sophisticated as in China, were generally not capable of transmitting arbitrary text messages. Possible messages were fixed and predetermined and such systems are thus not true telegraphs.\n\nThe earliest true telegraph put into widespread use was the optical telegraph of Claude Chappe, invented in the late 18th century. The system was extensively used in France, and European countries controlled by France, during the Napoleonic era. The electric telegraph started to replace the optical telegraph in the mid-19th century. It was first taken up in Britain in the form of the Cooke and Wheatstone telegraph, initially used mostly as an aid to railway signalling. This was quickly followed by a different system developed in the United States by Samuel Morse. The electric telegraph was slower to develop in France due to the established optical telegraph system, but an electrical telegraph was put into use with a code compatible with the Chappe optical telegraph. The Morse system was adopted as the international standard in 1865, using a modified Morse code developed in Germany.\n\nThe heliograph is a telegraph system using reflected sunlight for signalling. It was mainly used in areas where the electrical telegraph had not been established and generally uses the same code. The most extensive heliograph network established was in Arizona and New Mexico during the Apache Wars. The heliograph was standard military equipment as late as World War II. Wireless telegraphy developed in the early 20th century. Wireless telegraphy became important for maritime use, and was a competitor to electrical telegraphy using submarine telegraph cables in international communications.\n\nTelegrams became a popular means of sending messages once telegraph prices had fallen sufficiently. Traffic became high enough to spur the development of automated systems—teleprinters and punched tape transmission. These systems led to new telegraph codes, starting with the Baudot code. However, telegrams were never able to compete with the letter post on price, and competition from the telephone, which removed their speed advantage, drove the telegraph into decline from 1920 onwards. The few remaining telegraph applications were largely taken over by alternatives on the internet towards the end of the 20th century.\n\nThe word \"telegraph\" (from Ancient Greek: τῆλε, \"têle\", \"at a distance\" and γράφειν, \"gráphein\", \"to write\") was first coined by the French inventor of the Semaphore telegraph, Claude Chappe, who also coined the word \"semaphore\".\n\nA \"telegraph\" is a device for transmitting and receiving messages over long distances, i.e., for telegraphy. The word \"telegraph\" alone now generally refers to an electrical telegraph. Wireless telegraphy is transmission of messages over radio with telegraphic codes.\n\nContrary to the extensive definition used by Chappe, Morse argued that the term \"telegraph\" can strictly be applied only to systems that transmit \"and\" record messages at a distance. This is to be distinguished from \"semaphore\", which merely transmits messages. Smoke signals, for instance, are to be considered semaphore, not telegraph. According to Morse, telegraph dates only from 1832 when Pavel Schilling invented one of the earliest electrical telegraphs.\n\nA telegraph message sent by an electrical telegraph operator or telegrapher using Morse code (or a printing telegraph operator using plain text) was known as a \"telegram\". A \"cablegram\" was a message sent by a submarine telegraph cable, often shortened to a \"cable\" or a \"wire\". Later, a \"Telex\" was a message sent by a Telex network, a switched network of teleprinters similar to a telephone network.\n\nA \"wirephoto\" or \"wire picture\" was a newspaper picture that was sent from a remote location by a facsimile telegraph. A \"diplomatic telegram\", also known as a diplomatic cable, is the term given to a confidential communication between a diplomatic mission and the foreign ministry of its parent country. These continue to be called telegrams or cables regardless of the method used for transmission.\n\nPassing messages by signalling over distance is an ancient practice. One of the oldest examples is the signal towers of the Great Wall of China. In , signals could be sent by beacon fires or drum beats. By complex flag signalling had developed, and by the Han dynasty (200 BC–220 AD) signallers had a choice of lights, flags, or gunshots to send signals. By the Tang dynasty (618–907) a message could be sent 700 miles in 24 hours. The Ming dynasty (1368–1644) added artillery to the possible signals. While the signalling was complex (for instance, different-coloured flags could be used to indicate enemy strength), only predetermined messages could be sent. The Chinese signalling system extended well beyond the Great Wall. Signal towers away from the wall were used to give early warning of an attack. Others were built even further out as part of the protection of trade routes, especially the Silk Road.\n\nSignal fires were widely used in Europe and elsewhere for military purposes. The Roman army made frequent use of them, as did their enemies, and the remains of some of the stations still exist. Few details have been recorded of European/Mediterranean signalling systems and the possible messages. One of the few for which details are known is a system invented by Aeneas Tacticus (4th century BC). Tacticus's system had water filled pots at the two signal stations which were drained in synchronisation. Annotation on a floating scale indicated which message was being sent or received. Signals sent by means of torches indicated when to start and stop draining to keep the synchronisation.\n\nNone of the signalling systems discussed above are true telegraphs in the sense of a system that can transmit arbitrary messages over arbitrary distances. Lines of signalling relay stations can send messages to any required distance, but all these systems are limited to one extent or another in the range of messages that they can send. A system like flag semaphore, with an alphabetic code, can certainly send any given message, but the system is designed for short-range communication between two persons. An engine order telegraph, used to send instructions from the bridge of a ship to the engine room, fails to meet both criteria; it has a limited distance and very simple message set. There was only one ancient signalling system described that \"does\" meet these criteria. That was a system using the Polybius square to encode an alphabet. Polybius (2nd century BC) suggested using two successive groups of torches to identify the coordinates of the letter of the alphabet being transmitted. The number of said torches held up signalled the grid square that contained the letter. There is no definite record of the system ever being used, but there are several passages in ancient texts that some think are suggestive. Holzmann and Pehrson, for instance, suggest that Livy is describing its use by Philip V of Macedon in 207 BC during the First Macedonian War. Nothing else that could be described as a true telegraph existed until the 17th century. Possibly the first alphabetic telegraph code in the modern era is due to Franz Kessler who published his work in 1616. Kessler used a lamp placed inside a barrel with a moveable shutter operated by the signaller. The signals were observed at a distance with the newly-invented telescope.\n\nIn several places around the world, a system of passing messages from village to village using drum beats was developed. This was particularly highly developed in Africa. At the time of its discovery in Africa, the speed of message transmission was faster than any existing European system using optical telegraphs. The African drum system was not alphabetical. Rather, the drum beats followed the tones of the language. This made messages highly ambiguous and context was important for their correct interpretation.\n\nAn optical telegraph is a telegraph consisting of a line of stations in towers or natural high points which signal to each other by means of shutters or paddles. Signalling by means of indicator pointers was called \"semaphore\". Early proposals for an optical telegraph system were made to the Royal Society by Robert Hooke in 1684 and were first implemented on an experimental level by Sir Richard Lovell Edgeworth in 1767. The first successful optical telegraph network was invented by Claude Chappe and operated in France from 1793 to 1846. The two most extensive systems were Chappe's in France, with branches into neighbouring countries, and the system of Abraham Niclas Edelcrantz in Sweden.\n\nDuring 1790–1795, at the height of the French Revolution, France needed a swift and reliable communication system to thwart the war efforts of its enemies. In 1790, the Chappe brothers set about devising a system of communication that would allow the central government to receive intelligence and to transmit orders in the shortest possible time. On 2 March 1791, at 11 am, they sent the message \"si vous réussissez, vous serez bientôt couverts de gloire\" (If you succeed, you will soon bask in glory) between Brulon and Parce, a distance of . The first means used a combination of black and white panels, clocks, telescopes, and codebooks to send their message.\n\nIn 1792, Claude was appointed \"Ingénieur-Télégraphiste\" and charged with establishing a line of stations between Paris and Lille, a distance of . It was used to carry dispatches for the war between France and Austria. In 1794, it brought news of a French capture of Condé-sur-l'Escaut from the Austrians less than an hour after it occurred.\n\nThe Prussian system was put into effect in the 1830s. However, they were highly dependent on good weather and daylight to work and even then could accommodate only about two words per minute. The last commercial semaphore link ceased operation in Sweden in 1880. As of 1895, France still operated coastal commercial semaphore telegraph stations, for ship-to-shore communication.\n\nThe early ideas for an electric telegraph included in 1753 using electrostatic deflections of pith balls, proposals for electrochemical bubbles in acid by Campillo in 1804 and von Sömmering in 1809. The first experimental system over a substantial distance was electrostatic by Ronalds in 1816. Ronalds offered his invention to the British Admiralty, but it was rejected as unnecessary, the existing optical telegraph connecting the Admiralty in London to their main fleet base in Portsmouth being deemed adequate for their purposes. As late as 1844, after the electrical telegraph had come into use, the Admiralty's optical telegraph was still used, although it was accepted that poor weather ruled it out on many days of the year. France had an extensive optical telegraph dating from Napoleonic times and was even slower to take up electrical systems.\n\nEventually, electrostatic telegraphs were abandoned in favour of electromagnetic systems. An early experimental system (Schilling, 1832) led to a proposal to establish a telegraph between St Petersburg and Kronstadt, but it was never completed. The first operative electric telegraph (Gauss and Weber, 1833) connected Göttingen Observatory to the Institute of Physics about 1 km away during experimental investigations of the geomagnetic field.\n\nThe first commercial telegraph was by Cooke and Wheatstone following their English patent of 10 June 1837. It was demonstrated on the London and Birmingham Railway in July of the same year. In July 1839, a five-needle, five-wire system was installed to provide signalling over a record distance of 21 km on a section of the Great Western Railway between London Paddington station and West Drayton. However, in trying to get railway companies to take up his telegraph more widely for railway signalling, Cooke was rejected several times in favour of the more familiar, but shorter range, steam-powered pneumatic signalling. Even when his telegraph was taken up, it was considered experimental and the company backed out of a plan to finance extending the telegraph line out to Slough. However, this led to a breakthrough for the electric telegraph, as up to this point the Great Western had insisted on exclusive use and refused Cooke permission to open public telegraph offices. Cooke extended the line at his own expense and agreed that the railway could have free use of it in exchange for the right to open it up to the public. \nMost of the early electrical systems required multiple wires (Ronalds' system was an exception), but the system developed in the United States by Morse and Vail was a single-wire system. This was the system that first used the soon-to-become-ubiquitous Morse code. By 1844, the Morse system connected Baltimore to Washington, and by 1861 the west coast of the continent was connected to the east coast. The Cooke and Wheatstone telegraph, in a series of improvements, also ended up with a one-wire system, but still using their own code and needle displays.\n\nThe electric telegraph quickly became a means of more general communication. The Morse system was officially adopted as the standard for continental European telegraphy in 1851 with a revised code, which later became the basis of International Morse Code. However, Great Britain and the British Empire continued to use the Cooke and Wheatstone system, in some places as late as the 1930s. Likewise, the United States continued to use American Morse code internally, requiring translation operators skilled in both codes for international messages.\n\nRailway signal telegraphy was developed in Britain from the 1840s onward. It was used to manage railway traffic and to prevent accidents as part of the railway signalling system. On June 12, 1837 Cooke and Wheatstone were awarded a patent for an electric telegraph. This was demonstrated between Euston railway station—where Wheatstone was located—and the engine house at Camden Town—where Cooke was stationed, together with Robert Stephenson, the London and Birmingham Railway line's chief engineer. The messages were for the operation of the rope-haulage system for pulling trains up the 1 in 77 bank. The world's first permanent railway telegraph was completed in July 1839 between London Paddington and West Drayton on the Great Western Railway with an electric telegraph using a four-needle system.\n\nThe concept of a signalling \"block\" system was proposed by Cooke in 1842. Railway signal telegraphy did not change in essence from Cooke's initial concept for more than a century. In this system each line of railway was divided into sections or blocks of several miles length. Entry to and exit from the block was to be authorised by electric telegraph and signalled by the line-side semaphore signals, so that only a single train could occupy the rails. In Cooke's original system, a single-needle telegraph was adapted to indicate just two messages: \"Line Clear\" and \"Line Blocked\". The signaller would adjust his line-side signals accordingly. As first implemented in 1844 each station had as many needles as there were stations on the line, giving a complete picture of the traffic. As lines expanded, a sequence of pairs of single-needle instruments were adopted, one pair for each block in each direction.\n\nWigwag is a form of flag signalling using a single flag. Unlike most forms of flag signalling, which are used over relatively short distances, wigwag is designed to maximise the distance covered—up to 20 miles in some cases. Wigwag achieved this by using a large flag—a single flag can be held with both hands unlike flag semaphore which has a flag in each hand—and using motions rather than positions as its symbols since motions are more easily seen. It was invented by US Army surgeon Albert J. Myer in the 1850s who later became the first head of the Signal Corps. Wigwag was used extensively during the American Civil War where it filled a gap left by the electrical telegraph. Although the electrical telegraph had been in use for more than a decade, the network did not yet reach everywhere and portable, ruggedized equipment suitable for military use was not immediately available. Permanent or semi-permanent stations were established during the war, some of them towers of enormous height and the system for a while could be described as a communications network.\n\nA heliograph is a telegraph that transmits messages by flashing sunlight with a mirror, usually using Morse code. The idea for a telegraph of this type was first proposed as a modification of surveying equipment (Gauss, 1821). Various uses of mirrors were made for communication in the following years, mostly for military purposes, but the first device to become widely used was a heliograph with a moveable mirror (Mance, 1869). The system was used by the French during the 1870–71 siege of Paris, with night-time signalling using kerosene lamps as the source of light. An improved version (Begbie, 1870) was used by British military in many colonial wars, including the Anglo-Zulu War (1879). At some point, a morse key was added to the apparatus to give the operator the same degree of control as in the electric telegraph.\n\nAnother type of heliograph was the heliostat fitted with a Colomb shutter. The heliostat was essentially a surveying instrument with a fixed mirror and so could not transmit a code by itself. The term \"heliostat\" is sometimes used as a synonym for \"heliograph\" because of this origin. The Colomb shutter (Bolton and Colomb, 1862) was originally invented to enable the transmission of morse code by signal lamp between Royal Navy ships at sea.\n\nThe heliograph was heavily used by Nelson A. Miles in Arizona and New Mexico after he took over command (1886) of the fight against Geronimo and other Apache bands in the Apache Wars. Miles had previously set up the first heliograph line in the US between Fort Keogh and Fort Custer in Montana. He used the heliograph to fill in vast, thinly populated areas that were not covered by the electric telegraph. Twenty-six stations covered an area 200 by 300 miles. In a test of the system, a message was relayed 400 miles in four hours. Miles' enemies used smoke signals and flashes of sunlight from metal, but lacked a sophisticated telegraph code. The heliograph was ideal for use in the American Southwest due to its clear air and mountainous terrain on which stations could be located. It was found necessary to lengthen the morse dash (which is much shorter in American Morse code than in the modern International Morse code) to aid differentiating from the morse dot.\n\nUse of the heliograph declined from 1915 onwards, but remained in service in Britain and British Commonwealth countries for some time. Australian forces used the heliograph as late as 1942 in the Western Desert Campaign of World War II. Some form of heliograph was used by the mujahideen in the Soviet–Afghan War (1979-1989).\n \nA teleprinter is a telegraph machine that can send messages from a typewriter-like keyboard and print incoming messages in readable text with no need for the operators to be trained in the telegraph code used on the line. It developed from various earlier printing telegraphs and resulted in improved transmission speeds. The Morse telegraph (1837) was originally conceived as a system marking indentations on paper tape. A chemical telegraph making blue marks improved the speed of recording (Bain, 1846), but was retarded by a patent challenge from Morse. The first true printing telegraph (that is printing in plain text) used a spinning wheel of types in the manner of a daisy wheel printer (House, 1846, improved by Hughes, 1855). The system was adopted by Western Union.\n\nEarly teleprinters used the Baudot code, a five-bit sequential binary code. This was a telegraph code developed for use on the French telegraph using a five-key keyboard (Baudot, 1874). Teleprinters generated the same code from a full alphanumeric keyboard. A feature of the Baudot code, and subsequent telegraph codes, was that, unlike Morse code, every character has a code of the same length making it more machine friendly. The Baudot code was used on the earliest ticker tape machines (Calahan, 1867), a system for mass distributing stock price information.\nIn a punched-tape system, the message is first typed onto punched tape using the code of the telegraph system—Morse code for instance. It is then, either immediately or at some later time, run through a transmission machine which sends the message to the telegraph network. Multiple messages can be sequentially recorded on the same run of tape. The advantage of doing this is that messages can be sent at a steady, fast rate making maximum use of the available telegraph lines. The economic advantage of doing this is greatest on long, busy routes where the cost of the extra step of preparing the tape is outweighed by the cost of providing more telegraph lines. The first machine to use punched tape was Bain's teleprinter (Bain, 1843), but the system saw only limited use. Later versions of Bain's system achieved speeds up to 1000 words per minute, far faster than a human operator could achieve.\n\nThe first widely used system (Wheatstone, 1858) was first put into service with the British General Post Office in 1867. A novel feature of the Wheatstone system was the use of bipolar encoding. That is, both positive and negative polarity voltages were used. Bipolar encoding has several advantages, one of which is that it permits duplex communication. The Wheatstone tape reader was capable of a speed of 400 words per minute.\n\nA worldwide communication network meant that telegraph cables would have to be laid across oceans. On land cables could be run uninsulated suspended from poles. Underwater, a good insulator that was both flexible and capable of resisting the ingress of seawater was required, and at first this was not available. A solution presented itself with gutta-percha, a natural rubber from the \"Palaquium gutta\" tree, after William Montgomerie sent samples to London from Singapore in 1843. The new material was tested by Michael Faraday and in 1845 Wheatstone suggested that it should be used on the cable planned between Dover and Calais by John Watkins Brett. The idea was proved viable when the South Eastern Railway company successfully tested a two-mile gutta-percha insulated cable with telegraph messages to a ship off the coast of Folkstone. The cable to France was laid in 1850 but was almost immediately severed by a French fishing vessel. It was relaid the next year and connections to Ireland and the Low Countries soon followed.\n\nGetting a cable across the Atlantic Ocean proved much more difficult. The Atlantic Telegraph Company, formed in London in 1856, had several failed attempts. A cable laid in 1858 worked poorly for a few days (sometimes taking all day to send a message despite the use of the highly sensitive mirror galvanometer developed by William Thomson (the future Lord Kelvin) before being destroyed by applying too high a voltage. Its failure and slow speed of transmission prompted Thomson and Oliver Heaviside to find better mathematical descriptions of long transmission lines. Thomson also developed the . The company finally succeeded in 1866 with an improved cable laid by SS \"Great Eastern\", the largest ship of its day, designed by Isambard Kingdom Brunel.\n\nAn overland telegraph from Britain to India was first connected in 1866 but was unreliable so a submarine telegraph cable was connected in 1870. Several telegraph companies were combined to form the \"Eastern Telegraph Company\" in 1872. Australia was first linked to the rest of the world in October 1872 by a submarine telegraph cable at Darwin.\n\nFrom the 1850s until well into the 20th century, British submarine cable systems dominated the world system. This was set out as a formal strategic goal, which became known as the All Red Line. In 1896, there were thirty cable-laying ships in the world and twenty-four of them were owned by British companies. In 1892, British companies owned and operated two-thirds of the world's cables and by 1923, their share was still 42.7 percent. During World War I, Britain's telegraph communications were almost completely uninterrupted while it was able to quickly cut Germany's cables worldwide.\n\nIn 1843, Scottish inventor Alexander Bain invented a device that could be considered the first facsimile machine. He called his invention a \"recording telegraph\". Bain's telegraph was able to transmit images by electrical wires. Frederick Bakewell made several improvements on Bain's design and demonstrated a telefax machine. In 1855, an Italian abbot, Giovanni Caselli, also created an electric telegraph that could transmit images. Caselli called his invention \"Pantelegraph\". Pantelegraph was successfully tested and approved for a telegraph line between Paris and Lyon.\n\nIn 1881, English inventor Shelford Bidwell constructed the \"scanning phototelegraph\" that was the first telefax machine to scan any two-dimensional original, not requiring manual plotting or drawing. Around 1900, German physicist Arthur Korn invented the \"\" widespread in continental Europe especially since a widely noticed transmission of a wanted-person photograph from Paris to London in 1908 used until the wider distribution of the radiofax. Its main competitors were the \"Bélinographe\" by Édouard Belin first, then since the 1930s, the \"Hellschreiber\", invented in 1929 by German inventor Rudolf Hell, a pioneer in mechanical image scanning and transmission.\n\nThe late 1880s through to the 1890s saw the discovery and then development of a newly understood phenomenon into a form of wireless telegraphy, called \"Hertzian wave\" wireless telegraphy, radiotelegraphy, or (later) simply \"radio\". Between 1886 and 1888, Heinrich Rudolf Hertz published the results of his experiments where he was able to transmit electromagnetic waves (radio waves) through the air, proving James Clerk Maxwell's 1873 theory of electromagnetic radiation. Many scientists and inventors experimented with this new phenomenon but the general consensus was that these new waves (similar to light) would be just as short range as light, and, therefore, useless for long range communication.\n\nAt the end of 1894, the young Italian inventor Guglielmo Marconi began working on the idea of building a commercial wireless telegraphy system based on the use of Hertzian waves (radio waves), a line of inquiry that he noted other inventors did not seem to be pursuing. Building on the ideas of previous scientists and inventors Marconi re-engineered their apparatus by trial and error attempting to build a radio-based wireless telegraphic system that would function the same as wired telegraphy. He would work on the system through 1895 in his lab and then in field tests making improvements to extend its range. After many breakthroughs, including applying the wired telegraphy concept of grounding the transmitter and receiver, Marconi was able, by early 1896, to transmit radio far beyond the short ranges that had been predicted. Having failed to interest the Italian government, the 22-year-old inventor brought his telegraphy system to Britain in 1896 and met William Preece, a Welshman, who was a major figure in the field and Chief Engineer of the General Post Office. A series of demonstrations for the British government followed—by March 1897, Marconi had transmitted Morse code signals over a distance of about across Salisbury Plain.\n\nOn 13 May 1897, Marconi, assisted by George Kemp, a Cardiff Post Office engineer, transmitted the first wireless signals over water to Lavernock (near Penarth in Wales) from Flat Holm. The message sent was \"ARE YOU READY\". From his Fraserburgh base, he transmitted the first long-distance, cross-country wireless signal to Poldhu in Cornwall. His star rising, he was soon sending signals across The English channel (1899), from shore to ship (1899) and finally across the Atlantic (1901). A study of these demonstrations of radio, with scientists trying to work out how a phenomenon predicted to have a short range could transmit \"over the horizon\", led to the discovery of a radio reflecting layer in the Earth's atmosphere in 1902, later called the ionosphere.\n\nRadiotelegraphy proved effective for rescue work in sea disasters by enabling effective communication between ships and from ship to shore. In 1904, Marconi began the first commercial service to transmit nightly news summaries to subscribing ships, which could incorporate them into their on-board newspapers. A regular transatlantic radio-telegraph service was finally begun on 17 October 1907. Notably, Marconi's apparatus was used to help rescue efforts after the sinking of \"Titanic\". Britain's postmaster-general summed up, referring to the \"Titanic\" disaster, \"Those who have been saved, have been saved through one man, Mr. Marconi...and his marvellous invention.\"\n\nA telegram service is a company or public entity that delivers telegraphed messages.\n\nHistorically, telegrams were sent between a network of interconnected telegraph offices. A person visiting a local telegraph office paid by the word to have a message telegraphed to another office and delivered to the addressee on a paper form. Messages sent by telegraph could be delivered faster than mail, and even in the telephone age, the telegram remained popular for social and business correspondence. At their peak in 1929, an estimated 200 million telegrams were sent. \n\nTelegram services still operate in much of the world (see worldwide use of telegrams by country), but e-mail and text messaging have rendered telegrams obsolete in many countries, and the number of telegrams sent annually has been declining rapidly since the 1980s. Where telegram services still exist, the transmission method between offices is no longer by telegraph, but by telex or IP link.\n\nAs telegrams have been traditionally charged by the word, messages were often abbreviated to pack information into the smallest possible number of words, in what came to be called \"telegram style\".\n\nThe average length of a telegram in the 1900s in the US was 11.93 words; more than half of the messages were 10 words or fewer. According to another study, the mean length of the telegrams sent in the UK before 1950 was 14.6 words or 78.8 characters. For German telegrams, the mean length is 11.5 words or 72.4 characters. At the end of the 19th century, the average length of a German telegram was calculated as 14.2 words.\n\nTelex (TELegraph EXchange) was a public switched network of teleprinters. It used rotary-telephone-style pulse dialling for automatic routing through the network. It initially used the Baudot code for messages. Telex development began in Germany in 1926, becoming an operational service in 1933 run by the Reichspost (Reich postal service). It had a speed of 50 baud—approximately 66 words per minute. Up to 25 telex channels could share a single long-distance telephone channel by using voice frequency telegraphy multiplexing, making telex the least expensive method of reliable long-distance communication. Telex was introduced into Canada in July 1957, and the United States in 1958. A new code, ASCII, was introduced in 1963 by the American Standards Association. ASCII was a 7-bit code and could thus support a larger number of characters than Baudot. In particular, ASCII supported upper and lower case whereas Baudot was upper case only.\n\nTelegraph use began to permanently decline around 1920. The decline began with the growth of the use of the telephone. Ironically, the invention of the telephone grew out of the development of the harmonic telegraph, a device which was supposed to increase the efficiency of telegraph transmission and improve the profits of telegraph companies. Western Union gave up their patent battle with Alexander Graham Bell because they believed the telephone was not a threat to their telegraph business. The Bell Telephone Company was formed in 1877 and had 230 subscribers which grew to 30,000 by 1880. By 1886 there were a quarter of a million phones worldwide, and nearly 2 million by 1900. The decline was briefly postponed by the rise of special occasion congratulatory telegrams. Traffic continued to grow between 1867 and 1893 despite the introduction of the telephone in this period, but by 1900 the telegraph was definitely in decline.\n\nThere was a brief resurgence in telegraphy during World War I but the decline continued as the world entered the Great Depression years of the 1930s. Telegraph lines continued to be an important means of distributing news feeds from news agencies by teleprinter machine until the rise of the internet in the 1990s. For Western Union, one service remained highly profitable—the wire transfer of money. This service kept Western Union in business long after the telegraph had ceased to be important.\n\nThe telegraph freed communication from the time constraints of postal mail and revolutionized the global economy and society. By the end of the 19th century, the telegraph was becoming an increasingly common medium of communication for ordinary people. The telegraph isolated the message (information) from the physical movement of objects or the process.\n\nThere was some fear of the new technology. According to author Allan J. Kimmel, some people \"feared that the telegraph would erode the quality of public discourse through the transmission of irrelevant, context-free information.\" Henry David Thoreau thought of the Transatlantic cable \"...perchance the first news that will leak through into the broad flapping American ear will be that Princess Adelaide has the whooping cough.\" Kimmel says these fears anticipate many of the characteristics of the modern internet age.\n\nInitially, the telegraph was expensive to use, so was mostly limited to businesses that could use it to improve profits. The telegraph had an enormous effect on three industries; finance, newspapers, and railways. Telegraphy facilitated the growth of organizations \"in the railroads, consolidated financial and commodity markets, and reduced information costs within and between firms\". In the US, there were 200 to 300 stock exchanges before the telegraph, but most of these were unnecessary and unprofitable once the telegraph made financial transactions at a distance easy and drove down transaction costs. This immense growth in the business sectors influenced society to embrace the use of telegrams once the cost had fallen.\n\nWorldwide telegraphy changed the gathering of information for news reporting. Journalists were using the telegraph for war reporting as early as 1846 when the Mexican–American War broke out. News agencies were formed, such as the Associated Press, for the purpose of reporting news by telegraph. Messages and information would now travel far and wide, and the telegraph demanded a language \"stripped of the local, the regional; and colloquial\", to better facilitate a worldwide media language. Media language had to be standardized, which led to the gradual disappearance of different forms of speech and styles of journalism and storytelling.\n\nThe spread of the railways created a need for an accurate standard time to replace local arbitrary standards based on local noon. The means of achieving this synchronisation was the telegraph. This emphasis on precise time has led to major societal changes such as the concept of the time value of money.\n\nThe shortage of men to work as telegraph operators in the American Civil War opened up the opportunity for women of a well-paid skilled job.\n\nThe economic impact of the telegraph was not much studied by economic historians until parallels started to be drawn with the rise of the internet. In fact, the electric telegraph was as important as the invention of printing in this respect. According to economist Ronnie J. Phillips, the reason for this may be that institutional economists paid more attention to advances that required greater capital investment. The investment required to build railways, for instance, is orders of magnitude greater than that for the telegraph.\n\nThe optical telegraph was quickly forgotten once it went out of service. While it was in operation, it was very familiar to the public across Europe. Examples appear in many paintings of the period. Poems include \"Le Telégraphe\", by Victor Hugo, and the collection \"Telegrafen: Optisk kalender för 1858\" by is dedicated to the telegraph. In novels, the telegraph is a major component in \"Lucien Leuwen\" by Stendhal, and it features in \"The Count of Monte Cristo\", by Alexandre Dumas. Joseph Chudy's 1796 opera, \"Der Telegraph oder die Fernschreibmaschine\", was written to publicise Chudy's telegraph (a binary code with five lamps) when it became clear that Chappe's design was being taken up.\n\nRudyard Kipling wrote a poem in praise of submarine telegraph cables; \"And a new Word runs between: whispering, 'Let us be one!'\" Kipling's poem represented a widespread idea in the late nineteenth century that international telegraphy (and new technology in general) would bring peace and mutual understanding to the world.\n\nNumerous newspapers and news outlets in various countries, such as \"The Daily Telegraph\" in Britain, \"The Telegraph\" in India, \"De Telegraaf\" in the Netherlands, and the Jewish Telegraphic Agency in the US, were given names which include the word \"telegraph\" due to their having received news by means of electric telegraphy. Some of these names are retained even though different means of news acquisition are now used.\n\n", "related": "\n- Casa del Telegrafista, a Colombian museum dedicated to the telegrapher at a train station\n- David E. Hughes, designer of a telegraph that used an alphabetic keyboard and printer wheel\n- Familygram\n- First transcontinental telegraph\n- Globotype\n- Heliograph\n- Prosigns for Morse code\n- Telecommunications\n- Telegram messenger\n- Telegram style\n- Text messaging\n- \"The Victorian Internet: The Remarkable Story of the Telegraph and the Nineteenth Century's On-Line Pioneers\", a book about the telegraph\n- Women in telegraphy\n\n- Britton, John A. \"Cables, Crises, and the Press: The Geopolitics of the New International Information System in the Americas, 1866–1903\". (University of New Mexico Press, 2013).\n- Fari, Simone. \"Formative Years of the Telegraph Union\" (Cambridge Scholars Publishing, 2015).\n- Fari, Simone. \"Victorian Telegraphy Before Nationalization\" (2014).\n- Hochfelder, David, \"The Telegraph in America, 1832–1920\" (Johns Hopkins University Press, 2012).\n- Huurdeman, Anton A. \"The Worldwide History of Telecommunications\" (John Wiley & Sons, 2003)\n- John, Richard R. \"Network Nation: Inventing American Telecommunications\" (Harvard University Press; 2010) 520 pages; the evolution of American telegraph and telephone networks.\n- Kieve, Jeffrey L. (1973). \"The Electric Telegraph: a Social and Economic History\". David and Charles. .\n- Lew, B., and Cater, B. \"The Telegraph, Co-ordination of Tramp Shipping, and Growth in World Trade, 1870–1910\", \"European Review of Economic History\" 10 (2006): 147–73.\n- Müller, Simone M., and Heidi JS Tworek. \"'The telegraph and the bank': on the interdependence of global communications and capitalism, 1866–1914.\" \"Journal of Global History\" 10#2 (2015): 259–283.\n- O'Hara, Glen. \"New Histories of British Imperial Communication and the 'Networked World' of the 19th and Early 20th Centuries\" \"History Compass\" (2010) 8#7pp 609–625, Historiography,\n- Richardson, Alan J. \"The cost of a telegram: Accounting and the evolution of international regulation of the telegraph.\" \"Accounting History\" 20#4 (2015): 405–429.\n- Standage, Tom (1998). \"The Victorian Internet\". Berkley Trade. .\n- Thompson, Robert Luther. \"Wiring a continent: The history of the telegraph industry in the United States, 1832–1866\" (Princeton UP, 1947).\n- Wenzlhuemer, Roland. \"The Development of Telegraphy, 1870–1900: A European Perspective on a World History Challenge.\" \"History Compass\" 5#5 (2007): 1720–1742.\n- Wenzlhuemer, Roland. \"Connecting the nineteenth-century world: The telegraph and globalization\" (Cambridge UP, 2013). online review\n- Winseck, Dwayne R., and Robert M. Pike. \"Communication & Empire: Media, Markets & Globalization, 1860–1930\" (2007), 429pp.\n\n- Dargan, J. \"The Railway Telegraph\", \"Australian Railway Historical Society Bulletin\", March, 1985 pp. 49–71\n- Pichler, Franz, \"Magneto-Electric Dial Telegraphs: Contributions of Wheatstone, Stoehrer and Siemens\", The AWA Review vol. 26, (2013).\n- Ross, Nelson E. HOW TO WRITE TELEGRAMS PROPERLY The Telegraph Office (1928)\n- Wheen, Andrew;— \"DOT-DASH TO DOT.COM: How Modern Telecommunications Evolved from the Telegraph to the Internet\" (Springer, 2011)\n- Wilson, Geoffrey, \"The Old Telegraphs\", Phillimore & Co Ltd 1976 ; a comprehensive history of the shutter, semaphore and other kinds of visual mechanical telegraphs.\n\n- The Porthcurno Telegraph Museum The biggest Telegraph station in the world, now a museum\n- Distant Writing—The History of the Telegraph Companies in Britain between 1838 and 1868\n- Western Union Telegraph Company Records, 1820–1995 Archives Center, National Museum of American History, Smithsonian Institution.\n- Early telegraphy and fax engineering, still operable in a German computer museum\n- \"Telegram Falls Silent Stop Era Ends Stop\", \"The New York Times\", February 6, 2006\n- International Facilities of the American Carriers – an overview of the U.S. international cable network in 1950\n- Elizabeth Bruton: Communication Technology, in: 1914-1918-online. International Encyclopedia of the First World War.\n"}
{"id": "56977700", "url": "https://en.wikipedia.org/wiki?curid=56977700", "title": "Insecure channel", "text": "Insecure channel\n\nIn contrast to a secure channel, an insecure channel is unencrypted and may be subject to eavesdropping. Secure communications are possible over an insecure channel if the content to be communicated is encrypted prior to transmission.\n", "related": "NONE"}
{"id": "57859530", "url": "https://en.wikipedia.org/wiki?curid=57859530", "title": "Data plan", "text": "Data plan\n\nData plan refers to data quotas from a telecommunications or data hosting contract. Data plans are offered by internet service providers. These include mobile data plans, offered on cellular networks, from cellular telephony companies, and those from conventional fixed land line links, amongst other forms of offered data communications. Network data hosting servers also offer plans based on data served, such as for websites.\n", "related": "NONE"}
{"id": "4540869", "url": "https://en.wikipedia.org/wiki?curid=4540869", "title": "Radio code", "text": "Radio code\n\nRadio code is any code that is commonly used over a telecommunication system such as Morse code, brevity codes and procedure words.\n\nBrevity codes are designed to convey complex information with a few words or codes. Specific brevity codes include:\n- ACP-131\n- Aeronautical Code signals\n- ARRL Numbered Radiogram\n- Multiservice tactical brevity code\n- Ten-code\n- Phillips Code\n- NOTAM Code\n\nBrevity codes that are specifically designed for use \nbetween communications operators and to support communication operations are referred to as \"operating signals\". These include:\n- Prosigns for Morse code\n- 92 Code, Western Union telegraph brevity codes\n- Q code, initially developed for commercial radiotelegraph communication, later adopted by other radio services, especially amateur radio. Used since circa 1909.\n- QN Signals, published by the ARRL and used by Amateur radio operators to assist in the transmission of ARRL Radiograms in the National Traffic System.\n- R code, published by the British Post Office in 1908 for use only by British coastal wireless stations and ships licensed by the Postmaster General.\n- S code, published by the British Post Office in 1908 for use only by British coastal wireless stations and ships licensed by the Postmaster General.\n- X code, used by European military services as a wireless telegraphy code in the 1930s and 1940s\n- Z code, also used in the early days of radiotelegraph communication.\n\nMorse code, is commonly used in Amateur radio. Morse code abbreviations are a type of brevity code. Procedure words used in radiotelephony procedure, are a type of radio code. Spelling alphabets, including the ICAO spelling alphabet, are commonly used in communication over radios and telephones.\n\nMany car audio systems (car radios) have a so-called 'radio code' number which needs to be entered after a power disconnection. This was introduced as a measure to deter theft of these devices. If the code is entered correctly, the radio is activated for use. Entering the code incorrectly several times in a row will cause a temporary or permanent lockout. Some car radios have another check which operates in conjuction with car electronics. If the VIN or another vehicle ID matches the previously stored one, the radio is activated. If the radio cannot verify the vehicle, it is considered to be moved into another vehicle. The radio will then request for the code number or simply refuse to operate and display an error message such as \"CANCHECK\" or \"SECURE\".\n\n", "related": "\n- Encoding\n"}
{"id": "38140", "url": "https://en.wikipedia.org/wiki?curid=38140", "title": "Wide area network", "text": "Wide area network\n\nA wide area network (WAN) is a telecommunications network that extends over a large geographical area for the primary purpose of computer networking. Wide area networks are often established with leased telecommunication circuits.\n\nBusiness, as well as education and government entities use wide area networks to relay data to staff, students, clients, buyers and suppliers from various locations across the world. In essence, this mode of telecommunication allows a business to effectively carry out its daily function regardless of location. The Internet may be considered a WAN.\n\nSimilar types of networks are personal area networks (PANs), local area networks (LANs), campus area networks (CANs), or metropolitan area networks (MANs) which are usually limited to a room, building, campus or specific metropolitan area, respectively.\n\nThe textbook definition of a WAN is a computer network spanning regions, countries, or even the world. However, in terms of the application of computer networking protocols and concepts, it may be best to view WANs as computer networking technologies used to transmit data over long distances, and between different LANs, MANs and other localised computer networking architectures. This distinction stems from the fact that common LAN technologies operating at lower layers of the OSI model (such as the forms of Ethernet or Wi-Fi) are often designed for physically proximal networks, and thus cannot transmit data over tens, hundreds, or even thousands of miles or kilometres.\n\nWANs do not just necessarily connect physically disparate LANs. A CAN, for example, may have a localized backbone of a WAN technology, which connects different LANs within a campus. This could be to facilitate higher bandwidth applications or provide better functionality for users in the CAN.\n\nWANs are used to connect LANs and other types of networks together so that users and computers in one location can communicate with users and computers in other locations. Many WANs are built for one particular organization and are private. Others, built by Internet service providers, provide connections from an organization's LAN to the Internet. WANs are often built using leased lines. At each end of the leased line, a router connects the LAN on one side with a second router within the LAN on the other. Leased lines can be very expensive. Instead of using leased lines, WANs can also be built using less costly circuit switching or packet switching methods. Network protocols including TCP/IP deliver transport and addressing functions. Protocols including Packet over SONET/SDH, Multiprotocol Label Switching (MPLS), Asynchronous Transfer Mode (ATM) and Frame Relay are often used by service providers to deliver the links that are used in WANs. X.25 was an important early WAN protocol, and is often considered to be the \"grandfather\" of Frame Relay as many of the underlying protocols and functions of X.25 are still in use today (with upgrades) by Frame Relay.\n\nAcademic research into wide area networks can be broken down into three areas: mathematical models, network emulation, and network simulation.\n\nPerformance improvements are sometimes delivered via wide area file services or WAN optimization.\n\nOf the approximately four billion addresses defined in IPv4, about 18 million addresses in three ranges are reserved for use in private networks. Packets addresses in these ranges are not routable in the public Internet; they are ignored by all public routers. Therefore, private hosts cannot directly communicate with public networks, but require network address translation at a routing gateway for this purpose.\n<section begin=IPv4-private-networks/>\n\nSince two private networks, e.g., two branch offices, cannot directly interoperate via the public Internet, the two networks must be bridged across the Internet via a virtual private network (VPN) or an IP tunnel, which encapsulates packets, including their headers containing the private addresses, in a protocol layer during transmission across the public network. Additionally, encapsulated packets may be encrypted for the transmission across public networks to secure the data.\n\nMany technologies are available for wide area network links. Examples include circuit-switched telephone lines, radio wave transmission, and optical fiber. New developments in technologies have successively increased transmission rates. In ca. 1960, a 110 bit/s (bits per second) line was normal on the edge of the WAN, while core links of 56 kbit/s to 64 kbit/s were considered fast. , households are connected to the Internet with dial-up, asymmetric digital subscriber line (ADSL), cable, WiMAX, 4G or fiber. The speeds that people can currently use range from 28.8 kbit/s through a 28K modem over a telephone connection to speeds as high as 100 Gbit/s over an Ethernet 100GBaseY connection.\n\nThe following communication and networking technologies have been used to implement WANs.\n\n- Asynchronous Transfer Mode\n- Cable modem\n- Dial-up internet\n- Digital subscriber line\n- Fiber-optic communication\n- Frame Relay\n- ISDN\n- Leased line\n- SD-WAN\n- Synchronous optical networking\n- X.25\nAT&T conducted trials in 2017 for business use of 400-gigabit Ethernet. Researchers Robert Maher, Alex Alvarado, Domaniç Lavery, and Polina Bayvel of University College London were able to increase networking speeds to 1.125 terabits per second. Christos Santis, graduate student Scott Steger, Amnon Yariv, Martin and Eileen Summerfield developed a new laser that potentially quadruples transfer speeds with fiber optics.\n\n", "related": "\n- Cell switching\n- Internet area network (IAN)\n- Label switching\n- Low Power Wide Area Network (LPWAN)\n- Wide area application services\n- Wide area file services\n- Wireless WAN\n- Cisco - Introduction to WAN Technologies\n"}
{"id": "6671045", "url": "https://en.wikipedia.org/wiki?curid=6671045", "title": "T.38", "text": "T.38\n\nT.38 is an ITU recommendation for allowing transmission of fax over IP networks (FoIP) in real time.\n\nThe T.38 fax relay standard was devised in 1998 as a way to permit faxes to be transported across IP networks between existing Group 3 (G3) fax terminals. T.4 and related fax standards were published by the ITU in 1980, before the rise of the Internet. In the late 1990s, VoIP, or Voice over IP, began to gain ground as an alternative to the conventional Public Switched Telephone Network (PSTN). However, because most VoIP systems are optimized (through their use of aggressive lossy bandwidth-saving compression) for voice rather than data calls, conventional fax machines worked poorly or not at all on them due to the network impairments such as delay, jitter, packet loss, and so on. Thus, some way of transmitting fax over IP was needed.\n\nIn practical scenarios, a T.38 fax call has at least part of the call being carried over PSTN, although this is not required by the T.38 definition, and two T.38 devices can send faxes to each other. This particular type of device is called Internet-Aware Fax device, or IAF, and it is capable of initiating or completing a fax call towards the IP network.\n\nThe typical scenario where T.38 is used is - T.38 Fax relay - where a T.30 fax device sends a fax over PSTN to a T.38 Fax gateway which converts or encapsulates the T.30 protocol into T.38 data stream. This is then sent either to a T.38 enabled end point such as fax machine or fax server or another T.38 Gateway that converts it back to PSTN PCM or analog signal and terminates the fax on a T.30 device.\n\nThe T.38 recommendation defines the use of both TCP and UDP to transport T.38 packets. Implementations tend to use UDP, due to TCP's requirement for acknowledgement packets and resulting retransmission during packet loss, which introduces delays. When using UDP, T.38 copes with packet loss by using redundant data packets.\n\nT.38 is not a call setup protocol, thus the T.38 devices need to use standard call setup protocols to negotiate the T.38 call, e.g. H.323, SIP & MGCP.\n\nThere are two primary ways that fax transactions are conveyed across packet networks. The T.37 standard specifies how a fax image is encapsulated in e-mail and transported, ultimately, to the recipient using a store-and-forward process through intermediary entities. T.38, however, defines a protocol that supports the use of the T.30 protocol in both the sender and recipient terminals. (See diagram above.) T.38 lets one transmit a fax across an IP network in real time, just as the original G3 fax standards did for the traditional (time-division multiplexed (TDM)) network, also called the public switched telephone network or PSTN.\n\nA special protocol is needed for real-time fax over IP (Internet Protocol) since existing fax terminals only supported PSTN connections, where the information flow was generally smooth and uninterrupted, as opposed to the jittery arrival of IP packets. The trick was to come up with a protocol that makes the IP network “invisible” to the endpoint fax terminals, which would mean the user of a legacy fax terminal need not know that the fax call was traversing an IP network.\n\nThe network interconnections supported by T.38 are shown above. The two fax terminals on either side of the figure communicate using the T.30 fax protocol published by the ITU in 1980. Interconnection of the PSTN with the IP packet network requires a “gateway” between the PSTN and IP networks. PSTN-IP Gateways support TDM voice on the PSTN side and VoIP and FoIP on the packet side.\n\nFor voice sessions, the gateway will take in voice packets on the IP side, accumulate a few packets to ensure a smooth flow of TDM data upon their release, and then meter them out over TDM where they eventually are heard by a human or stored on a computer for later playback. The gateway employs packet-management techniques to enhance the quality of the speech in the presence of network errors by taking advantage of the natural ability of a listener to not really hear the occasional missing or repeated packet.\n\nBut facsimile data are transmitted by modems, which aren't as forgiving as the human ear is for speech. Missing packets will often cause a fax session to fail at worst or create one or more image lines in error at best. So the job of T.38 is to “fool” the terminal into “thinking” that it's communicating directly with another T.30 terminal. It will also correct for network delays with so-called spoofing techniques, and missing or delayed packets with fax-aware buffer-management techniques.\n\nSpoofing refers to the logic implemented in the protocol engine of a T.38 relay that modifies the protocol commands and responses on the TDM side to keep network delays on the IP side from causing the transaction to fail. This is done, for example, by padding image lines or deliberately causing a message to be re-transmitted to render network delays transparent to the sending/receiving fax terminals.\n\nNetworks that do not have packet loss or excessive delay can exhibit acceptable fax performance without T.38, provided the PCM clocks in all gateways are of very high accuracy (explained below). T.38 not only removes the effect of PCM clocks not being synchronized, but also reduces the required network bandwidth by a factor of 10, while it corrects for packet loss and delay.\n\nAs shown in the diagram below, a T.38 gateway is composed of two primary elements: the fax modems and the T.38 subsystem. The fax modems modulate and demodulate the PCM samples of the analog data, turning the sampled-data representation of the fax terminal's analog signal to its binary translation, and vice versa. The PSTN network samples the analog signal of a voice or modem signal (it doesn't know the difference) 8,000 times per second (SPS), and encodes them as 8-bit data bytes. This means 8000 samples-per-second times 8-bits per sample, or 64,000 bits per second (bit/s) to represent the modem (or voice) data in one direction. For both directions the modem transaction consumes 128,000 bits of network bandwidth.\n\nHowever, the typical modem in a fax terminal transmits the image data at 33,600 bit/s, so if the analog data are first converted to the digital content they represent, only 33,600 bits (plus network overhead of a few bytes) are needed. And since T.30 fax is a half-duplex protocol, the network is only needed for one direction at a time.\n\nRefer to RFC 3261\n\nIn the diagram above, there is a sample-rate clock in the fax terminal and one in the gateway's modems that is used to trigger the sampling of the analog line 8,000 times per second. These clocks are usually quite accurate, but in some low-cost terminal adapters (a one or two-line gateway) the PCM clock can be surprisingly inaccurate. If the terminal is sending data to the gateway, and the gateway's clock is too slow, the buffers (jitter buffers) in the gateway will eventually overflow, causing the transaction to fail. Since the difference is often quite small, this problem occurs on long, detailed fax images giving the clocks more time to cause the jitter buffer in gateway to either underflow or overflow, which is just the same as missing or duplicated packets.\n\nT.38 provides facilities to eliminate the effects of packet loss through data redundancy. When a packet is sent, either zero, one, two, three, or even more of the previously sent packets are repeated. (The specification does not impose a limit.) This increases the network bandwidth required (it's still much less than not using T.38) but it allows the receiving gateway to reconstruct the complete packet sequence, even with a fairly high level of packet loss.\n\n- T.4 is the umbrella specification for fax. It specifies the standard image sizes, two forms of image-data compression (encoding), the image-data format, and references, T.30 and the various modem standards.\n- T.6 specifies a compression scheme that reduces the time required to transmit an image by roughly 50-percent.\n- T.30 specifies the procedures that a sending and receiving terminal use to set up a fax call, determine the image size, encoding, and transfer speed, the demarcation between pages, and the termination of the call. T.30 also references the various modem standards.\n- V.21, V.27ter, V.29, V.17, V.34: ITU modem standards used in facsimile. The first three were ratified prior to 1980, and were specified in the original T.4 and T.30 standards. V.34 was published for fax in 1994.\n- T.37 The ITU standard for sending a fax-image file via e-mail to the intended recipient of a fax.\n- G.711 pass through - this is where the T.30 fax call is carried in a VoIP call encoded as audio. This is sensitive to network packet loss, jitter and clock synchronization. When using voice high-compression encoding techniques such as, but not limited to, G.729, some fax tonal signals may not get correctly transported across the packet network.\n- RFC 3362 defines the image/t38 media type (formerly known as MIME type) for use with the Session Description Protocol.\n\n- Asterisk (PBX) open source pbx support T.38 faxing\n- Freeswitch Softswitch / pbx also support T.38\n- ICTFax Web fax / Email to fax gateway with support T.38\n\n", "related": "\n- Internet fax\n- Telephony\n\n- ITU-T T.38 page\n- spandsp author's science paper on FoIP\n"}
{"id": "59972697", "url": "https://en.wikipedia.org/wiki?curid=59972697", "title": "Sherita Ceasar", "text": "Sherita Ceasar\n\nSherita T. Ceasar is the Senior Vice President of National Video Deployment Engineering for Comcast Communications, and has worked in the telecommunications industry since the 1990s.\n\nSherida Brown grew up on the south side of Chicago, attending a technical college preparatory school. She earned a Bachelor of Science in 1981 followed by a Masters of Science in 1984, both in Mechanical Engineering from the Illinois Institute of Technology in Chicago, Illinois.\n\nCeasar began her career in the defense department at Northrop Grumman. She then moved to work at Motorola from 1992-1996, working in component design, manufacturing, quality, and building pagers. As Director of Manufacturing, Ceasar was the highest-ranking black female engineer at Motorola's Paging Products Group, which had over 10,000 associates globally. In 1996 she started at Scientific-Atlanta as Vice President of Quality, where she was the highest ranking African American. Ceasar then worked as Vice President and General Manager of the Georgia branch of Charter Communications, before starting as Vice President of the product engineering, cross platform and engineering services of Comcast in 2007. She became Vice President of National Video Deployment Engineering for Comcast in 2011, leading the development of services such as the X1 remote, cloud DVR, and building infrastructure of the cloud.\n\nIn 1994, Ceasar won the Black Engineer of the Year Special Recognition Award. In 1997, she won the Women of Color Technology Award, sponsored by Career Communications Group during Baltimore's Bicentennial Celebration. She also received the Society of Women Engineers' Distinguished New Engineer of the Year, and the Julia Beveridge Award for her support of the Illinois Institute of Technology. She was inducted into the Women in Technology Hall of Fame in 1999. She also served as President of the Society of Women Engineers from 1999-2000, becoming the first African American to hold the position. In 2003, Ceasar won a Cable & Telecommunications Association for Marketing (CTAM) TAMI Award for launching master courses on advanced digital services. In 2014, she won the Women in Technology Award.\n", "related": "NONE"}
{"id": "48324675", "url": "https://en.wikipedia.org/wiki?curid=48324675", "title": "Closing the Loop", "text": "Closing the Loop\n\nClosing the Loop is a company that offers a closed loop service for mobile phones. The Dutch social enterprise is based in Amsterdam, the Netherlands. It was founded with the aim to reduce electronic waste (e-waste). It does this by offering users and sellers of phones a way to make their device material-neutral and waste free. The company pays people in emerging markets to collect scrap phones. These phones are then recycled for Closing the Loop’s customers. The proposition works on a one for one basis, where a customer’s phone is ‘offset’ by the recycling of a broken phone. Known customers are T-Mobile, KPMG, the city of Utrecht, Rabobank and the Dutch national government.\n\nClosing the Loop buys and collects 'end-of-life' scrap phones in African countries, which are known to be places where many used phones from Europe and the US get a second life. The waste Closing the Loop collects, is recycled in Europe. In this way Closing the Loop turns scrap phones into valuable resources and an income for people in developing countries. Its goal is to prevent mobile phones from ending up in dump sites and at the same time create a more sustainable telecom industry.\n\nClosing the Loop has saved more than 2.2 million mobile phones from the dump in Africa and gave more than 145,000 mobile phones a second life. Mobile phones are bought from informal local collector networks. To date, Closing the Loop has helped more than 2,000 people in Africa to earn additional income through safe employment.\n\nThe social enterprise sees e-waste as an opportunity. An opportunity to source companies with responsibly sourced metals, to make industries like telecom circular - by closing loops - and to create income for people in emerging markets. It aims to contribute to the circular economy and the Sustainable Development Goals.\n\nClosing the Loop was founded in 2012 by Joost de Kluijver. Joost started with an NGO to make the electronic industry aware of the impact of e-waste. Although all recognized that e-waste was a major problem, the industry clearly needed more than awareness on the topic of e-waste. Joost and his team therefore took own initiative and showed that the metals inside broken mobile phones still have a value as they contain gold, silver, copper and other recyclable metals. Closing the Loop set up a network of collectors in African countries and in 2015 the first container filled with mobile phones was shipped from Ghana to Europe for proper recycling.\n\nWhen at the end of their lifespan, scrap mobile phones are often dumped and become a hazard for the environment and human health. For example, in landfills like Agbogbloshie, e-waste is dumped and people try to make a living by burning electronics to extract metals. The fumes that are released are very toxic.\n", "related": "NONE"}
{"id": "42168", "url": "https://en.wikipedia.org/wiki?curid=42168", "title": "Data transmission", "text": "Data transmission\n\nData transmission (also data communication or digital communications) is the transfer of data (a digital bitstream or a digitized analog signal) over a point-to-point or point-to-multipoint communication channel. Examples of such channels are copper wires, optical fibers, wireless communication channels, storage media and computer buses. The data are represented as an electromagnetic signal, such as an electrical voltage, radiowave, microwave, or infrared signal. \n\nAnalog or analogue transmission is a transmission method of conveying voice, data, image, signal or video information using a continuous signal which varies in amplitude, phase, or some other property in proportion to that of a variable. The messages are either represented by a sequence of pulses by means of a line code (\"baseband transmission\"), or by a limited set of continuously varying wave forms (\"passband transmission\"), using a digital modulation method. The passband modulation and corresponding demodulation (also known as detection) is carried out by modem equipment. According to the most common definition of digital signal, both baseband and passband signals representing bit-streams are considered as digital transmission, while an alternative definition only considers the baseband signal as digital, and passband transmission of digital data as a form of digital-to-analog conversion.\n\nData transmitted may be digital messages originating from a data source, for example a computer or a keyboard. It may also be an analog signal such as a phone call or a video signal, digitized into a bit-stream, for example, using pulse-code modulation (PCM) or more advanced source coding (analog-to-digital conversion and data compression) schemes. This source coding and decoding is carried out by codec equipment.\n\nCourses and textbooks in the field of \"data transmission\" as well as \"digital transmission\" and \"digital communications\" have similar content.\n\nDigital transmission or data transmission traditionally belongs to telecommunications and electrical engineering. Basic principles of data transmission may also be covered within the computer science or computer engineering topic of data communications, which also includes computer networking applications and networking protocols, for example routing, switching and inter-process communication. Although the Transmission Control Protocol (TCP) involves transmission, TCP and other transport layer protocols are covered in computer networking but \"not\" discussed in a textbook or course about data transmission.\n\nThe term tele transmission involves the analog as well as digital communication. In most textbooks, the term analog transmission only refers to the transmission of an analog message signal (without digitization) by means of an analog signal, either as a non-modulated baseband signal, or as a passband signal using an analog modulation method such as AM or FM. It may also include analog-over-analog pulse modulatated baseband signals such as pulse-width modulation. In a few books within the computer networking tradition, \"analog transmission\" also refers to passband transmission of bit-streams using digital modulation methods such as FSK, PSK and ASK. Note that these methods are covered in textbooks named digital transmission or data transmission, for example.\n\nThe theoretical aspects of data transmission are covered by information theory and coding theory.\n\nCourses and textbooks in the field of data transmission typically deal with the following OSI model protocol layers and topics:\n- Layer 1, the physical layer:\n- Channel coding including\n-  Digital modulation schemes\n-  Line coding schemes\n-  Forward error correction (FEC) codes\n- Bit synchronization\n- Multiplexing\n- Equalization\n- Channel models\n- Layer 2, the data link layer:\n- Channel access schemes, media access control (MAC)\n- Packet mode communication and Frame synchronization\n- Error detection and automatic repeat request (ARQ)\n- Flow control\n- Layer 6, the presentation layer:\n- Source coding (digitization and data compression), and information theory.\n- Cryptography (may occur at any layer)\nIt is also common to deal with the cross-layer design of those three layers.\n\nData (mainly but not exclusively informational) has been sent via non-electronic (e.g. optical, acoustic, mechanical) means since the advent of communication. Analog signal data has been sent electronically since the advent of the telephone. However, the first data electromagnetic transmission applications in modern time were telegraphy (1809) and teletypewriters (1906), which are both digital signals. The fundamental theoretical work in data transmission and information theory by Harry Nyquist, Ralph Hartley, Claude Shannon and others during the early 20th century, was done with these applications in mind.\n\nData transmission is utilized in computers in computer buses and for communication with peripheral equipment via parallel ports and serial ports such as RS-232 (1969), Firewire (1995) and USB (1996). The principles of data transmission are also utilized in storage media for Error detection and correction since 1951.\n\nData transmission is utilized in computer networking equipment such as modems (1940), local area networks (LAN) adapters (1964), repeaters, repeater hubs, microwave links, wireless network access points (1997), etc.\n\nIn telephone networks, digital communication is utilized for transferring many phone calls over the same copper cable or fiber cable by means of Pulse code modulation (PCM), i.e. sampling and digitization, in combination with Time division multiplexing (TDM) (1962). Telephone exchanges have become digital and software controlled, facilitating many value added services. For example, the first AXE telephone exchange was presented in 1976. Since the late 1980s, digital communication to the end user has been possible using Integrated Services Digital Network (ISDN) services. Since the end of the 1990s, broadband access techniques such as ADSL, Cable modems, fiber-to-the-building (FTTB) and fiber-to-the-home (FTTH) have become widespread to small offices and homes. The current tendency is to replace traditional telecommunication services by packet mode communication such as IP telephony and IPTV.\n\nTransmitting analog signals digitally allows for greater signal processing capability. The ability to process a communications signal means that errors caused by random processes can be detected and corrected. Digital signals can also be sampled instead of continuously monitored. The multiplexing of multiple digital signals is much simpler to the multiplexing of analog signals.\n\nBecause of all these advantages, and because recent advances in wideband communication channels and solid-state electronics have allowed scientists to fully realize these advantages, digital communications has grown quickly. Digital communications is quickly edging out analog communication because of the vast demand to transmit computer data and the ability of digital communications to do so.\n\nThe digital revolution has also resulted in many digital telecommunication applications where the principles of data transmission are applied. Examples are second-generation (1991) and later cellular telephony, video conferencing, digital TV (1998), digital radio (1999), telemetry, etc.\n\nData transmission, digital transmission or digital communications is the physical transfer of data (a digital bit stream or a digitized analog signal[1]) over a point-to-point or point-to-multipoint communication channel. Examples of such channels are copper wires, optical fibers, wireless communication channels, storage media and computer buses. The data are represented as an electromagnetic signal, such as an electrical voltage, radiowave, microwave, or infrared signal.\n\nWhile analog transmission is the transfer of a continuously varying analog signal over an analog channel, digital communications is the transfer of discrete messages over a digital or an analog channel. The messages are either represented by a sequence of pulses by means of a line code (baseband transmission), or by a limited set of continuously varying wave forms (passband transmission), using a digital modulation method. The passband modulation and corresponding demodulation (also known as detection) is carried out by modem equipment. According to the most common definition of digital signal, both baseband and passband signals representing bit-streams are considered as digital transmission, while an alternative definition only considers the baseband signal as digital, and passband transmission of digital data as a form of digital-to-analog conversion.\n\nData transmitted may be digital messages originating from a data source, for example a computer or a keyboard. It may also be an analog signal such as a phone call or a video signal, digitized into a bit-stream for example using pulse-code modulation (PCM) or more advanced source coding (analog-to-digital conversion and data compression) schemes. This source coding and decoding is carried out by codec equipment.\n\nIn telecommunications, serial transmission is the sequential transmission of signal elements of a group representing a character or other entity of data. Digital serial transmissions are bits sent over a single wire, frequency or optical path sequentially. Because it requires less signal processing and less chances for error than parallel transmission, the transfer rate of each individual path may be faster. This can be used over longer distances as a check digit or parity bit can be sent along it easily.\n\nIn telecommunications, parallel transmission is the simultaneous transmission of the signal elements of a character or other entity of data. In digital communications, parallel transmission is the simultaneous transmission of related signal elements over two or more separate paths. Multiple electrical wires are used which can transmit multiple bits simultaneously, which allows for higher data transfer rates than can be achieved with serial transmission. This method is used internally within the computer, for example the internal buses, and sometimes externally for such things as printers, The major issue with this is \"skewing\" because the wires in parallel data transmission have slightly different properties (not intentionally) so some bits may arrive before others, which may corrupt the message. A parity bit can help to reduce this. However, electrical wire parallel data transmission is therefore less reliable for long distances because corrupt transmissions are far more likely.\n\nSome communications channel types include:\n- Data transmission circuit\n- Full-duplex\n- Half-duplex\n- Multi-drop:\n- Bus network\n- Mesh network\n- Ring network\n- Star network\n- Wireless network\n- Point-to-point\n- Simplex\n\nAsynchronous serial communication uses start and stop bits to signify the beginning and end of transmission. This method of transmission is used when data are sent intermittently as opposed to in a solid stream. \n\nSynchronous transmission synchronizes transmission speeds at both the receiving and sending end of the transmission using clock signals. The clock may be a separate signal or embedded in the data. A continual stream of data is then sent between the two nodes. Due to there being no start and stop bits the data transfer rate is more efficient.\n\n", "related": "\n- Computer networking\n- Data migration\n- Information theory\n- Media (communication)\n- Network security\n- Node-to-node data transfer\n- Signal processing\n- Telecommunication\n- Transmission (disambiguation)\n"}
{"id": "23429692", "url": "https://en.wikipedia.org/wiki?curid=23429692", "title": "Mahindra Comviva", "text": "Mahindra Comviva\n\nComviva (formerly known as Mahindra Comiva) is a value-added services provider for mobile operators. Comviva has customers in over 90 countries, predominantly in Asia, the Middle East, Latin America and Africa. It offers messaging, mobile Internet, content, mobile commerce, prepaid and \"business support solutions\". It is headquartered with its main R&D and network operation center in Gurgaon, Haryana. Comviva also has offices in Bangalore and Mumbai. It has international offices in South Africa, Dubai, Singapore, Thailand, the United Kingdom and the United States. In 2012 Tech Mahindra bought 51% stake in Comviva.\n\nComviva was founded in 1999 in New Delhi. It was incorporated as Bharti Telesoft Limited, changing its name to Comviva Technologies Limited in April 2009. Comviva merged with CellCloud Technologies Limited, a Bangalore headquartered company, offering \"electronic top-up solutions\", in December 2002. In December 2007, Comviva acquired Jataayu Software Limited, a Bangalore-based provider of \"value added telecom solutions\". On Sep 2012 Tech Mahindra acquired 51 per cent stake in Gurgaon-based mobile application firm Comviva from Bharti Group. In February 2013, Comviva was re-branded to Mahindra Comviva. In February 2014, it partnered with Bharti Airtel for deploying its enterprise communications platform in 16 countries across Africa. In 2019, Mahindra Comviva was re-branded again as Comviva (A Tech Mahindra Company). \n\nComviva provides Consumer Value Management Space services to businesses such as campaign management, loyalty management, customer care, provisioning, and retailing solutions. It also sells mobile apps and a variety of voice, SMS and internet services. \n", "related": "NONE"}
{"id": "37871408", "url": "https://en.wikipedia.org/wiki?curid=37871408", "title": "Foreground detection", "text": "Foreground detection\n\nForeground detection is one of the major tasks in the field of computer vision and image processing whose aim is to detect changes in image sequences. Background subtraction is any technique which allows an image's foreground to be extracted for further processing (object recognition etc.).\n\nMany applications do not need to know everything about the evolution of movement in a video sequence, but only require the information of changes in the scene, because an image's regions of interest are objects (humans, cars, text etc.) in its foreground. After the stage of image preprocessing (which may include image denoising, post processing like morphology etc.) object localisation is required which may make use of this technique.\n\nForeground detection separates foreground from background based on these changes taking place in the foregound. It is a set of techniques that typically analyze video sequences recorded in real time with a stationary camera.\n\nAll detection techniques are based on modelling the background of the image, i.e. set the background and detect which changes occur. Defining the background can be very difficult when it contains shapes, shadows, and moving objects. In defining the background it is assumed that the stationary objects could vary in color and intensity over time.\n\nScenarios where these techniques apply tend to be very diverse. There can be highly variable sequences, such as images with very different lighting, interiors, exteriors, quality, and noise. In addition to processing in real time, systems need to be able to adapt to these changes.\n\nA very good foreground detection system should be able to:\n- Develop a background (estimate) model.\n- Be robust to lighting changes, repetitive movements (leaves, waves, shadows), and long-term changes.\n\nBackground subtraction is a widely used approach for detecting moving objects in videos from static cameras. The rationale in the approach is that of detecting the moving objects from the difference between the current frame and a reference frame, often called \"background image\", or \"background model\". Background subtraction is mostly done if the image in question is a part of a video stream. Background subtraction provides important cues for numerous applications in computer vision, for example surveillance tracking or human poses estimation.\n\nBackground subtraction is generally based on a static background hypothesis which is often not applicable in real environments. With indoor scenes, reflections or animated images on screens lead to background changes. Similarly, due to wind, rain or illumination changes brought by weather, static backgrounds methods have difficulties with outdoor scenes.\n\nThe temporal average filter is a method that was proposed at the Velastin. This system estimates the background model from the median of all pixels of a number of previous images.\nThe system uses a buffer with the pixel values of the last frames to update the median for each image.\n\nTo model the background, the system examines all images in a given time period called training time. At this time we only display images and will find the median, pixel by pixel, of all the plots in the background this time.\n\nAfter the training period for each new frame, each pixel value is compared with the input value of funds previously calculated. If the input pixel is within a threshold, the pixel is considered to match the background model and its value is included in the pixbuf. Otherwise, if the value is outside this threshold pixel is classified as foreground, and not included in the buffer.\n\nThis method can not be considered very efficient because they do not present a rigorous statistical basis and requires a buffer that has a high computational cost.\n\nA robust background subtraction algorithm should be able to handle lighting changes, repetitive motions from clutter and long-term scene changes. The following analyses make use of the function of \"V\"(\"x\",\"y\",\"t\") as a video sequence where \"t\" is the time dimension, \"x\" and \"y\" are the pixel location variables. e.g. \"V\"(1,2,3) is the pixel intensity at (1,2) pixel location of the image at \"t\" = 3 in the video sequence.\n\nA motion detection algorithm begins with the segmentation part where foreground or moving objects are segmented from\nthe background. The simplest way to implement this is to take an image as background and take the frames obtained at the time\nt, denoted by I(t) to compare with the background image denoted by B. Here using simple arithmetic calculations, we can\nsegment out the objects simply by using image subtraction technique of computer vision meaning for each pixels in I(t), take the\npixel value denoted by P[I(t)] and subtract it with the corresponding pixels at the same position on the background image\ndenoted as P[B].\n\nIn mathematical equation, it is written as:\n\nThe background is assumed to be the frame at time \"t\". This difference image would only show some intensity for the pixel locations which have changed in the two frames. Though we have seemingly removed the background, this approach will only work for cases where all foreground pixels are moving and all background pixels are static. A threshold \"Threshold\" is put on this difference image to improve the subtraction (see Image thresholding).\n\nThis means that the difference image's pixels' intensities are 'thresholded' or filtered on the basis of value of Threshold.\n\nFor calculating the image containing only the background, a series of preceding images are averaged. For calculating the background image at the instant \"t\",\n\nwhere \"N\" is the number of preceding images taken for averaging. This averaging refers to averaging corresponding pixels in the given images. \"N\" would depend on the video speed (number of images per second in the video) and the amount of movement in the video. After calculating the background \"B\"(\"x\",\"y\",\"t\") we can then subtract it from the image \"V\"(\"x\",\"y\",\"t\") at time \"t\" = t and threshold it. Thus the foreground is\n\nwhere Th is threshold. Similarly we can also use median instead of mean in the above calculation of \"B\"(\"x\",\"y\",\"t\").\n\nUsage of global and time-independent thresholds (same Th value for all pixels in the image) may limit the accuracy of the above two approaches.\n\nFor this method, Wren et al. propose fitting a Gaussian probabilistic density function (pdf) on the most recent formula_5 frames. In order to avoid fitting the pdf from scratch at each new frame time formula_6, a running (or on-line cumulative) average is computed.\n\nThe pdf of every pixel is characterized by mean formula_7 and variance formula_8 . The following is a possible initial condition (assuming that initially every pixel is background):\n\nwhere formula_11 is the value of the pixel's intensity at time formula_6. In order to initialize variance, we can, for example, use the variance in x and y from a small window around each pixel.\n\nNote that background may change over time (e.g. due to illumination changes or non-static background objects). To accommodate for that change, at every frame formula_6, every pixel's mean and variance must be updated, as follows:\n\nWhere formula_17 determines the size of the temporal window that is used to fit the pdf (usually formula_18 ) and formula_19 is the Euclidean distance between the mean and the value of the pixel.\n\nWe can now classify a pixel as background if its current intensity lies within some confidence interval of its distribution's mean:\n\nwhere the parameter formula_22 is a free threshold (usually formula_23 ). A larger value for formula_24 allows for more dynamic background, while a smaller formula_24 increases the probability of a transition from background to foreground due to more subtle changes.\n\nIn a variant of the method, a pixel's distribution is only updated if it is classified as background. This is to prevent newly introduced foreground objects from fading into the background. The update formula for the mean is changed accordingly:\n\nwhere formula_27 when formula_11 is considered foreground and formula_29 otherwise. So when formula_27 , that is, when the pixel is detected as foreground, the mean will stay the same. As a result, a pixel, once it has become foreground, can only become background again when the intensity value gets close to what it was before turning foreground. This method, however, has several issues: It only works if all pixels are initially background pixels (or foreground pixels are annotated as such). Also, it cannot cope with gradual background changes: If a pixel is categorized as foreground for a too long period of time, the background intensity in that location might have changed (because illumination has changed etc.). As a result, once the foreground object is gone, the new background intensity might not be recognized as such anymore.\n\nMixture of Gaussians method approaches by modelling each pixel as a mixture of Gaussians and uses an on-line approximation to update the model. In this technique, it is assumed that every pixel's intensity values in the video can be modeled using a Gaussian mixture model. A simple heuristic determines which intensities are most probably of the background. Then the pixels which do not match to these are called the foreground pixels.\nForeground pixels are grouped using 2D connected component analysis.\n\nAt any time t, a particular pixel (formula_31)'s history is\n\nThis history is modeled by a mixture of \"K\" Gaussian distributions:\n\nwhere\n\nFirst, each pixel is characterized by its intensity in RGB color space. Then probability of observing the current pixel is given by the following formula in the multidimensional case\n\nWhere K is the number of distributions, ω is a weight associated to the ith Gaussian at time t and µ, Σ are the mean and standard deviation of said Gaussian respectively.\n\nOnce the parameters initialization is made, a first foreground detection can be made then the parameters are updated. The first B Gaussian distribution which exceeds the threshold \"T\" is retained for a background distribution\n\nThe other distributions are considered to represent a foreground distribution. Then, when the new frame incomes at times formula_38, a match test is made of each pixel. A pixel matches a Gaussian distribution if the Mahalanobis distance\n\nwhere \"k\" is a constant threshold equal to formula_40.Then, two cases can occur:\n\nCase 1: A match is found with one of the \"k\" Gaussians. For the matched component, the update is done as follows\n\nPower and Schoonees [3] used the same algorithm to segment the foreground of the image\n\nThe essential approximation to formula_43 is given by formula_44\n\nCase 2: No match is found with any of the formula_46 Gaussians. In this case, the least probable distribution formula_46 is replaced with a new one with parameters\n\nOnce the parameter maintenance is made, foreground detection can be made and so on. An on-line K-means approximation is used to update the Gaussians. Numerous improvements of this original method developed by Stauffer and Grimson have been proposed and a complete survey can be found in Bouwmans et al. A standard method of adaptive backgrounding is averaging the images over time, creating a background approximation which is similar to the current static scene except where motion occur.\n\nSeveral surveys which concern categories or sub-categories of models can be found as follows:\n\n- MOG background subtraction\n- Subspace learning background subtraction\n- Statistical background subtraction\n- Fuzzy background subtraction\n- RPCA background subtraction (See Robust principal component analysis for more details)\n- Dynamic RPCA for background/foreground separation (See Robust principal component analysis for more details)\n- Decomposition into low-rank plus additive matrices for background/foreground Separation\n- Deep neural networks concepts for background subtraction\n- Traditional and recent approaches for background subtraction\n\n- Video surveillance\n- Optical motion capture\n- Human computer interaction\n- Content-based video coding\n- Traffic monitoring\n- Real-time motion gesture recognition\n\nFor more details, please see \n\n", "related": "\n- 3D data acquisition and object reconstruction\n- Gaussian adaptation\n- PBAS\n- Region of interest\n- SOBS\n- Teknomo–Fernandez algorithm\n- ViBe\n\nSeveral comparison/evaluation papers can be found in the literature:\n- A. Sobral, A. Vacavant. \"A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos\". Computer Vision and Image Understanding, CVIU 2014, 2014.\n- A. Shahbaz, J. Hariyono, K. Jo, \"Evaluation of Background Subtraction Algorithms for Video Surveillance\", FCV 2015, 2015.\n- Y. Xu, J. Dong, B. Zhang, D. Xu, \"Background modeling methods in video analysis: A review and comparative evaluation', CAAI Transactions on Intelligence Technology, pages 43–60, Volume 1, Issue 1, January 2016.\n\n- T. Bouwmans, F. Porikli, B. Horferlin, A. Vacavant, \"Handbook on \"Background Modeling and Foreground Detection for Video Surveillance: Traditional and Recent Approaches, Implementations, Benchmarking and Evaluation\"\", CRC Press, Taylor and Francis Group, June 2014. (For more information: http://www.crcpress.com/product/isbn/9781482205374)\n- T. Bouwmans, N. Aybat, and E. Zahzah. \"Handbook on Robust Low-Rank and Sparse Matrix Decomposition: Applications in Image and Video Processing\", CRC Press, Taylor and Francis Group, May 2016. (For more information: http://www.crcpress.com/product/isbn/9781498724623)\n\n- T. Bouwmans, L. Davis, J. Gonzalez, M. Piccardi, C. Shan, Special Issue on \"Background Modeling for Foreground Detection in Real-World Dynamic Scenes\", Special Issue in \"Machine Vision and Applications\", July 2014.\n- A. Vacavant, L. Tougne, T. Chateau, Special section on \"Background models comparison\", \"Computer Vision and Image Understanding\", CVIU 2014, May 2014.\n- A. Petrosino, L. Maddalena, T. Bouwmans, Special Issue on \"Scene Background Modeling and Initialization\", \"Pattern Recognition Letters\", September 2017.\n- T. Bouwmans, Special Issue on \"Detection of Moving Objects\", MDPI Journal of Imaging, 2018.\n\n- Background Learning for Detection and Tracking from RGB videos (RGBD 2017) Workshop in conjunction with ICIAP 2017. (For more information: http://rgbd2017.na.icar.cnr.it/)\n- Scene Background Modeling and Initialization (SBMI 2015) Workshop in conjunction with ICIAP 2015. (For more information: http://sbmi2015.na.icar.cnr.it/)\n- IEEE Change Detection Workshop in conjunction with CVPR 2014. (For more information: http://www.changedetection.net/)\n- Workshop on Background Model Challenges (BMC 2012) in conjunction with ACCV 2012. (For more information: http://bmc.iut-auvergne.com/)\n\n- IEEE Scene Background Modeling Contest (SBMC 2016) in conjunction with ICPR 2016 (For more information: http://pione.dinf.usherbrooke.ca/sbmc2016/)\n\n- Background subtraction by R. Venkatesh Babu\n- Foreground Segmentation and Tracking based on Foreground and Background Modeling Techniques by Jaume Gallego\n- Detecció i extracció d’avions a seqüències de vídeo by Marc Garcia i Ramis\n\n- Background Subtraction website\n\nThe Background Subtraction Website (T. Bouwmans, Univ. La Rochelle, France) contains a comprehensive list of the references in the field, and links to available datasets and software.\n\n- ChangeDetection.net (For more information: http://www.changedetection.net/)\n- Background Models Challenge (For more information: http://bmc.iut-auvergne.com/)\n- Stuttgart Artificial Background Subtraction Dataset (For more information: http://www.vis.uni-stuttgart.de/index.php?id=sabs)\n- SBMI dataset (For more information: http://sbmi2015.na.icar.cnr.it/)\n- SBMnet dataset (For more information: http://pione.dinf.usherbrooke.ca/dataset/)\n\n- BackgroundSubtractorCNT\nThe BackgroundSubtractorCNT library implements a very fast and high quality algorithm written in C++ based on OpenCV. It is targeted at low spec hardware but works just as fast on modern Linux and Windows. (For more information: https://github.com/sagi-z/BackgroundSubtractorCNT).\n\n- BGS Library\nThe BGS Library (A. Sobral, Univ. La Rochelle, France) provides a C++ framework to perform background subtraction algorithms. The code works either on Windows or on Linux. Currently the library offers more than 30 BGS algorithms. (For more information: https://github.com/andrewssobral/bgslibrary)\n\n- LRS Library – Low-Rank and Sparse tools for Background Modeling and Subtraction in Videos The LRSLibrary (A. Sobral, Univ. La Rochelle, France) provides a collection of low-rank and sparse decomposition algorithms in MATLAB. The library was designed for motion segmentation in videos, but it can be also used or adapted for other computer vision problems. Currently the LRSLibrary contains more than 100 matrix-based and tensor-based algorithms. (For more information: https://github.com/andrewssobral/lrslibrary)\n- OpenCV – The OpenCV library provides a number background/foreground segmentation algorithms.\n"}
{"id": "7012204", "url": "https://en.wikipedia.org/wiki?curid=7012204", "title": "Communication endpoint", "text": "Communication endpoint\n\nA communication endpoint is a type of communication network node. It is an interface exposed by a communicating party or by a communication channel. An example of the latter type of a communication endpoint is a publish-subscribe topic \nor a group in group communication systems.\n\n", "related": "\n- Data terminal equipment\n- Dial peer\n- End system\n- Host (network)\n- Node (networking)\n- Terminal (telecommunication)\n"}
{"id": "1639070", "url": "https://en.wikipedia.org/wiki?curid=1639070", "title": "Ještěd Tower", "text": "Ještěd Tower\n\nJeštěd Tower is a 94-meter-tall television transmitter built on the top of Ještěd mountain near Liberec in the Czech Republic. \nIt is made of reinforced concrete shaped in a \"hyperboloid\" form. The tower's architect is Karel Hubáček who was assisted by Zdeněk Patrman, involved in building statics, and by Otakar Binar who designed the interior furnishing. It took the team three years to finalize the structure design (1963-1966). The construction itself took seven years to finish (1966-1973).\n\nThe hyperboloid shape was chosen since it naturally extends the silhouette of the hill and, moreover, well resists the extreme climate conditions on the Ještěd summit. The design cleverly combines the operation of a mountain-top hotel and a television transmitter in one. The hotel and the restaurant are located in the lowest sections of the tower.\n\nBefore the construction of the current hotel, there were already two huts standing near the mountain summit: one was built in the middle of the 19th century and the other was added in the early 20th century. Both buildings had a wooden structure and both burned to the ground in the 1960s.\n\nThe tower is one of the dominant features of the North Bohemian landscape. The gallery on the found floor and the restaurant on the first floor offer views of much of Bohemia and parts of Poland and Germany. The tower silhouette appears on the region flag and the coat-of-arms, and on the local university's logo and on the logo of the local first-league soccer club Slovan Liberec. The building is also featured in the Czech movie Grandhotel based on book by Jaroslav Rudiš.\n\nThe tower has been on the list of the Czech cultural monuments since 1998, becoming a national cultural monument in 2006. In 2007 it was entered on the Tentative List of UNESCO World Heritage sites. In 1969 Karel Hubáček was awarded the prestigious Perret Prize of the International Union of Architects (UIA).\n\nThe monument is accessible by road and also by a cable car from the foot of the mountain.\n\nAfter the existing Ještěd hut burned down in January 1963, a decision was made by Restaurace Liberec ( company that used to manage the burnt down huts) and the Prague Radio Communications Administration to build a new complex on the Ještěd mountain summit, which would accommodate a mountain hotel including a restaurant and at the same time would serve as a TV signal transmitter. An architectural competition for the building design was announced. It took place in February 1963 on the Liberec Stavoprojekt premises. Eleven architects/teams took part in the competition, including individual architects Otakar Binar, Jiří Svoboda, Pavel Švancer, Ota Nykodým, Karel Hubáček, Jaromír Syrovátko, Miroslav Ulmann, Jaromír Vacek and teams Josef Patrný - Jiří Hubka - V. Netolička, Miloš Technik and Svatopluk Technik. Hubáček's design was the only one complying with both the requirements. All the designs were put on public display in the Liberec branch of Československá spořitelna. The jury (aka the council of Liberec district national committee) on its April 22, 1963 meeting chose Hubáček's proposal as the winner.\n\nThe building design created some technical problems for Hubáček and his team due to the climate conditions at the Ještěd summit. Experts from the Czechoslovak Academy of Sciences, the Czech Technical University in Prague (ČVUT) and the Liberec Institute of Textile and Mechanical Engineering helped to overcome the technical difficulties. The technological equipment and procedures that were put together were protected by the Czechoslovak patents. Some elements (such as the laminated cladding, the special pendulum or the transverse damper) introduced by Zdeněk Patrman in collaboration with the Academy experts were since then included in other structures (e.g. the Cukrák transmitter tower) \n\nThe ceremonial laying of the foundation stone took place on July 30, 1966. The general contractor was Pozemní stavby from Liberec. On 1 May 1971 the transmitter began its operation. However, the hotel interiors and the restaurant were completed two years later. On July 9, 1973, the Ještěd Tower grand opening took place. The total construction was 64 million Czechoslovak crowns (in 1973).\n\nIn 1964, the Association of Architects of the Czechoslovak Socialist Republic awarded the Ještěd Tower design on its annual Architectural Works 1962–63 exhibit. In spring of 1969, at a time when the building had not yet been completed, Karel Hubáček was awarded the Auguste Perret Prize for the creative use of technology in architecture by the International Union of Architects. It is the most significant award ever achieved by a Czech architect. In 2000, the building was awarded the title “The Most Important Czech Building of the 20th Century” In September 2005, in the iDNES.cz “Seven Wonders of the Czech Republic” readers survey the tower ranked as second being defeated by the Pumped storage hydro power plant at Dlouhé stráně.\n\nOn 26 March 1998, the Ministry of Culture of the Czech Republic registered the building as an immovable cultural monument. On January 2006, the building was declared a national cultural monument. On May 29, 2007, it was added to the Indicative List of Cultural Property of the Czech Republic, of which buildings are nominated for inclusion in the UNESCO World Heritage List.\n\nThe tower foundation consists of a circular reinforced concrete slab with a thickness of 1 meter and a diameter of 13.40 meters . The foundation is laid in the altitude of 1004.75 meters. The load-bearing element of the structure consists of two concentric reinforced concrete rollers with inner diameters of 4.4 and 12.5 meters (and a wall thicknesses of 30 centimeters); the narrower is 42.4 meters high, the wider (external) is 22.5 meters high. On the tubes the individual floors are suspended on a steel structure, starting with the second floor. The columns were manufactured by Průmstav Pardubice. The supporting steel structures for the floors and for the tower structure were manufactured in the Mostárna plant in the then state-owned company Vítkovice Iron Works of Klement Gottwald. A steel shell with a length of 44 meters of a variable diameter (from 10.50 meters to 1.62 meters) is attached to the inner column The laminate support roller (diameter of 1.90 meters and a wall thickness of 16 to 12 millimeters) attached to it, originally had a length of 17.52 meters which was extended another 3 meters during the 1997 reconstruction.\n\nIn the basement of the building, there are engine rooms and warehouses. The first floor is shared by the administrative offices and the television transmission hall that is connected to the antenna systems on the ninth floor by means of an elevator and an emergency staircase built inside the central tube. The rest of the first floor is occupied by the restaurant kitchen. On the second floor there is an observation terrace, a buffet and the main entrance hall with the reception desk. The hall is dominated by a suspended staircase leading to an observation restaurant on third floor.\n\nOn the fourth and fifth floor there are hotel rooms. On the fourth floor there are 12 double rooms and one apartment. Rooms on the fifth floor were originally used as flats for the hotel and transmitter employees but were later converted to hotel apartments. The sixth and seventh floors house the transmitting technology.There is a specially developed laminated cladding in the shape of a revolving hyperboloid shielding against extreme weather conditions. On the eighth and ninth floors the architect placed drinking water tanks and a backup battery power supply. There is an elevator engine room on the tenth floor. Above it a special pendulum is installed, movement of which absorb cross vibrations caused by the wind.\n\nAt the third to the fifth floor levels (i.e. the restaurant and hotel floors) the outer shell takes on the shape of a conical rotating surface. It consists of 64 conically placed panels. The panel surface is made of anodized aluminum sheets. At the restaurant level, these panels are glazed over the entire width and complemented by a low window sill, while at the hotel level there are smaller windows with rounded corners.\n\nParabolic antennas of microwave transmitters are located on the seventh and eighth floors. The building cover is made of trapezoid-shaped laminated panels, which are not joined by any metal elements, as these would prevent the passage of electromagnetic waves. The upper side of the elevator machine room on the tenth floor is fitted with a welded steel tube, which forms a 48 meter high antenna mast. Its surface is covered with metallized aluminum and a spiral staircase leads up inside the tube. An the top of the mast there is a self-supporting laminate extension of 18 meters attached. During the 1997 transmitter reconstruction it was extended by another 3 meters. The extension is there to protect the TV broadcast antennas against the elements. On top of the extension there is a steel lid, on which an annular pendulum weighing 800 kg is suspended by means of dampers.\n\nThe interior design including its furniture comes from Otakar Binar. Cookware and some textile accessories were based on Karl Wünsch designs. Glass makers Stanislav Libenský and his partner Jaroslava Brychtová also participated in the interior furnishing. They originally planned inserting a tall glass pendulum in the publicly accessible space. The pendulum would consist of two lenses representing the eternal movement. Instead, they decided to drill eight glass emblems into the concrete transmitter shaft. According to the artists, the shaft and its modification suggested the tower was growing up from the rock. On the other hand, for Karel Hubáčekt the glass emblems embodied fallen meteorites. The author of the trellis located in the hotel corridor is Jaroslav Klápště. The staircase walls and the hotel corridors are lined with ceramic tiles designed by Děvana Mírová. The entrance doors and the hotel reception walls are covered with wrought sheets by Miloš Koška, the tapestry hanging on the lounge wall was created by Vladimír Křečan.\n\nOn 1 May 1971, the transmitter (equipped with Tesla III-Zona) began broadcasting television signal from the new tower. In September 1973, broadcasting of the second Czechoslovak Television program was added.\n\nAfter the Velvet Revolution, the transmitter (using a Tesla equipment) was spreading signals of Czech Television (ČT1 and ČT2), Nova and Prima and Czech Radio (Radiožurnál, Praha (today Dvojka) and Vltava) and of private operators ( Radio Proglas, Radio Contact Liberec and Europe 2).\n\nIn connection with the broadcasting digitization in the Czech Republic, in June 2009 the antenna systems in the laminate extension were updated.\n\nIn addition to radio and television broadcasting, Jested is also an important node for radio relay and optical links. Mobile operators T-Mobile, O2, Vodafone and Nordic Telecom have base stations (BTS) here.\n\n", "related": "\n- List of towers\n- Hyperboloid structure\n- List of hyperboloid structures\n- Heinle, Erwin; \"Türme aller Zeiten – aller Kulturen\", Deutsche Verlags-Anstalt, Stuttgart (Germany), , 1997.\n\n- Hotel on Jested\n- History and architecture of the Ještěd Tower\n"}
{"id": "61534344", "url": "https://en.wikipedia.org/wiki?curid=61534344", "title": "IPhone 11", "text": "IPhone 11\n\nThe iPhone 11 is a smartphone designed, developed, and marketed by Apple Inc. It is the thirteenth generation lower-priced iPhone, succeeding the iPhone XR. It was unveiled on September 10, 2019, alongside the higher-end iPhone 11 Pro flagship at the Steve Jobs Theater in Apple Park, Cupertino by Apple CEO Tim Cook. Pre-orders began on September 13, 2019, and was officially released on September 20, 2019, one day after the official public release of iOS 13.\n\nThe prominent changes compared with the iPhone XR are the Apple A13 Bionic chip, and an ultra wide dual camera system. While the iPhone 11 Pro comes with an 18W Lightning to USB-C fast charger, the iPhone 11 comes with the same 5W charger found on previous iPhones, even though this faster charger is compatible with both models.\n\nDetails regarding the smartphone were leaked widely before the official release, with complete specifications and renderings of the phone being publicized, many of which turned out to be correct, such as advancements in the camera and the keeping of the 'notch' design from the frontal camera featured since the iPhone X. Official release event invites sent out to press featured layered colored glass elements organized to form the Apple logo, which some reviewers drew similarities to Apple's original logo, suggesting new colors for the phone, and to a patent Apple filed for a new camera design earlier.\n\nThe iPhone 11 is available in six colors: Purple, Yellow, Green, Black, White, and Product Red. There is a notch at the front for the TrueDepth camera system and speaker, similar to its predecessor, the iPhone XR. There is a bump in the back for the cameras and the flash that is the same size as the iPhone 11 Pro, although the iPhone 11 only has two cameras compared to the Pro's three cameras. Also, the iPhone 11 has a matte glass rear camera housing and glossy glass back, while the iPhone 11 Pro has a glossy glass rear camera housing and matte glass back. The Apple logo is now centered on the back of the device with no text, a change from previous models.\n\nThe iPhone 11, along with the iPhone 11 Pro, uses Apple's A13 Bionic processor, which contains a third-generation neural engine. It has three internal storage options: 64 GB, 128 GB, and 256GB. It also has 4 GB of RAM. The iPhone 11 has an IP68 water and dust-resistant rating along with dirt and grime, and is water-resistant up to two meters for 30 minutes. However, the manufacturer warranty does not cover liquid damage to the phone. Also, like previous iPhones, both phones do not have a headphone jack, and come with wired EarPods with a Lightning connector. The iPhone 11 is the first smartphone with built-in ultra-wideband hardware, via its Apple U1 chip.\n\nThe iPhone 11 has a IPS LCD, unlike the Pro models which have OLED displays.\n\nThe resolution is pixels (1.5 megapixels at 326 ppi) with a maximum brightness of 625 nits and a 1400:1 contrast ratio. It supports Dolby Vision, HDR10, True-Tone, and wide color gamut. As with the iPhone 11 Pro, XR, XS, and X, the display has a notch at the top for the TrueDepth camera system and the speaker. The display has an oleophobic coating that is fingerprint-resistant. Apple announced in September 2019 that both the iPhone 11 and iPhone 11 Pro would show a warning notification if a display was replaced with an unauthorized part. Apple stated that problems with the phone could arise if the wrong parts or procedures were used during the repair process.\n\nThe iPhone 11 includes a dual-lens 12MP rear camera array. There is one f/2.4 ultra wide angle lens with a 120 degree field of view and 2x optical zoom out and one f/1.8 wide angle lens. The iPhone 11 supports 4K video at up to 60 fps and 1080p slow motion at up to 240 fps. The phone also features an audio zoom feature which focuses audio on the area that is being zoomed in on, similar to the Pro model. Both of the cameras support video although only the primary lens has OIS. It supports a Portrait Mode with depth control and an advanced Bokeh effect. The phone also has an automatic Night Mode allowing the camera to take brighter pictures with reduced noise in low light environments. There is also a redesigned camera app that adds new features such as a scroll wheel for choosing between the different lenses and a feature called “QuickTake,” which allows the user to long-press the shutter button to take a video. Apple has also announced a new Deep Fusion feature which takes advantage of AI and machine learning for image processing and was released via iOS 13.2 software update on October 29.\n\nThe iPhone 11 shipped with iOS 13, which includes Siri, Face ID (through the TrueDepth camera), Apple Pay, and supports Apple Card.\n\nThe iPhone 11 drew generally positive reviews after its launch. Reviews generally praised the phone's performance, battery life, and cameras, while criticizing the display as passable, but aging quickly. Reviewers also criticized the notch as being far too large for 2019. According to Counterpoint Research's Market Pulse, it was the second best-selling model globally for 2019, in less than four months of launch.\n\n", "related": "\n- Comparison of smartphones\n- History of iPhone\n- List of iOS devices\n\n- Official website\n"}
{"id": "6031554", "url": "https://en.wikipedia.org/wiki?curid=6031554", "title": "Attenuation distortion", "text": "Attenuation distortion\n\nAttenuation distortion is the distortion of an analog signal that occurs during transmission when the transmission medium does not have a flat frequency response across the bandwidth of the medium or the frequency spectrum of the signal.\n\nAttenuation distortion occurs when some frequencies are attenuated more than other frequencies. When an analog signal of constant amplitude across its frequency spectrum suffers attenuation distortion, some frequencies of the received signal arrive being greater in amplitude (louder), relative to other frequencies. \n\nTo overcome the effects of attenuation distortion, communications circuits have special equalization equipment attached at the ends of the circuit or in between, designed to attenuate the signal evenly across the frequency spectrum, or to allow the signal to be received at equal amplitude for all frequencies. Attenuation distortion can still occur in a properly equipped circuit if this equalization filter is not properly maintained or adjusted.\n\nIn DSL circuits, echoes due to impedance mismatch often cause attenuation distortion so severe that some frequencies must be automatically mapped out and not used.\n", "related": "NONE"}
{"id": "1456103", "url": "https://en.wikipedia.org/wiki?curid=1456103", "title": "Globe Telecom", "text": "Globe Telecom\n\nGlobe Telecom, Inc., commonly shortened as Globe, is a major provider of telecommunications services in the Philippines. The company is the largest mobile network operator in the Philippines and one of the largest fixed line, and broadband networks. As of end-September 2019, Globe’s total mobile subscriber base reached 97.4 million, five percent more than its subscriber count from the previous quarter.\n\nThe company's principal shareholders are Ayala Corporation and Singapore Telecommunications. It is listed on the Philippine Stock Exchange under the ticker symbol GLO and had a market capitalization of US$3.8 billion as of the end of June 2018.\n\nGlobe's main competitor in the fixed-line telephone market is PLDT with its subsidiary, Digitel. BayanTel used to be one of its competitors prior to its acquisition by Globe. In the mobile phone market (along with TM), its main competitors are PLDT's cellular services namely, Smart, TNT and Sun Cellular.\n\nIn 2016, Globe introduced its \"Globe Lifestyle\" brand as a way to connect to its customers through fashion. It also launched two entertainment divisions: Globe Studios, which focuses on film and television production, and Globe Live, which focuses on live concerts and musical events.\nIn 1928, Congress passed Act No. 3495 granting the Robert Dollar Company (a corporation organized and existing under the laws of the State of California), a franchise to operate wireless long-distance message services in the Philippines. Subsequently, Congress passed Act No. 4150 in 1934 to transfer the franchise and privileges of the Robert Dollar Company to Globe Wireless Limited, which was incorporated in the Philippines on 15 January 1935.\n\nGlobe Wireless Limited was later renamed as Globe-Mackay Cable and Radio Corporation (\"Globe-Mackay\"). Through Republic Act (\"RA\") No. 4630 enacted in 1965 by Congress, its franchise was further expanded to allow it to operate international communications systems. Globe-Mackay was granted a new franchise in 1980 by Batasang Pambansa, under Batas Pambansa 95.\n\nIn 1974, Globe-Mackay sold 60% of its stock to Ayala Corporation, local investors and its employees. It offered its shares to the public on 11 August 1975.\n\nIn 1992, Globe-Mackay merged with Clavecilla Radio Corporation, a domestic telecommunications pioneer, to form GMCR, Inc. (\"GMCR\"). The merger gave GMCR the capability to provide all forms of telecommunications to address the international and domestic requirements of its customers. GMCR was subsequently renamed to Globe Telecom, Inc. (\"Globe\").\n\nIn 1993, Globe partnered with Singapore Telecom, Inc. (STI), a wholly owned subsidiary of Singapore Telecommunications Limited (\"Singtel\"), after Ayala and STI signed a Memorandum of Understanding.\n\nIn 2001, Globe merged with Isla Communications Company, Inc. (\"Islacom\") a joint venture with Deutsche Telekom as foreign partner. It became its wholly owned subsidiary effective 27 June 2001. Deutsche Telekom eventually sold its share to Singapore Telecom. In 2003, the National Telecommunications Commission (\"NTC\") granted Globe Telecom's application to transfer its fixed line business assets and subscribers to Islacom, pursuant to its strategy to integrate all of its fixed line services under Islacom. Subsequently, Islacom was renamed as Innove Communications, Inc.\n\nIn 2004, Globe invested in G-Xchange, Inc. (\"GXI\"), a wholly owned subsidiary, to handle the mobile payment and remittance service marketed under the GCash brand using Globe Telecom's network as transport channel. GXI started commercial operations on 16 October 2004.\n\nIn November 2004, Globe and seven other leading Asia-Pacific mobile operators (\"JV Partners\") signed an agreement (\"JV agreement\") to form Bridge Alliance. The joint venture company operates through a Singapore-incorporated company, Bridge Mobile Pte. Limited (BMPL) which serves as a commercial vehicle for the JV partners to build and establish a regional mobile infrastructure and common service platform to deliver different regional mobile services to their subscribers. The Bridge Alliance currently has a combined customer base of over 250 million subscribers among its partners in India, Thailand, Hong Kong, South Korea, Macau, Philippines, Malaysia, Singapore, Australia, Taiwan and Indonesia.\n\nIn 2005, Innove was awarded by the National Telecommunications Commission (NTC) with a nationwide franchise for its fixed line business, allowing it to operate a Local Exchange Carrier service nationwide and expand its network coverage. In December 2005, the NTC approved Globe Telecom's application for third generation (3G) radio frequency spectra to support the upgrade of its cellular mobile telephone system (\"CMTS\") network to be able to provide 3G services. Globe was assigned with 10-Megahertz (MHz) of the 3G radio frequency spectrum.\n\nOn 19 May 2008, following the approval of the NTC, the subscribers contracts of Touch Mobile (TM) prepaid service were transferred from Innove to Globe, which now operates all wireless prepaid services using its integrated cellular networks.\n\nIn August 2008, and to further grow its mobile data segment, Globe acquired 100% ownership of Entertainment Gateway Group (\"EGG\"), a leading mobile content provide in the Philippines. EGG Group is engaged in the development and creation of wireless products and services accessible through telephones or other forms of communication devices. It also provides internet and mobile value added services, information technology and technical services including software development and related services. EGGC is registered with the Department of Transportation and Communication (DOTC) as a content provider. On May 15, 2014, EGGC changed its corporate name from Entertainment Gateway Group Corp. to Yondu, Inc. (Yondu).\n\nOn 30 October 2008, Globe, the Bank of the Philippine Islands and Ayala Corporation signed a memorandum of agreement to form a joint venture that would allow rural and low-income customers' access to financial products and services. Last October 2009, the Bangko Sentral ng Pilipinas (BSP) approved the sale and transfer by BPI of its shares of stock in Pilipinas Savings Bank, Inc. (PSBI), formalizing the creation of the venture. Globe Telecom's and BPI's ownership stakes in PSBI is at 40% each, while AC's shareholding is at 20%. The partners plan to transform PSBI (now called BPI Globe BanKO, Inc.) into the country's first mobile microfinance bank. The bank's initial focus will be on wholesale lending to other microfinance institutions but will eventually expand to include retail lending, deposit-taking, and micro-insurance. BPI Globe BanKO opened its first branch in Metro Manila in the first quarter of 2011 and now has 6 branches nationwide, over 2,000 partner outlets, 261,000 customers and over P2.4 billion in its wholesale loan portfolio.\n\nOn 25 November 2008, Globe formed GTI Business Holdings, Inc. (GTIBH) primarily to act as an investment company. In March 2012, Globe launched Kickstart Ventures, Inc. (Kickstart) to help, support and develop the dynamic and growing community of technopreneurs in the Philippines. Kickstart is a business incubator that is focused on providing aspiring technopreneurs with the efficient environment and the necessary mechanisms to start their own business. Since its launch, Kickstart has 10 companies in its portfolio covering the digital media and technology, and web/mobile platform space.\n\nIn May 2013, ABS-CBN Convergence, Inc. (\"ABS-C\", formerly Multimedia Telephony, Inc.) announced the launch of its mobile brand, ABS-CBNmobile. The launch of the new mobile brand is being supported through a network sharing agreement with Globe, wherein the latter provides network capacity and coverage to ABS-C on a nationwide basis. ABS-C formally launched the brand on November 26, 2013.\n\nIn October 2013, following the court's approval of the Amended Rehabilitation Plan (jointly filed by Globe and BayanTel in May 2013), Globe acquired a 38% interest in BayanTel by converting BayanTel's unsustainable debt into common shares. This follows Globe Telecom's successful tender offer for close to 97% of BayanTel's outstanding indebtedness as of December 2012. As part of the amended rehab plan and pending regulatory approvals, Globe would further convert a portion of its sustainable debt into common shares of BayanTel, bringing up its stake to around 56%. In October 2014, Globe Telecom received a copy of the temporary restraining order (TRO) issued by the Court of Appeals stopping the National Telecommunications Commission's (NTC) proceedings in connection with the bid of Globe Telecom Inc. to take over Bayan Telecommunications Inc. (BayanTel). Despite the lapse of the Temporary Restraining Order (TRO) last December 9, 2014, the Court of Appeals has advised the NTC to refrain from conducting any proceedings in connection with the bid of Globe assume majority control of BayanTel.\n\nOn June 3, 2014, Globe signed an agreement with Azalea Technology, Inc. and SCS Computer Systems, acquiring the entire ownership stake in Asticom. Asticom, a systems integrator and information technology services provider to domestic and international markets, is 49% owned by Azalea, a 100%-owned subsidiary of Ayala Corporation and 51% owned by SCS Computer Systems, a subsidiary of Singapore Telecom.\n\nOn June 30, 2015, Globe incorporated Global Capital Venture Holdings, Inc., a wholly owned subsidiary organized under the laws of the Philippines and formed for the purpose of venturing into strategic non-core business.\n\nOn August 27, 2015, Globe Telecom, Inc. (Globe), Ayala Corporation (AC) and Bank of the Philippine Islands (BPI) signed an agreement to turn over full ownership of BPI Globe BanKO (BanKO) to BPI, one of the majority owners of the joint venture.\n\nIn Q3 2016, Globe Telecom dislodged Smart Communications as the largest telecommunications company it terms of subscriber base with 65.8 million subscribers, 200,000 more than its rival.\n\nIn 2017, Globe Telecom's CEO, Ernest Cu was named the CEO of the year by the World Communications Awards 2017.\n\nIn 2018, Globe Telecom was selected as the best workplace in Asia. and the Internet was proposed to be extended in Europe.\n\nThe following are the major stockholders of Globe Telecom as of 30 June 2015:\n- Ayala Corporation: 13.85% (with common shares of 40,351,591)\n- SingTel: 21.51% (with common shares of 62,646,487)\n- Asiacom: 54.43% (With preferred shares of 158,515,016)\n- Directors, Officers, ESOP: 0.07% (With common shares of 205,027; preferred shares of 5)\n- Public Stock : 10.14% (With common shares of 29,537,111)\n\nUpdated Shareholding Structure of Globe Telecom as of 31 March 2019:\n- Innove Communications, Inc. (Innove.) - 100% ownership\n- Kickstart Ventures, Inc. (Kickstart)- 100% ownership\n- Flipside Publishing Services, Inc. (FPSI) - 40% ownership\n- AdSpark Inc. - 100% ownership\n- Yondu (formerly known as Entertainment Gateway Group Corp.) - 100% ownership\n- Mynt (Globe Fintech Innovations, Inc.)- 45% ownership\n- GTI Business Holdings (GTI) - 100% ownership\n- Asticom Technology, Inc. – 100% ownership\n\n- G-Xchange, Inc. (GXI, mobile payment and remittance service marketed under the GCash brand) – 100% ownership\n\n- BayanTel\n\n- ABS-CBN Convergence (32%)\n- Bridge Mobile - 10% ownership\n- Cherry Mobile Prepaid\n\n- Bayan Telecommunications Inc. (BTI) – 98.57% ownership\n- AF Payments, Inc. – 20% ownership\n\n- Bethlehem Holdings Inc. (BHI) - a media investment firm through its retirement pension agency funded by Globe Telecom\n- Altimax Broadcasting Company (Altimax)\n- Broadcast Enterprises and Affiliated Media (BEAM) - 100% ownership\n\nGlobe Telecom and MET Events organized the Philippine Pro Gaming League. In its first season, it only had 3 games Dota 2, Tekken 7, and Arena of Valor with P800,000 prize pool. The second season increased the prize pool to P1.3-million, had 4 games: League of Legends, Tekken 7, Rules of Survival, and Arena of Valor and a corporate league added later on.\n\n", "related": "\n- Ayala Corporation\n- TM (cellular service)\n"}
{"id": "12600", "url": "https://en.wikipedia.org/wiki?curid=12600", "title": "Grid network", "text": "Grid network\n\nA grid network is a computer network consisting of a number of computer systems connected in a grid topology.\n\nIn a regular grid topology, each node in the network is connected with two neighbors along one or more dimensions. If the network is one-dimensional, and the chain of nodes is connected to form a circular loop, the resulting topology is known as a ring. Network systems such as FDDI use two counter-rotating token-passing rings to achieve high reliability and performance. In general, when an \"n\"-dimensional grid network is connected circularly in more than one dimension, the resulting network topology is a torus, and the network is called \"toroidal\". When the number of nodes along each dimension of a toroidal network is 2, the resulting network is called\na hypercube.\n\nA parallel computing cluster or multi-core processor is often connected in regular interconnection network such as a\nde Bruijn graph,\na hypercube graph,\na hypertree network,\na fat tree network,\na torus, or cube-connected cycles.\n\nA grid network is not the same as a grid computer or a computational grid, although the nodes in a grid network are usually computers, and grid computing requires some kind of computer network or \"universal coding\" to interconnect the computers.\n\n", "related": "\n- Grid plan - street network\n- Network topology\n"}
{"id": "57462594", "url": "https://en.wikipedia.org/wiki?curid=57462594", "title": "Line splice", "text": "Line splice\n\nIn telecommunications, a line splice is a method of connecting electrical cables (electrical splice) or optical fibers (optical splice).\n\nSplices are often housed in sleeves to protect against external influences.\n\nThe splicing of copper wires happens in the following steps:\n\n- The cores are laid one above the other at the junction.\n- The wires are wrapped two to three times around each other (twisting).\n- The core insulation is removed.\n- The bare veins on a length of about 3 cm \"strangle\" or \"twist\". In some cases, the strangulation is soldered.\n- To isolate the splice, an insulating sleeve made of paper or plastic is pushed over it.\n\nThe splicing of copper wires is mainly used on paper insulated wires.\n\nLSA techniques (LSA: soldering, screwing and stripping free) are used to connect copper wires, making the copper wires faster and easier to connect. LSA techniques include:\n\n- Wire connection sleeves (AVH = Adernverbindungshülsen) and other crimp connectors. The two wires to be connected are inserted into the AVH without being stripped, which is then compressed with special pliers. The about 2 cm long AVH consist of contact, pressure and insulation.\n- For wire connection strips (AVL = Adernverbindungsleisten) several pairs of wires (10 = AVL10 or 20 = AVL20) are inserted, the strip is then closed with a lid and pressed together with a hydraulic press, which ensures the connection.\n\nFiber-optic cables are spliced using a special arc-splicer, with installation cables connected at their ends to respective \"pigtails\" - short individual fibers with fiber-optic connectors at one end. The splicer precisely adjusts the light-guiding cores of the two ends of the glass fibers to be spliced. The adjustment is done fully automatically in modern devices, whereas in older models this is carried out manually by means of micrometer screws and microscope. An experienced splicer can precisely position the fiber ends within a few seconds. Subsequently, the fibers are fused together (welded) with an electric arc. Since no additional material is added, such as gas welding or soldering, this is called a \"fusion splice\".\n\nDepending on the quality of the splicing process, attenuation values at the splice points are achieved by 0.3 dB, with good splices also below 0.02 dB. For newer generation devices, alignment is done automatically by motors. Here one differentiates core and jacket centering. At core centering (usually single-mode fibers), the fiber cores are aligned. A possible core offset with respect to the jacket is corrected. In the jacket centering (usually in multimode fibers), the fibers are adjusted to each other by means of electronic image processing in front of the splice.\n\nWhen working with good equipment, the damping value is according to experience at max. 0.1 dB. Measurements are made by means of special measuring devices including optical time-domain reflectometry (OTDR). A good splice should have an attenuation of less than 0.3 dB over the entire distance. Finished fiber optic splices are housed in splice boxes.\n\nOne differentiates:\n\n- Fusion splice\n- Adhesive splicing\n- Crimp splice or NENP (no-epoxy no-polish), mechanical splice\n\n", "related": "\n- Fusion splice\n- Mechanical splice\n- Western Union splice\n"}
{"id": "56557404", "url": "https://en.wikipedia.org/wiki?curid=56557404", "title": "Networked flying platform", "text": "Networked flying platform\n\nNetworked flying platforms (NFPs) are unmanned flying platforms of various types including unmanned aerial vehicles (UAVs), drones, tethered balloon and high-altitude/medium-altitude/low-altitude platforms\n(HAPs/MAPs/LAPs) carrying RF/mmWave/FSO payload (transceivers) along with an extended battery life capabilities, and are floating or moving in the air at a quasi-stationary positions with the ability to move horizontally and vertically to offer 5G and beyond 5G (B5G) cellular networks and network support services.\n\nThere are following two possible NFPs deployment configurations:\n\n- Deployment configuration 1: NFPs are expected to complement the conventional cellular networks to further enhance the wireless capacity, expand the coverage and improve the network reliability for temporary events, where there is a high density of mobile users or small cells in a limited/hard to reach area or in a remote region where infrastructure is not available and expensive to deploy, e.g., sports events and concert gatherings\n- Deployment configuration 2: NFPs can be deployed for unexpected scenarios, such as in emergency situations to support disaster relief activities and to enable communications when conventional cellular networks are either damaged or congested. In addition, owing to their mobility, NFPs are expected to deploy quickly and efficiently to support cellular networks, enhance network quality-of-service (QoS) and improve network resilience under emergency scenarios\n\nNFPs can be manually (non-autonomously) controlled but mainly designed for autonomous pre-determined flights. NFPs can either operate in a single NFP mode where NFPs do not cooperate with other NFPs in the network, if exists or a swarm of NFPs where multiple interconnected NFPs cooperate, collaborate and perform the network mission autonomously with one of the NFPs designated as mother-NFP\n\n- BT Drone flights to connect Isle of Lewis with mainland\n- Qualcomm Technologies releases LTE drone trial results\n- Intel testing drones over AT&T LTE Networks, Verizon starts 5G Trials with Samsung\n- Project Skybender: Google's secretive 5G internet drone tests revealed\n", "related": "NONE"}
